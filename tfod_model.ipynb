{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tfod_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltq_UY5m2akX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "458bc96f-502f-4de2-f3c2-158e43f45207"
      },
      "source": [
        "#!nvidia-smi\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Sep 24 17:34:55 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWwVaIR8WHJl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3af9974b-5748-469b-f4f7-8bc54a6bf876"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLddSueSY3bO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "RESEARCH_DIR = \"/content/drive/My Drive/TFOD/models/research\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eZq9m0TY7ze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(RESEARCH_DIR)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEADjo1kY-jN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b7b31b02-c71e-4ef0-de11-13af16b7e174"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/TFOD/models/research'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXvAZuNk4GWf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "277d5c6a-670a-4f12-b699-a905780c001c"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/TFOD/models/research'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akwuiVdJonfc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4cd3753f-96fc-4ad1-ad08-b3d0b14725b7"
      },
      "source": [
        "#----------this is for change tensorflow version 1.14.0 run same command again for select version 1.14 ----------\n",
        "\n",
        "#%tensorflow_version 2.x\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow==1.14.0\n",
        "!pip install tensorflow-gpu==1.14.0"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-1.15.2:\n",
            "  Successfully uninstalled tensorflow-1.15.2\n",
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 111kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 52.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.35.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.6 (from tensorflow==1.14.0) (1.0.8)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 56.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (50.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed tensorboard-2.3.0 tensorflow-1.14.0 tensorflow-estimator-2.3.0\n",
            "Collecting tensorflow-gpu==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 46kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.6 (from tensorflow-gpu==1.14.0) (1.0.8)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Using cached https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.35.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Using cached https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14.0) (50.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.1.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X0tqkqJnr6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1msKyhBbu23b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "615bc587-7d28-4ce7-c4b7-141f12a73f3b"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e__En72-a2m7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a84436ba-5b4c-46eb-adaa-019b1866aaf5"
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF2engaat649",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip uninstall tensorflow"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vAB_4SF8T01",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "bc587042-1a9f-4ce0-cd7e-e7cb4801a3c6"
      },
      "source": [
        "!pip install --upgrade protobuf"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting protobuf\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/79/510974552cebff2ba04038544799450defe75e96ea5f1675dbf72cc8744f/protobuf-3.13.0-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
            "\r\u001b[K     |▎                               | 10kB 27.8MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 6.2MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 8.7MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 7.2MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 71kB 8.6MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 8.5MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92kB 9.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 102kB 9.5MB/s eta 0:00:01\r\u001b[K     |██▉                             | 112kB 9.5MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 9.5MB/s eta 0:00:01\r\u001b[K     |███▍                            | 133kB 9.5MB/s eta 0:00:01\r\u001b[K     |███▋                            | 143kB 9.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 153kB 9.5MB/s eta 0:00:01\r\u001b[K     |████                            | 163kB 9.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 174kB 9.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 184kB 9.5MB/s eta 0:00:01\r\u001b[K     |████▉                           | 194kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 204kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 215kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 225kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 235kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 245kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 256kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 266kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 276kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 286kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 296kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 307kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 317kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 327kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 337kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 348kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 358kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 368kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 378kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 389kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 399kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 409kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 419kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 430kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 440kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 450kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 460kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 471kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 481kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 491kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 501kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 512kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 522kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 532kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 542kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 552kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 563kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 573kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 583kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 593kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 604kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 614kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 624kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 634kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 645kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 655kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 665kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 675kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 686kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 696kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 706kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 716kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 727kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 737kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 747kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 757kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 768kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 778kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 788kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 798kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 808kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 819kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 829kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 839kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 849kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 860kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 870kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 880kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 890kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 901kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 911kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 921kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 931kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 942kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 952kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 962kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 972kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 983kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 993kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.0MB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.0MB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.0MB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.0MB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.0MB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.1MB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2MB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2MB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2MB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.2MB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.3MB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.3MB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf) (50.3.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf) (1.15.0)\n",
            "Installing collected packages: protobuf\n",
            "  Found existing installation: protobuf 3.12.4\n",
            "    Uninstalling protobuf-3.12.4:\n",
            "      Successfully uninstalled protobuf-3.12.4\n",
            "Successfully installed protobuf-3.13.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRNM5WLmZAH-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ad15957a-99d3-45d6-eb8f-3f2784a3dfb0"
      },
      "source": [
        "#!python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v1_coco.config\n",
        "!python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2_coco.config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "I0923 10:05:52.136819 139631849019264 learning.py:507] global step 19047: loss = 0.0654 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 19048: loss = 0.1956 (0.273 sec/step)\n",
            "I0923 10:05:52.411820 139631849019264 learning.py:507] global step 19048: loss = 0.1956 (0.273 sec/step)\n",
            "INFO:tensorflow:global step 19049: loss = 0.1214 (0.273 sec/step)\n",
            "I0923 10:05:52.686853 139631849019264 learning.py:507] global step 19049: loss = 0.1214 (0.273 sec/step)\n",
            "INFO:tensorflow:global step 19050: loss = 0.1766 (0.274 sec/step)\n",
            "I0923 10:05:52.963984 139631849019264 learning.py:507] global step 19050: loss = 0.1766 (0.274 sec/step)\n",
            "INFO:tensorflow:global step 19051: loss = 0.1134 (0.272 sec/step)\n",
            "I0923 10:05:53.238697 139631849019264 learning.py:507] global step 19051: loss = 0.1134 (0.272 sec/step)\n",
            "INFO:tensorflow:global step 19052: loss = 0.1453 (0.292 sec/step)\n",
            "I0923 10:05:53.531961 139631849019264 learning.py:507] global step 19052: loss = 0.1453 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19053: loss = 0.0532 (0.292 sec/step)\n",
            "I0923 10:05:53.825489 139631849019264 learning.py:507] global step 19053: loss = 0.0532 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19054: loss = 0.1117 (0.333 sec/step)\n",
            "I0923 10:05:54.160330 139631849019264 learning.py:507] global step 19054: loss = 0.1117 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 19055: loss = 0.1656 (0.302 sec/step)\n",
            "I0923 10:05:54.464230 139631849019264 learning.py:507] global step 19055: loss = 0.1656 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 19056: loss = 0.0872 (0.323 sec/step)\n",
            "I0923 10:05:54.788811 139631849019264 learning.py:507] global step 19056: loss = 0.0872 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 19057: loss = 0.1508 (0.287 sec/step)\n",
            "I0923 10:05:55.077859 139631849019264 learning.py:507] global step 19057: loss = 0.1508 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 19058: loss = 0.0623 (0.316 sec/step)\n",
            "I0923 10:05:55.396445 139631849019264 learning.py:507] global step 19058: loss = 0.0623 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 19059: loss = 0.0919 (0.389 sec/step)\n",
            "I0923 10:05:55.786941 139631849019264 learning.py:507] global step 19059: loss = 0.0919 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 19060: loss = 0.1027 (0.325 sec/step)\n",
            "I0923 10:05:56.113197 139631849019264 learning.py:507] global step 19060: loss = 0.1027 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 19061: loss = 0.0294 (0.284 sec/step)\n",
            "I0923 10:05:56.399596 139631849019264 learning.py:507] global step 19061: loss = 0.0294 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19062: loss = 0.0573 (0.332 sec/step)\n",
            "I0923 10:05:56.735990 139631849019264 learning.py:507] global step 19062: loss = 0.0573 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 19063: loss = 0.0955 (0.346 sec/step)\n",
            "I0923 10:05:57.084186 139631849019264 learning.py:507] global step 19063: loss = 0.0955 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 19064: loss = 0.3647 (0.327 sec/step)\n",
            "I0923 10:05:57.413371 139631849019264 learning.py:507] global step 19064: loss = 0.3647 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19065: loss = 0.1093 (0.321 sec/step)\n",
            "I0923 10:05:57.735731 139631849019264 learning.py:507] global step 19065: loss = 0.1093 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 19066: loss = 0.1132 (0.300 sec/step)\n",
            "I0923 10:05:58.037759 139631849019264 learning.py:507] global step 19066: loss = 0.1132 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 19067: loss = 0.0721 (0.335 sec/step)\n",
            "I0923 10:05:58.374719 139631849019264 learning.py:507] global step 19067: loss = 0.0721 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 19068: loss = 0.0979 (0.311 sec/step)\n",
            "I0923 10:05:58.687976 139631849019264 learning.py:507] global step 19068: loss = 0.0979 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 19069: loss = 0.1059 (0.297 sec/step)\n",
            "I0923 10:05:58.988009 139631849019264 learning.py:507] global step 19069: loss = 0.1059 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 19070: loss = 0.1321 (0.272 sec/step)\n",
            "I0923 10:05:59.262722 139631849019264 learning.py:507] global step 19070: loss = 0.1321 (0.272 sec/step)\n",
            "INFO:tensorflow:global step 19071: loss = 0.0645 (0.329 sec/step)\n",
            "I0923 10:05:59.593424 139631849019264 learning.py:507] global step 19071: loss = 0.0645 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 19072: loss = 0.1508 (0.282 sec/step)\n",
            "I0923 10:05:59.878345 139631849019264 learning.py:507] global step 19072: loss = 0.1508 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 19073: loss = 0.0563 (0.338 sec/step)\n",
            "I0923 10:06:00.218910 139631849019264 learning.py:507] global step 19073: loss = 0.0563 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 19074: loss = 0.1260 (0.287 sec/step)\n",
            "I0923 10:06:00.507235 139631849019264 learning.py:507] global step 19074: loss = 0.1260 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 19075: loss = 0.1315 (0.321 sec/step)\n",
            "I0923 10:06:00.830340 139631849019264 learning.py:507] global step 19075: loss = 0.1315 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 19076: loss = 0.0495 (0.299 sec/step)\n",
            "I0923 10:06:01.131608 139631849019264 learning.py:507] global step 19076: loss = 0.0495 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 19077: loss = 0.1088 (0.305 sec/step)\n",
            "I0923 10:06:01.438810 139631849019264 learning.py:507] global step 19077: loss = 0.1088 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 19078: loss = 0.0352 (0.296 sec/step)\n",
            "I0923 10:06:01.736857 139631849019264 learning.py:507] global step 19078: loss = 0.0352 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 19079: loss = 0.1224 (0.327 sec/step)\n",
            "I0923 10:06:02.065633 139631849019264 learning.py:507] global step 19079: loss = 0.1224 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19080: loss = 0.0800 (0.300 sec/step)\n",
            "I0923 10:06:02.367368 139631849019264 learning.py:507] global step 19080: loss = 0.0800 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 19081: loss = 0.2647 (0.317 sec/step)\n",
            "I0923 10:06:02.686474 139631849019264 learning.py:507] global step 19081: loss = 0.2647 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 19082: loss = 0.2514 (0.312 sec/step)\n",
            "I0923 10:06:03.000758 139631849019264 learning.py:507] global step 19082: loss = 0.2514 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 19083: loss = 0.1108 (0.354 sec/step)\n",
            "I0923 10:06:03.356590 139631849019264 learning.py:507] global step 19083: loss = 0.1108 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 19084: loss = 0.0649 (0.336 sec/step)\n",
            "I0923 10:06:03.694087 139631849019264 learning.py:507] global step 19084: loss = 0.0649 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 19085: loss = 0.1724 (0.315 sec/step)\n",
            "I0923 10:06:04.011642 139631849019264 learning.py:507] global step 19085: loss = 0.1724 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 19086: loss = 0.0598 (0.332 sec/step)\n",
            "I0923 10:06:04.345822 139631849019264 learning.py:507] global step 19086: loss = 0.0598 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 19087: loss = 0.1094 (0.319 sec/step)\n",
            "I0923 10:06:04.667052 139631849019264 learning.py:507] global step 19087: loss = 0.1094 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 19088: loss = 0.0342 (0.296 sec/step)\n",
            "I0923 10:06:04.964517 139631849019264 learning.py:507] global step 19088: loss = 0.0342 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 19089: loss = 0.1150 (0.284 sec/step)\n",
            "I0923 10:06:05.250823 139631849019264 learning.py:507] global step 19089: loss = 0.1150 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19090: loss = 0.0601 (0.299 sec/step)\n",
            "I0923 10:06:05.552001 139631849019264 learning.py:507] global step 19090: loss = 0.0601 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 19091: loss = 0.0476 (0.290 sec/step)\n",
            "I0923 10:06:05.844256 139631849019264 learning.py:507] global step 19091: loss = 0.0476 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 19092: loss = 0.1984 (0.331 sec/step)\n",
            "I0923 10:06:06.176817 139631849019264 learning.py:507] global step 19092: loss = 0.1984 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 19093: loss = 0.0619 (0.296 sec/step)\n",
            "I0923 10:06:06.474789 139631849019264 learning.py:507] global step 19093: loss = 0.0619 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 19094: loss = 0.0512 (0.340 sec/step)\n",
            "I0923 10:06:06.816321 139631849019264 learning.py:507] global step 19094: loss = 0.0512 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 19095: loss = 0.1293 (0.325 sec/step)\n",
            "I0923 10:06:07.142734 139631849019264 learning.py:507] global step 19095: loss = 0.1293 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 19096: loss = 0.0685 (0.302 sec/step)\n",
            "I0923 10:06:07.446719 139631849019264 learning.py:507] global step 19096: loss = 0.0685 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 19097: loss = 0.1181 (0.344 sec/step)\n",
            "I0923 10:06:07.792786 139631849019264 learning.py:507] global step 19097: loss = 0.1181 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 19098: loss = 0.0398 (0.341 sec/step)\n",
            "I0923 10:06:08.135614 139631849019264 learning.py:507] global step 19098: loss = 0.0398 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 19099: loss = 0.0442 (0.358 sec/step)\n",
            "I0923 10:06:08.495754 139631849019264 learning.py:507] global step 19099: loss = 0.0442 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 19100: loss = 0.0560 (0.322 sec/step)\n",
            "I0923 10:06:08.819623 139631849019264 learning.py:507] global step 19100: loss = 0.0560 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 19101: loss = 0.0251 (0.373 sec/step)\n",
            "I0923 10:06:09.194108 139631849019264 learning.py:507] global step 19101: loss = 0.0251 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 19102: loss = 0.2953 (0.315 sec/step)\n",
            "I0923 10:06:09.510273 139631849019264 learning.py:507] global step 19102: loss = 0.2953 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 19103: loss = 0.1396 (0.322 sec/step)\n",
            "I0923 10:06:09.833890 139631849019264 learning.py:507] global step 19103: loss = 0.1396 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 19104: loss = 0.1371 (0.344 sec/step)\n",
            "I0923 10:06:10.179448 139631849019264 learning.py:507] global step 19104: loss = 0.1371 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 19105: loss = 0.0941 (0.289 sec/step)\n",
            "I0923 10:06:10.472562 139631849019264 learning.py:507] global step 19105: loss = 0.0941 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 19106: loss = 0.1594 (0.359 sec/step)\n",
            "I0923 10:06:10.833699 139631849019264 learning.py:507] global step 19106: loss = 0.1594 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 19107: loss = 0.1362 (0.284 sec/step)\n",
            "I0923 10:06:11.119946 139631849019264 learning.py:507] global step 19107: loss = 0.1362 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19108: loss = 0.1313 (0.301 sec/step)\n",
            "I0923 10:06:11.423107 139631849019264 learning.py:507] global step 19108: loss = 0.1313 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 19109: loss = 0.1180 (0.287 sec/step)\n",
            "I0923 10:06:11.711529 139631849019264 learning.py:507] global step 19109: loss = 0.1180 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 19110: loss = 0.0918 (0.274 sec/step)\n",
            "I0923 10:06:11.987171 139631849019264 learning.py:507] global step 19110: loss = 0.0918 (0.274 sec/step)\n",
            "INFO:tensorflow:global step 19111: loss = 0.2772 (0.303 sec/step)\n",
            "I0923 10:06:12.293316 139631849019264 learning.py:507] global step 19111: loss = 0.2772 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 19112: loss = 0.0455 (0.284 sec/step)\n",
            "I0923 10:06:12.578800 139631849019264 learning.py:507] global step 19112: loss = 0.0455 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19113: loss = 0.0803 (0.274 sec/step)\n",
            "I0923 10:06:12.855020 139631849019264 learning.py:507] global step 19113: loss = 0.0803 (0.274 sec/step)\n",
            "INFO:tensorflow:global step 19114: loss = 0.0397 (0.283 sec/step)\n",
            "I0923 10:06:13.140213 139631849019264 learning.py:507] global step 19114: loss = 0.0397 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 19115: loss = 0.0986 (0.302 sec/step)\n",
            "I0923 10:06:13.444645 139631849019264 learning.py:507] global step 19115: loss = 0.0986 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 19116: loss = 0.1010 (0.297 sec/step)\n",
            "I0923 10:06:13.743960 139631849019264 learning.py:507] global step 19116: loss = 0.1010 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 19117: loss = 0.0984 (0.302 sec/step)\n",
            "I0923 10:06:14.047830 139631849019264 learning.py:507] global step 19117: loss = 0.0984 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 19118: loss = 0.2223 (0.318 sec/step)\n",
            "I0923 10:06:14.367559 139631849019264 learning.py:507] global step 19118: loss = 0.2223 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 19119: loss = 0.0782 (0.297 sec/step)\n",
            "I0923 10:06:14.666080 139631849019264 learning.py:507] global step 19119: loss = 0.0782 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 19120: loss = 0.1158 (0.334 sec/step)\n",
            "I0923 10:06:15.001993 139631849019264 learning.py:507] global step 19120: loss = 0.1158 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 19121: loss = 0.1262 (0.332 sec/step)\n",
            "I0923 10:06:15.336241 139631849019264 learning.py:507] global step 19121: loss = 0.1262 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 19122: loss = 0.0687 (0.335 sec/step)\n",
            "I0923 10:06:15.672773 139631849019264 learning.py:507] global step 19122: loss = 0.0687 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 19123: loss = 0.2096 (0.291 sec/step)\n",
            "I0923 10:06:15.965799 139631849019264 learning.py:507] global step 19123: loss = 0.2096 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 19124: loss = 0.0783 (0.295 sec/step)\n",
            "I0923 10:06:16.262239 139631849019264 learning.py:507] global step 19124: loss = 0.0783 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 19125: loss = 0.0697 (0.284 sec/step)\n",
            "I0923 10:06:16.549421 139631849019264 learning.py:507] global step 19125: loss = 0.0697 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19126: loss = 0.2913 (0.311 sec/step)\n",
            "I0923 10:06:16.863383 139631849019264 learning.py:507] global step 19126: loss = 0.2913 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 19127: loss = 0.0717 (0.346 sec/step)\n",
            "I0923 10:06:17.211266 139631849019264 learning.py:507] global step 19127: loss = 0.0717 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 19128: loss = 0.0723 (0.346 sec/step)\n",
            "I0923 10:06:17.559169 139631849019264 learning.py:507] global step 19128: loss = 0.0723 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 19129: loss = 0.0390 (0.341 sec/step)\n",
            "I0923 10:06:17.902943 139631849019264 learning.py:507] global step 19129: loss = 0.0390 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 19130: loss = 0.0644 (0.483 sec/step)\n",
            "I0923 10:06:18.388217 139631849019264 learning.py:507] global step 19130: loss = 0.0644 (0.483 sec/step)\n",
            "INFO:tensorflow:global step 19131: loss = 0.1327 (0.363 sec/step)\n",
            "I0923 10:06:18.753154 139631849019264 learning.py:507] global step 19131: loss = 0.1327 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 19132: loss = 0.2450 (0.488 sec/step)\n",
            "I0923 10:06:19.263701 139631849019264 learning.py:507] global step 19132: loss = 0.2450 (0.488 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 19132.\n",
            "I0923 10:06:19.328237 139628630939392 supervisor.py:1050] Recording summary at step 19132.\n",
            "INFO:tensorflow:global step 19133: loss = 0.0895 (0.362 sec/step)\n",
            "I0923 10:06:19.627475 139631849019264 learning.py:507] global step 19133: loss = 0.0895 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 19134: loss = 0.0627 (0.297 sec/step)\n",
            "I0923 10:06:19.925860 139631849019264 learning.py:507] global step 19134: loss = 0.0627 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 19135: loss = 0.1111 (0.273 sec/step)\n",
            "I0923 10:06:20.200483 139631849019264 learning.py:507] global step 19135: loss = 0.1111 (0.273 sec/step)\n",
            "INFO:tensorflow:global step 19136: loss = 0.0634 (0.287 sec/step)\n",
            "I0923 10:06:20.489281 139631849019264 learning.py:507] global step 19136: loss = 0.0634 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 19137: loss = 0.1047 (0.350 sec/step)\n",
            "I0923 10:06:20.841440 139631849019264 learning.py:507] global step 19137: loss = 0.1047 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 19138: loss = 0.0873 (0.319 sec/step)\n",
            "I0923 10:06:21.162744 139631849019264 learning.py:507] global step 19138: loss = 0.0873 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 19139: loss = 0.0331 (0.284 sec/step)\n",
            "I0923 10:06:21.448515 139631849019264 learning.py:507] global step 19139: loss = 0.0331 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19140: loss = 0.0463 (0.344 sec/step)\n",
            "I0923 10:06:21.794285 139631849019264 learning.py:507] global step 19140: loss = 0.0463 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 19141: loss = 0.1940 (0.280 sec/step)\n",
            "I0923 10:06:22.076093 139631849019264 learning.py:507] global step 19141: loss = 0.1940 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 19142: loss = 0.0588 (0.319 sec/step)\n",
            "I0923 10:06:22.396865 139631849019264 learning.py:507] global step 19142: loss = 0.0588 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 19143: loss = 0.0736 (0.284 sec/step)\n",
            "I0923 10:06:22.683127 139631849019264 learning.py:507] global step 19143: loss = 0.0736 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19144: loss = 0.0881 (0.310 sec/step)\n",
            "I0923 10:06:22.995263 139631849019264 learning.py:507] global step 19144: loss = 0.0881 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 19145: loss = 0.0677 (0.289 sec/step)\n",
            "I0923 10:06:23.285567 139631849019264 learning.py:507] global step 19145: loss = 0.0677 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 19146: loss = 0.0924 (0.299 sec/step)\n",
            "I0923 10:06:23.586810 139631849019264 learning.py:507] global step 19146: loss = 0.0924 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 19147: loss = 0.0963 (0.301 sec/step)\n",
            "I0923 10:06:23.889303 139631849019264 learning.py:507] global step 19147: loss = 0.0963 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 19148: loss = 0.1411 (0.337 sec/step)\n",
            "I0923 10:06:24.227732 139631849019264 learning.py:507] global step 19148: loss = 0.1411 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 19149: loss = 0.0986 (0.345 sec/step)\n",
            "I0923 10:06:24.575210 139631849019264 learning.py:507] global step 19149: loss = 0.0986 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 19150: loss = 0.0543 (0.302 sec/step)\n",
            "I0923 10:06:24.879203 139631849019264 learning.py:507] global step 19150: loss = 0.0543 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 19151: loss = 0.1455 (0.283 sec/step)\n",
            "I0923 10:06:25.163955 139631849019264 learning.py:507] global step 19151: loss = 0.1455 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 19152: loss = 0.1296 (0.323 sec/step)\n",
            "I0923 10:06:25.489245 139631849019264 learning.py:507] global step 19152: loss = 0.1296 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 19153: loss = 0.1231 (0.285 sec/step)\n",
            "I0923 10:06:25.775802 139631849019264 learning.py:507] global step 19153: loss = 0.1231 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 19154: loss = 0.1366 (0.326 sec/step)\n",
            "I0923 10:06:26.103410 139631849019264 learning.py:507] global step 19154: loss = 0.1366 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 19155: loss = 0.0558 (0.315 sec/step)\n",
            "I0923 10:06:26.420150 139631849019264 learning.py:507] global step 19155: loss = 0.0558 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 19156: loss = 0.0611 (0.364 sec/step)\n",
            "I0923 10:06:26.786468 139631849019264 learning.py:507] global step 19156: loss = 0.0611 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 19157: loss = 0.0662 (0.291 sec/step)\n",
            "I0923 10:06:27.079337 139631849019264 learning.py:507] global step 19157: loss = 0.0662 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 19158: loss = 0.1044 (0.331 sec/step)\n",
            "I0923 10:06:27.412778 139631849019264 learning.py:507] global step 19158: loss = 0.1044 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 19159: loss = 0.1650 (0.296 sec/step)\n",
            "I0923 10:06:27.710978 139631849019264 learning.py:507] global step 19159: loss = 0.1650 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 19160: loss = 0.0630 (0.335 sec/step)\n",
            "I0923 10:06:28.047811 139631849019264 learning.py:507] global step 19160: loss = 0.0630 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 19161: loss = 0.1096 (0.316 sec/step)\n",
            "I0923 10:06:28.365439 139631849019264 learning.py:507] global step 19161: loss = 0.1096 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 19162: loss = 0.0581 (0.286 sec/step)\n",
            "I0923 10:06:28.652908 139631849019264 learning.py:507] global step 19162: loss = 0.0581 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 19163: loss = 0.1206 (0.305 sec/step)\n",
            "I0923 10:06:28.959507 139631849019264 learning.py:507] global step 19163: loss = 0.1206 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 19164: loss = 0.0632 (0.286 sec/step)\n",
            "I0923 10:06:29.247483 139631849019264 learning.py:507] global step 19164: loss = 0.0632 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 19165: loss = 0.0482 (0.297 sec/step)\n",
            "I0923 10:06:29.546414 139631849019264 learning.py:507] global step 19165: loss = 0.0482 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 19166: loss = 0.1340 (0.336 sec/step)\n",
            "I0923 10:06:29.884308 139631849019264 learning.py:507] global step 19166: loss = 0.1340 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 19167: loss = 0.0672 (0.335 sec/step)\n",
            "I0923 10:06:30.220981 139631849019264 learning.py:507] global step 19167: loss = 0.0672 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 19168: loss = 0.1153 (0.323 sec/step)\n",
            "I0923 10:06:30.546090 139631849019264 learning.py:507] global step 19168: loss = 0.1153 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 19169: loss = 0.0396 (0.334 sec/step)\n",
            "I0923 10:06:30.881831 139631849019264 learning.py:507] global step 19169: loss = 0.0396 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 19170: loss = 0.1513 (0.331 sec/step)\n",
            "I0923 10:06:31.214313 139631849019264 learning.py:507] global step 19170: loss = 0.1513 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 19171: loss = 0.1162 (0.297 sec/step)\n",
            "I0923 10:06:31.513504 139631849019264 learning.py:507] global step 19171: loss = 0.1162 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 19172: loss = 0.0937 (0.294 sec/step)\n",
            "I0923 10:06:31.809231 139631849019264 learning.py:507] global step 19172: loss = 0.0937 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 19173: loss = 0.2175 (0.320 sec/step)\n",
            "I0923 10:06:32.130796 139631849019264 learning.py:507] global step 19173: loss = 0.2175 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19174: loss = 0.1801 (0.279 sec/step)\n",
            "I0923 10:06:32.411698 139631849019264 learning.py:507] global step 19174: loss = 0.1801 (0.279 sec/step)\n",
            "INFO:tensorflow:global step 19175: loss = 0.0989 (0.273 sec/step)\n",
            "I0923 10:06:32.686285 139631849019264 learning.py:507] global step 19175: loss = 0.0989 (0.273 sec/step)\n",
            "INFO:tensorflow:global step 19176: loss = 0.1253 (0.281 sec/step)\n",
            "I0923 10:06:32.968614 139631849019264 learning.py:507] global step 19176: loss = 0.1253 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 19177: loss = 0.1178 (0.296 sec/step)\n",
            "I0923 10:06:33.266252 139631849019264 learning.py:507] global step 19177: loss = 0.1178 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 19178: loss = 0.2208 (0.293 sec/step)\n",
            "I0923 10:06:33.560818 139631849019264 learning.py:507] global step 19178: loss = 0.2208 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 19179: loss = 0.0980 (0.327 sec/step)\n",
            "I0923 10:06:33.889978 139631849019264 learning.py:507] global step 19179: loss = 0.0980 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19180: loss = 0.1231 (0.356 sec/step)\n",
            "I0923 10:06:34.247668 139631849019264 learning.py:507] global step 19180: loss = 0.1231 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 19181: loss = 0.1358 (0.276 sec/step)\n",
            "I0923 10:06:34.525667 139631849019264 learning.py:507] global step 19181: loss = 0.1358 (0.276 sec/step)\n",
            "INFO:tensorflow:global step 19182: loss = 0.1521 (0.293 sec/step)\n",
            "I0923 10:06:34.820761 139631849019264 learning.py:507] global step 19182: loss = 0.1521 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 19183: loss = 0.0541 (0.349 sec/step)\n",
            "I0923 10:06:35.171407 139631849019264 learning.py:507] global step 19183: loss = 0.0541 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 19184: loss = 0.0380 (0.310 sec/step)\n",
            "I0923 10:06:35.483163 139631849019264 learning.py:507] global step 19184: loss = 0.0380 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 19185: loss = 0.0657 (0.278 sec/step)\n",
            "I0923 10:06:35.762949 139631849019264 learning.py:507] global step 19185: loss = 0.0657 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 19186: loss = 0.1185 (0.334 sec/step)\n",
            "I0923 10:06:36.098347 139631849019264 learning.py:507] global step 19186: loss = 0.1185 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 19187: loss = 0.0533 (0.316 sec/step)\n",
            "I0923 10:06:36.415969 139631849019264 learning.py:507] global step 19187: loss = 0.0533 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 19188: loss = 0.2264 (0.294 sec/step)\n",
            "I0923 10:06:36.711619 139631849019264 learning.py:507] global step 19188: loss = 0.2264 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 19189: loss = 0.0985 (0.293 sec/step)\n",
            "I0923 10:06:37.006529 139631849019264 learning.py:507] global step 19189: loss = 0.0985 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 19190: loss = 0.0988 (0.340 sec/step)\n",
            "I0923 10:06:37.347785 139631849019264 learning.py:507] global step 19190: loss = 0.0988 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 19191: loss = 0.1094 (0.316 sec/step)\n",
            "I0923 10:06:37.666264 139631849019264 learning.py:507] global step 19191: loss = 0.1094 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 19192: loss = 0.1376 (0.326 sec/step)\n",
            "I0923 10:06:37.994291 139631849019264 learning.py:507] global step 19192: loss = 0.1376 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 19193: loss = 0.0584 (0.295 sec/step)\n",
            "I0923 10:06:38.290688 139631849019264 learning.py:507] global step 19193: loss = 0.0584 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 19194: loss = 0.0532 (0.326 sec/step)\n",
            "I0923 10:06:38.618852 139631849019264 learning.py:507] global step 19194: loss = 0.0532 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 19195: loss = 0.0944 (0.294 sec/step)\n",
            "I0923 10:06:38.914971 139631849019264 learning.py:507] global step 19195: loss = 0.0944 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 19196: loss = 0.0703 (0.343 sec/step)\n",
            "I0923 10:06:39.261006 139631849019264 learning.py:507] global step 19196: loss = 0.0703 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 19197: loss = 0.0865 (0.315 sec/step)\n",
            "I0923 10:06:39.577413 139631849019264 learning.py:507] global step 19197: loss = 0.0865 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 19198: loss = 0.0754 (0.353 sec/step)\n",
            "I0923 10:06:39.932094 139631849019264 learning.py:507] global step 19198: loss = 0.0754 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 19199: loss = 0.1560 (0.293 sec/step)\n",
            "I0923 10:06:40.226493 139631849019264 learning.py:507] global step 19199: loss = 0.1560 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 19200: loss = 0.1499 (0.308 sec/step)\n",
            "I0923 10:06:40.535947 139631849019264 learning.py:507] global step 19200: loss = 0.1499 (0.308 sec/step)\n",
            "INFO:tensorflow:global step 19201: loss = 0.0522 (0.302 sec/step)\n",
            "I0923 10:06:40.839116 139631849019264 learning.py:507] global step 19201: loss = 0.0522 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 19202: loss = 0.1011 (0.327 sec/step)\n",
            "I0923 10:06:41.167675 139631849019264 learning.py:507] global step 19202: loss = 0.1011 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19203: loss = 0.1810 (0.334 sec/step)\n",
            "I0923 10:06:41.503342 139631849019264 learning.py:507] global step 19203: loss = 0.1810 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 19204: loss = 0.1596 (0.308 sec/step)\n",
            "I0923 10:06:41.813487 139631849019264 learning.py:507] global step 19204: loss = 0.1596 (0.308 sec/step)\n",
            "INFO:tensorflow:global step 19205: loss = 0.0555 (0.279 sec/step)\n",
            "I0923 10:06:42.094529 139631849019264 learning.py:507] global step 19205: loss = 0.0555 (0.279 sec/step)\n",
            "INFO:tensorflow:global step 19206: loss = 0.0970 (0.316 sec/step)\n",
            "I0923 10:06:42.412897 139631849019264 learning.py:507] global step 19206: loss = 0.0970 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 19207: loss = 0.0746 (0.358 sec/step)\n",
            "I0923 10:06:42.773092 139631849019264 learning.py:507] global step 19207: loss = 0.0746 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 19208: loss = 0.0594 (0.304 sec/step)\n",
            "I0923 10:06:43.078745 139631849019264 learning.py:507] global step 19208: loss = 0.0594 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 19209: loss = 0.0775 (0.318 sec/step)\n",
            "I0923 10:06:43.398879 139631849019264 learning.py:507] global step 19209: loss = 0.0775 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 19210: loss = 0.0582 (0.330 sec/step)\n",
            "I0923 10:06:43.731111 139631849019264 learning.py:507] global step 19210: loss = 0.0582 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 19211: loss = 0.1049 (0.323 sec/step)\n",
            "I0923 10:06:44.055640 139631849019264 learning.py:507] global step 19211: loss = 0.1049 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 19212: loss = 0.3763 (0.306 sec/step)\n",
            "I0923 10:06:44.363512 139631849019264 learning.py:507] global step 19212: loss = 0.3763 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 19213: loss = 0.1789 (0.313 sec/step)\n",
            "I0923 10:06:44.678352 139631849019264 learning.py:507] global step 19213: loss = 0.1789 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 19214: loss = 0.1070 (0.361 sec/step)\n",
            "I0923 10:06:45.041027 139631849019264 learning.py:507] global step 19214: loss = 0.1070 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 19215: loss = 0.1703 (0.311 sec/step)\n",
            "I0923 10:06:45.354241 139631849019264 learning.py:507] global step 19215: loss = 0.1703 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 19216: loss = 0.1292 (0.316 sec/step)\n",
            "I0923 10:06:45.672343 139631849019264 learning.py:507] global step 19216: loss = 0.1292 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 19217: loss = 0.1361 (0.326 sec/step)\n",
            "I0923 10:06:46.002305 139631849019264 learning.py:507] global step 19217: loss = 0.1361 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 19218: loss = 0.0899 (0.328 sec/step)\n",
            "I0923 10:06:46.331811 139631849019264 learning.py:507] global step 19218: loss = 0.0899 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 19219: loss = 0.0628 (0.295 sec/step)\n",
            "I0923 10:06:46.629087 139631849019264 learning.py:507] global step 19219: loss = 0.0628 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 19220: loss = 0.0769 (0.296 sec/step)\n",
            "I0923 10:06:46.927184 139631849019264 learning.py:507] global step 19220: loss = 0.0769 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 19221: loss = 0.1873 (0.291 sec/step)\n",
            "I0923 10:06:47.220143 139631849019264 learning.py:507] global step 19221: loss = 0.1873 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 19222: loss = 0.1735 (0.429 sec/step)\n",
            "I0923 10:06:47.650745 139631849019264 learning.py:507] global step 19222: loss = 0.1735 (0.429 sec/step)\n",
            "INFO:tensorflow:global step 19223: loss = 0.2906 (0.304 sec/step)\n",
            "I0923 10:06:47.956368 139631849019264 learning.py:507] global step 19223: loss = 0.2906 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 19224: loss = 0.2126 (0.316 sec/step)\n",
            "I0923 10:06:48.274334 139631849019264 learning.py:507] global step 19224: loss = 0.2126 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 19225: loss = 0.0637 (0.336 sec/step)\n",
            "I0923 10:06:48.611996 139631849019264 learning.py:507] global step 19225: loss = 0.0637 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 19226: loss = 0.1226 (0.359 sec/step)\n",
            "I0923 10:06:48.972458 139631849019264 learning.py:507] global step 19226: loss = 0.1226 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 19227: loss = 0.0502 (0.340 sec/step)\n",
            "I0923 10:06:49.314299 139631849019264 learning.py:507] global step 19227: loss = 0.0502 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 19228: loss = 0.0982 (0.309 sec/step)\n",
            "I0923 10:06:49.625142 139631849019264 learning.py:507] global step 19228: loss = 0.0982 (0.309 sec/step)\n",
            "INFO:tensorflow:global step 19229: loss = 0.1494 (0.329 sec/step)\n",
            "I0923 10:06:49.955592 139631849019264 learning.py:507] global step 19229: loss = 0.1494 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 19230: loss = 0.0443 (0.357 sec/step)\n",
            "I0923 10:06:50.314445 139631849019264 learning.py:507] global step 19230: loss = 0.0443 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 19231: loss = 0.1950 (0.354 sec/step)\n",
            "I0923 10:06:50.670470 139631849019264 learning.py:507] global step 19231: loss = 0.1950 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 19232: loss = 0.1992 (0.328 sec/step)\n",
            "I0923 10:06:51.000725 139631849019264 learning.py:507] global step 19232: loss = 0.1992 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 19233: loss = 0.0537 (0.303 sec/step)\n",
            "I0923 10:06:51.306607 139631849019264 learning.py:507] global step 19233: loss = 0.0537 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 19234: loss = 0.0351 (0.313 sec/step)\n",
            "I0923 10:06:51.622080 139631849019264 learning.py:507] global step 19234: loss = 0.0351 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 19235: loss = 0.0857 (0.288 sec/step)\n",
            "I0923 10:06:51.911638 139631849019264 learning.py:507] global step 19235: loss = 0.0857 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 19236: loss = 0.0911 (0.299 sec/step)\n",
            "I0923 10:06:52.212731 139631849019264 learning.py:507] global step 19236: loss = 0.0911 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 19237: loss = 0.1367 (0.327 sec/step)\n",
            "I0923 10:06:52.541286 139631849019264 learning.py:507] global step 19237: loss = 0.1367 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19238: loss = 0.0368 (0.326 sec/step)\n",
            "I0923 10:06:52.869749 139631849019264 learning.py:507] global step 19238: loss = 0.0368 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 19239: loss = 0.0657 (0.334 sec/step)\n",
            "I0923 10:06:53.205544 139631849019264 learning.py:507] global step 19239: loss = 0.0657 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 19240: loss = 0.1191 (0.328 sec/step)\n",
            "I0923 10:06:53.535337 139631849019264 learning.py:507] global step 19240: loss = 0.1191 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 19241: loss = 0.0884 (0.343 sec/step)\n",
            "I0923 10:06:53.880101 139631849019264 learning.py:507] global step 19241: loss = 0.0884 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 19242: loss = 0.0828 (0.317 sec/step)\n",
            "I0923 10:06:54.199130 139631849019264 learning.py:507] global step 19242: loss = 0.0828 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 19243: loss = 0.1722 (0.334 sec/step)\n",
            "I0923 10:06:54.534473 139631849019264 learning.py:507] global step 19243: loss = 0.1722 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 19244: loss = 0.0524 (0.302 sec/step)\n",
            "I0923 10:06:54.838032 139631849019264 learning.py:507] global step 19244: loss = 0.0524 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 19245: loss = 0.0919 (0.337 sec/step)\n",
            "I0923 10:06:55.176362 139631849019264 learning.py:507] global step 19245: loss = 0.0919 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 19246: loss = 0.0427 (0.297 sec/step)\n",
            "I0923 10:06:55.475413 139631849019264 learning.py:507] global step 19246: loss = 0.0427 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 19247: loss = 0.0753 (0.328 sec/step)\n",
            "I0923 10:06:55.806832 139631849019264 learning.py:507] global step 19247: loss = 0.0753 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 19248: loss = 0.0568 (0.320 sec/step)\n",
            "I0923 10:06:56.128378 139631849019264 learning.py:507] global step 19248: loss = 0.0568 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19249: loss = 0.1200 (0.320 sec/step)\n",
            "I0923 10:06:56.450462 139631849019264 learning.py:507] global step 19249: loss = 0.1200 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19250: loss = 0.0779 (0.312 sec/step)\n",
            "I0923 10:06:56.764127 139631849019264 learning.py:507] global step 19250: loss = 0.0779 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 19251: loss = 0.0538 (0.349 sec/step)\n",
            "I0923 10:06:57.114887 139631849019264 learning.py:507] global step 19251: loss = 0.0538 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 19252: loss = 0.4662 (0.345 sec/step)\n",
            "I0923 10:06:57.462562 139631849019264 learning.py:507] global step 19252: loss = 0.4662 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 19253: loss = 0.0656 (0.297 sec/step)\n",
            "I0923 10:06:57.761981 139631849019264 learning.py:507] global step 19253: loss = 0.0656 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 19254: loss = 0.1523 (0.298 sec/step)\n",
            "I0923 10:06:58.062146 139631849019264 learning.py:507] global step 19254: loss = 0.1523 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 19255: loss = 0.1046 (0.299 sec/step)\n",
            "I0923 10:06:58.362836 139631849019264 learning.py:507] global step 19255: loss = 0.1046 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 19256: loss = 0.0681 (0.308 sec/step)\n",
            "I0923 10:06:58.672656 139631849019264 learning.py:507] global step 19256: loss = 0.0681 (0.308 sec/step)\n",
            "INFO:tensorflow:global step 19257: loss = 0.0730 (0.294 sec/step)\n",
            "I0923 10:06:58.968977 139631849019264 learning.py:507] global step 19257: loss = 0.0730 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 19258: loss = 0.0717 (0.323 sec/step)\n",
            "I0923 10:06:59.296100 139631849019264 learning.py:507] global step 19258: loss = 0.0717 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 19259: loss = 0.0333 (0.274 sec/step)\n",
            "I0923 10:06:59.571647 139631849019264 learning.py:507] global step 19259: loss = 0.0333 (0.274 sec/step)\n",
            "INFO:tensorflow:global step 19260: loss = 0.2126 (0.339 sec/step)\n",
            "I0923 10:06:59.912030 139631849019264 learning.py:507] global step 19260: loss = 0.2126 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 19261: loss = 0.1114 (0.296 sec/step)\n",
            "I0923 10:07:00.209932 139631849019264 learning.py:507] global step 19261: loss = 0.1114 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 19262: loss = 0.1035 (0.318 sec/step)\n",
            "I0923 10:07:00.529296 139631849019264 learning.py:507] global step 19262: loss = 0.1035 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 19263: loss = 0.1096 (0.356 sec/step)\n",
            "I0923 10:07:00.887020 139631849019264 learning.py:507] global step 19263: loss = 0.1096 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 19264: loss = 0.1251 (0.405 sec/step)\n",
            "I0923 10:07:01.294223 139631849019264 learning.py:507] global step 19264: loss = 0.1251 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 19265: loss = 0.1198 (0.277 sec/step)\n",
            "I0923 10:07:01.573178 139631849019264 learning.py:507] global step 19265: loss = 0.1198 (0.277 sec/step)\n",
            "INFO:tensorflow:global step 19266: loss = 0.1272 (0.327 sec/step)\n",
            "I0923 10:07:01.902209 139631849019264 learning.py:507] global step 19266: loss = 0.1272 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19267: loss = 0.0799 (0.325 sec/step)\n",
            "I0923 10:07:02.229141 139631849019264 learning.py:507] global step 19267: loss = 0.0799 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 19268: loss = 0.0311 (0.301 sec/step)\n",
            "I0923 10:07:02.531730 139631849019264 learning.py:507] global step 19268: loss = 0.0311 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 19269: loss = 0.1442 (0.356 sec/step)\n",
            "I0923 10:07:02.889656 139631849019264 learning.py:507] global step 19269: loss = 0.1442 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 19270: loss = 0.0445 (0.338 sec/step)\n",
            "I0923 10:07:03.229799 139631849019264 learning.py:507] global step 19270: loss = 0.0445 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 19271: loss = 0.0646 (0.284 sec/step)\n",
            "I0923 10:07:03.515022 139631849019264 learning.py:507] global step 19271: loss = 0.0646 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19272: loss = 0.0402 (0.328 sec/step)\n",
            "I0923 10:07:03.845227 139631849019264 learning.py:507] global step 19272: loss = 0.0402 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 19273: loss = 0.0355 (0.363 sec/step)\n",
            "I0923 10:07:04.209985 139631849019264 learning.py:507] global step 19273: loss = 0.0355 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 19274: loss = 0.1244 (0.328 sec/step)\n",
            "I0923 10:07:04.540300 139631849019264 learning.py:507] global step 19274: loss = 0.1244 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 19275: loss = 0.0631 (0.317 sec/step)\n",
            "I0923 10:07:04.859128 139631849019264 learning.py:507] global step 19275: loss = 0.0631 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 19276: loss = 0.0645 (0.296 sec/step)\n",
            "I0923 10:07:05.157168 139631849019264 learning.py:507] global step 19276: loss = 0.0645 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 19277: loss = 0.1066 (0.308 sec/step)\n",
            "I0923 10:07:05.467890 139631849019264 learning.py:507] global step 19277: loss = 0.1066 (0.308 sec/step)\n",
            "INFO:tensorflow:global step 19278: loss = 0.0560 (0.326 sec/step)\n",
            "I0923 10:07:05.796324 139631849019264 learning.py:507] global step 19278: loss = 0.0560 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 19279: loss = 0.0379 (0.297 sec/step)\n",
            "I0923 10:07:06.096105 139631849019264 learning.py:507] global step 19279: loss = 0.0379 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 19280: loss = 0.0317 (0.332 sec/step)\n",
            "I0923 10:07:06.430152 139631849019264 learning.py:507] global step 19280: loss = 0.0317 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 19281: loss = 0.0986 (0.327 sec/step)\n",
            "I0923 10:07:06.759595 139631849019264 learning.py:507] global step 19281: loss = 0.0986 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19282: loss = 0.0810 (0.315 sec/step)\n",
            "I0923 10:07:07.076944 139631849019264 learning.py:507] global step 19282: loss = 0.0810 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 19283: loss = 0.0928 (0.294 sec/step)\n",
            "I0923 10:07:07.373477 139631849019264 learning.py:507] global step 19283: loss = 0.0928 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 19284: loss = 0.1166 (0.294 sec/step)\n",
            "I0923 10:07:07.669755 139631849019264 learning.py:507] global step 19284: loss = 0.1166 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 19285: loss = 0.0446 (0.291 sec/step)\n",
            "I0923 10:07:07.962797 139631849019264 learning.py:507] global step 19285: loss = 0.0446 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 19286: loss = 0.1385 (0.343 sec/step)\n",
            "I0923 10:07:08.308323 139631849019264 learning.py:507] global step 19286: loss = 0.1385 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 19287: loss = 0.0642 (0.292 sec/step)\n",
            "I0923 10:07:08.602050 139631849019264 learning.py:507] global step 19287: loss = 0.0642 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19288: loss = 0.0571 (0.290 sec/step)\n",
            "I0923 10:07:08.893944 139631849019264 learning.py:507] global step 19288: loss = 0.0571 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 19289: loss = 0.0821 (0.315 sec/step)\n",
            "I0923 10:07:09.211247 139631849019264 learning.py:507] global step 19289: loss = 0.0821 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 19290: loss = 0.1036 (0.318 sec/step)\n",
            "I0923 10:07:09.531732 139631849019264 learning.py:507] global step 19290: loss = 0.1036 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 19291: loss = 0.0627 (0.325 sec/step)\n",
            "I0923 10:07:09.859482 139631849019264 learning.py:507] global step 19291: loss = 0.0627 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 19292: loss = 0.0218 (0.335 sec/step)\n",
            "I0923 10:07:10.195891 139631849019264 learning.py:507] global step 19292: loss = 0.0218 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 19293: loss = 0.0825 (0.327 sec/step)\n",
            "I0923 10:07:10.524668 139631849019264 learning.py:507] global step 19293: loss = 0.0825 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19294: loss = 0.1942 (0.325 sec/step)\n",
            "I0923 10:07:10.851042 139631849019264 learning.py:507] global step 19294: loss = 0.1942 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 19295: loss = 0.0330 (0.320 sec/step)\n",
            "I0923 10:07:11.173148 139631849019264 learning.py:507] global step 19295: loss = 0.0330 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19296: loss = 0.0304 (0.297 sec/step)\n",
            "I0923 10:07:11.472393 139631849019264 learning.py:507] global step 19296: loss = 0.0304 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 19297: loss = 0.1606 (0.299 sec/step)\n",
            "I0923 10:07:11.772839 139631849019264 learning.py:507] global step 19297: loss = 0.1606 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 19298: loss = 0.1262 (0.278 sec/step)\n",
            "I0923 10:07:12.053390 139631849019264 learning.py:507] global step 19298: loss = 0.1262 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 19299: loss = 0.0683 (0.348 sec/step)\n",
            "I0923 10:07:12.404001 139631849019264 learning.py:507] global step 19299: loss = 0.0683 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 19300: loss = 0.1736 (0.329 sec/step)\n",
            "I0923 10:07:12.735380 139631849019264 learning.py:507] global step 19300: loss = 0.1736 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 19301: loss = 0.0549 (0.306 sec/step)\n",
            "I0923 10:07:13.043418 139631849019264 learning.py:507] global step 19301: loss = 0.0549 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 19302: loss = 0.1134 (0.364 sec/step)\n",
            "I0923 10:07:13.409801 139631849019264 learning.py:507] global step 19302: loss = 0.1134 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 19303: loss = 0.0730 (0.322 sec/step)\n",
            "I0923 10:07:13.733020 139631849019264 learning.py:507] global step 19303: loss = 0.0730 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 19304: loss = 0.0980 (0.395 sec/step)\n",
            "I0923 10:07:14.129639 139631849019264 learning.py:507] global step 19304: loss = 0.0980 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 19305: loss = 0.0854 (0.314 sec/step)\n",
            "I0923 10:07:14.446246 139631849019264 learning.py:507] global step 19305: loss = 0.0854 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 19306: loss = 0.1258 (0.320 sec/step)\n",
            "I0923 10:07:14.768348 139631849019264 learning.py:507] global step 19306: loss = 0.1258 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19307: loss = 0.0502 (0.275 sec/step)\n",
            "I0923 10:07:15.045479 139631849019264 learning.py:507] global step 19307: loss = 0.0502 (0.275 sec/step)\n",
            "INFO:tensorflow:global step 19308: loss = 0.0819 (0.319 sec/step)\n",
            "I0923 10:07:15.368232 139631849019264 learning.py:507] global step 19308: loss = 0.0819 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 19309: loss = 0.1597 (0.366 sec/step)\n",
            "I0923 10:07:15.736271 139631849019264 learning.py:507] global step 19309: loss = 0.1597 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 19310: loss = 0.1203 (0.281 sec/step)\n",
            "I0923 10:07:16.019254 139631849019264 learning.py:507] global step 19310: loss = 0.1203 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 19311: loss = 0.0921 (0.294 sec/step)\n",
            "I0923 10:07:16.315087 139631849019264 learning.py:507] global step 19311: loss = 0.0921 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 19312: loss = 0.1131 (0.305 sec/step)\n",
            "I0923 10:07:16.622308 139631849019264 learning.py:507] global step 19312: loss = 0.1131 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 19313: loss = 0.0654 (0.332 sec/step)\n",
            "I0923 10:07:16.955832 139631849019264 learning.py:507] global step 19313: loss = 0.0654 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 19314: loss = 0.0947 (0.291 sec/step)\n",
            "I0923 10:07:17.248602 139631849019264 learning.py:507] global step 19314: loss = 0.0947 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 19315: loss = 0.0631 (0.308 sec/step)\n",
            "I0923 10:07:17.558010 139631849019264 learning.py:507] global step 19315: loss = 0.0631 (0.308 sec/step)\n",
            "INFO:tensorflow:global step 19316: loss = 0.0604 (0.327 sec/step)\n",
            "I0923 10:07:17.887011 139631849019264 learning.py:507] global step 19316: loss = 0.0604 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19317: loss = 0.3211 (0.313 sec/step)\n",
            "I0923 10:07:18.201851 139631849019264 learning.py:507] global step 19317: loss = 0.3211 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 19318: loss = 0.0654 (0.282 sec/step)\n",
            "I0923 10:07:18.486158 139631849019264 learning.py:507] global step 19318: loss = 0.0654 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 19319: loss = 0.0941 (0.288 sec/step)\n",
            "I0923 10:07:18.777275 139631849019264 learning.py:507] global step 19319: loss = 0.0941 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 19320: loss = 0.1753 (0.315 sec/step)\n",
            "I0923 10:07:19.093705 139631849019264 learning.py:507] global step 19320: loss = 0.1753 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 19321: loss = 0.0572 (0.283 sec/step)\n",
            "I0923 10:07:19.379162 139631849019264 learning.py:507] global step 19321: loss = 0.0572 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 19322: loss = 0.1125 (0.288 sec/step)\n",
            "I0923 10:07:19.669242 139631849019264 learning.py:507] global step 19322: loss = 0.1125 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 19323: loss = 0.1255 (0.316 sec/step)\n",
            "I0923 10:07:19.987683 139631849019264 learning.py:507] global step 19323: loss = 0.1255 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 19324: loss = 0.0825 (0.315 sec/step)\n",
            "I0923 10:07:20.304421 139631849019264 learning.py:507] global step 19324: loss = 0.0825 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 19325: loss = 0.0238 (0.301 sec/step)\n",
            "I0923 10:07:20.608228 139631849019264 learning.py:507] global step 19325: loss = 0.0238 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 19326: loss = 0.0558 (0.285 sec/step)\n",
            "I0923 10:07:20.895853 139631849019264 learning.py:507] global step 19326: loss = 0.0558 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 19327: loss = 0.0547 (0.284 sec/step)\n",
            "I0923 10:07:21.181257 139631849019264 learning.py:507] global step 19327: loss = 0.0547 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19328: loss = 0.1099 (0.361 sec/step)\n",
            "I0923 10:07:21.543918 139631849019264 learning.py:507] global step 19328: loss = 0.1099 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 19329: loss = 0.1229 (0.349 sec/step)\n",
            "I0923 10:07:21.895048 139631849019264 learning.py:507] global step 19329: loss = 0.1229 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 19330: loss = 0.1721 (0.334 sec/step)\n",
            "I0923 10:07:22.231087 139631849019264 learning.py:507] global step 19330: loss = 0.1721 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 19331: loss = 0.1407 (0.327 sec/step)\n",
            "I0923 10:07:22.559558 139631849019264 learning.py:507] global step 19331: loss = 0.1407 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19332: loss = 0.1420 (0.307 sec/step)\n",
            "I0923 10:07:22.868404 139631849019264 learning.py:507] global step 19332: loss = 0.1420 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 19333: loss = 0.1108 (0.341 sec/step)\n",
            "I0923 10:07:23.210956 139631849019264 learning.py:507] global step 19333: loss = 0.1108 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 19334: loss = 0.2017 (0.283 sec/step)\n",
            "I0923 10:07:23.495416 139631849019264 learning.py:507] global step 19334: loss = 0.2017 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 19335: loss = 0.1087 (0.297 sec/step)\n",
            "I0923 10:07:23.794243 139631849019264 learning.py:507] global step 19335: loss = 0.1087 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 19336: loss = 0.1523 (0.271 sec/step)\n",
            "I0923 10:07:24.067109 139631849019264 learning.py:507] global step 19336: loss = 0.1523 (0.271 sec/step)\n",
            "INFO:tensorflow:global step 19337: loss = 0.0907 (0.282 sec/step)\n",
            "I0923 10:07:24.351469 139631849019264 learning.py:507] global step 19337: loss = 0.0907 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 19338: loss = 0.1095 (0.316 sec/step)\n",
            "I0923 10:07:24.669163 139631849019264 learning.py:507] global step 19338: loss = 0.1095 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 19339: loss = 0.2184 (0.286 sec/step)\n",
            "I0923 10:07:24.957038 139631849019264 learning.py:507] global step 19339: loss = 0.2184 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 19340: loss = 0.1439 (0.321 sec/step)\n",
            "I0923 10:07:25.279769 139631849019264 learning.py:507] global step 19340: loss = 0.1439 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 19341: loss = 0.0826 (0.297 sec/step)\n",
            "I0923 10:07:25.578250 139631849019264 learning.py:507] global step 19341: loss = 0.0826 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 19342: loss = 0.1828 (0.306 sec/step)\n",
            "I0923 10:07:25.886160 139631849019264 learning.py:507] global step 19342: loss = 0.1828 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 19343: loss = 0.0790 (0.288 sec/step)\n",
            "I0923 10:07:26.176290 139631849019264 learning.py:507] global step 19343: loss = 0.0790 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 19344: loss = 0.0731 (0.284 sec/step)\n",
            "I0923 10:07:26.462146 139631849019264 learning.py:507] global step 19344: loss = 0.0731 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19345: loss = 0.0325 (0.303 sec/step)\n",
            "I0923 10:07:26.768028 139631849019264 learning.py:507] global step 19345: loss = 0.0325 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 19346: loss = 0.0601 (0.290 sec/step)\n",
            "I0923 10:07:27.062761 139631849019264 learning.py:507] global step 19346: loss = 0.0601 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 19347: loss = 0.0499 (0.285 sec/step)\n",
            "I0923 10:07:27.350399 139631849019264 learning.py:507] global step 19347: loss = 0.0499 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 19348: loss = 0.0910 (0.331 sec/step)\n",
            "I0923 10:07:27.683349 139631849019264 learning.py:507] global step 19348: loss = 0.0910 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 19349: loss = 0.0558 (0.274 sec/step)\n",
            "I0923 10:07:27.958992 139631849019264 learning.py:507] global step 19349: loss = 0.0558 (0.274 sec/step)\n",
            "INFO:tensorflow:global step 19350: loss = 0.1756 (0.286 sec/step)\n",
            "I0923 10:07:28.246920 139631849019264 learning.py:507] global step 19350: loss = 0.1756 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 19351: loss = 0.1004 (0.333 sec/step)\n",
            "I0923 10:07:28.581197 139631849019264 learning.py:507] global step 19351: loss = 0.1004 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 19352: loss = 0.0760 (0.310 sec/step)\n",
            "I0923 10:07:28.892779 139631849019264 learning.py:507] global step 19352: loss = 0.0760 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 19353: loss = 0.1247 (0.334 sec/step)\n",
            "I0923 10:07:29.228440 139631849019264 learning.py:507] global step 19353: loss = 0.1247 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 19354: loss = 0.0556 (0.283 sec/step)\n",
            "I0923 10:07:29.513012 139631849019264 learning.py:507] global step 19354: loss = 0.0556 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 19355: loss = 0.1116 (0.319 sec/step)\n",
            "I0923 10:07:29.834374 139631849019264 learning.py:507] global step 19355: loss = 0.1116 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 19356: loss = 0.0564 (0.293 sec/step)\n",
            "I0923 10:07:30.130940 139631849019264 learning.py:507] global step 19356: loss = 0.0564 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 19357: loss = 0.0798 (0.329 sec/step)\n",
            "I0923 10:07:30.461410 139631849019264 learning.py:507] global step 19357: loss = 0.0798 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 19358: loss = 0.3954 (0.306 sec/step)\n",
            "I0923 10:07:30.769509 139631849019264 learning.py:507] global step 19358: loss = 0.3954 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 19359: loss = 0.1165 (0.340 sec/step)\n",
            "I0923 10:07:31.111051 139631849019264 learning.py:507] global step 19359: loss = 0.1165 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 19360: loss = 0.0745 (0.288 sec/step)\n",
            "I0923 10:07:31.400266 139631849019264 learning.py:507] global step 19360: loss = 0.0745 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 19361: loss = 0.0727 (0.347 sec/step)\n",
            "I0923 10:07:31.749184 139631849019264 learning.py:507] global step 19361: loss = 0.0727 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 19362: loss = 0.0540 (0.338 sec/step)\n",
            "I0923 10:07:32.089340 139631849019264 learning.py:507] global step 19362: loss = 0.0540 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 19363: loss = 0.0474 (0.359 sec/step)\n",
            "I0923 10:07:32.450430 139631849019264 learning.py:507] global step 19363: loss = 0.0474 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 19364: loss = 0.1634 (0.315 sec/step)\n",
            "I0923 10:07:32.767466 139631849019264 learning.py:507] global step 19364: loss = 0.1634 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 19365: loss = 0.0621 (0.292 sec/step)\n",
            "I0923 10:07:33.061980 139631849019264 learning.py:507] global step 19365: loss = 0.0621 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19366: loss = 0.1645 (0.320 sec/step)\n",
            "I0923 10:07:33.384398 139631849019264 learning.py:507] global step 19366: loss = 0.1645 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19367: loss = 0.0859 (0.287 sec/step)\n",
            "I0923 10:07:33.673018 139631849019264 learning.py:507] global step 19367: loss = 0.0859 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 19368: loss = 0.0883 (0.335 sec/step)\n",
            "I0923 10:07:34.009483 139631849019264 learning.py:507] global step 19368: loss = 0.0883 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 19369: loss = 0.0432 (0.292 sec/step)\n",
            "I0923 10:07:34.303954 139631849019264 learning.py:507] global step 19369: loss = 0.0432 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19370: loss = 0.1073 (0.369 sec/step)\n",
            "I0923 10:07:34.675187 139631849019264 learning.py:507] global step 19370: loss = 0.1073 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 19371: loss = 0.0400 (0.323 sec/step)\n",
            "I0923 10:07:34.999976 139631849019264 learning.py:507] global step 19371: loss = 0.0400 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 19372: loss = 0.0743 (0.305 sec/step)\n",
            "I0923 10:07:35.307322 139631849019264 learning.py:507] global step 19372: loss = 0.0743 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 19373: loss = 0.0831 (0.321 sec/step)\n",
            "I0923 10:07:35.630424 139631849019264 learning.py:507] global step 19373: loss = 0.0831 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 19374: loss = 0.0411 (0.330 sec/step)\n",
            "I0923 10:07:35.962583 139631849019264 learning.py:507] global step 19374: loss = 0.0411 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 19375: loss = 0.0861 (0.357 sec/step)\n",
            "I0923 10:07:36.320967 139631849019264 learning.py:507] global step 19375: loss = 0.0861 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 19376: loss = 0.1725 (0.290 sec/step)\n",
            "I0923 10:07:36.612406 139631849019264 learning.py:507] global step 19376: loss = 0.1725 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 19377: loss = 0.0400 (0.334 sec/step)\n",
            "I0923 10:07:36.948320 139631849019264 learning.py:507] global step 19377: loss = 0.0400 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 19378: loss = 0.1608 (0.371 sec/step)\n",
            "I0923 10:07:37.321608 139631849019264 learning.py:507] global step 19378: loss = 0.1608 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 19379: loss = 0.1665 (0.373 sec/step)\n",
            "I0923 10:07:37.696447 139631849019264 learning.py:507] global step 19379: loss = 0.1665 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 19380: loss = 0.2020 (0.336 sec/step)\n",
            "I0923 10:07:38.034957 139631849019264 learning.py:507] global step 19380: loss = 0.2020 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 19381: loss = 0.2119 (0.322 sec/step)\n",
            "I0923 10:07:38.359311 139631849019264 learning.py:507] global step 19381: loss = 0.2119 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 19382: loss = 0.0802 (0.289 sec/step)\n",
            "I0923 10:07:38.650542 139631849019264 learning.py:507] global step 19382: loss = 0.0802 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 19383: loss = 0.1089 (0.339 sec/step)\n",
            "I0923 10:07:38.992855 139631849019264 learning.py:507] global step 19383: loss = 0.1089 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 19384: loss = 0.0810 (0.285 sec/step)\n",
            "I0923 10:07:39.283585 139631849019264 learning.py:507] global step 19384: loss = 0.0810 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 19385: loss = 0.0701 (0.283 sec/step)\n",
            "I0923 10:07:39.568720 139631849019264 learning.py:507] global step 19385: loss = 0.0701 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 19386: loss = 0.1378 (0.329 sec/step)\n",
            "I0923 10:07:39.899989 139631849019264 learning.py:507] global step 19386: loss = 0.1378 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 19387: loss = 0.1625 (0.336 sec/step)\n",
            "I0923 10:07:40.238372 139631849019264 learning.py:507] global step 19387: loss = 0.1625 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 19388: loss = 0.0596 (0.320 sec/step)\n",
            "I0923 10:07:40.560347 139631849019264 learning.py:507] global step 19388: loss = 0.0596 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19389: loss = 0.1113 (0.310 sec/step)\n",
            "I0923 10:07:40.872653 139631849019264 learning.py:507] global step 19389: loss = 0.1113 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 19390: loss = 0.1138 (0.323 sec/step)\n",
            "I0923 10:07:41.197657 139631849019264 learning.py:507] global step 19390: loss = 0.1138 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 19391: loss = 0.0737 (0.292 sec/step)\n",
            "I0923 10:07:41.491274 139631849019264 learning.py:507] global step 19391: loss = 0.0737 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19392: loss = 0.1439 (0.338 sec/step)\n",
            "I0923 10:07:41.831121 139631849019264 learning.py:507] global step 19392: loss = 0.1439 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 19393: loss = 0.1105 (0.336 sec/step)\n",
            "I0923 10:07:42.169195 139631849019264 learning.py:507] global step 19393: loss = 0.1105 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 19394: loss = 0.0570 (0.344 sec/step)\n",
            "I0923 10:07:42.514687 139631849019264 learning.py:507] global step 19394: loss = 0.0570 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 19395: loss = 0.0924 (0.291 sec/step)\n",
            "I0923 10:07:42.807995 139631849019264 learning.py:507] global step 19395: loss = 0.0924 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 19396: loss = 0.1454 (0.293 sec/step)\n",
            "I0923 10:07:43.102662 139631849019264 learning.py:507] global step 19396: loss = 0.1454 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 19397: loss = 0.0861 (0.326 sec/step)\n",
            "I0923 10:07:43.430197 139631849019264 learning.py:507] global step 19397: loss = 0.0861 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 19398: loss = 0.1468 (0.274 sec/step)\n",
            "I0923 10:07:43.706767 139631849019264 learning.py:507] global step 19398: loss = 0.1468 (0.274 sec/step)\n",
            "INFO:tensorflow:global step 19399: loss = 0.1085 (0.320 sec/step)\n",
            "I0923 10:07:44.028458 139631849019264 learning.py:507] global step 19399: loss = 0.1085 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19400: loss = 0.0411 (0.293 sec/step)\n",
            "I0923 10:07:44.323924 139631849019264 learning.py:507] global step 19400: loss = 0.0411 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 19401: loss = 0.1156 (0.344 sec/step)\n",
            "I0923 10:07:44.670294 139631849019264 learning.py:507] global step 19401: loss = 0.1156 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 19402: loss = 0.1233 (0.324 sec/step)\n",
            "I0923 10:07:44.996505 139631849019264 learning.py:507] global step 19402: loss = 0.1233 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 19403: loss = 0.1463 (0.288 sec/step)\n",
            "I0923 10:07:45.286437 139631849019264 learning.py:507] global step 19403: loss = 0.1463 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 19404: loss = 0.0779 (0.300 sec/step)\n",
            "I0923 10:07:45.588505 139631849019264 learning.py:507] global step 19404: loss = 0.0779 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 19405: loss = 0.0613 (0.306 sec/step)\n",
            "I0923 10:07:45.896002 139631849019264 learning.py:507] global step 19405: loss = 0.0613 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 19406: loss = 0.1290 (0.288 sec/step)\n",
            "I0923 10:07:46.185616 139631849019264 learning.py:507] global step 19406: loss = 0.1290 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 19407: loss = 0.1175 (0.285 sec/step)\n",
            "I0923 10:07:46.472116 139631849019264 learning.py:507] global step 19407: loss = 0.1175 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 19408: loss = 0.0398 (0.289 sec/step)\n",
            "I0923 10:07:46.764031 139631849019264 learning.py:507] global step 19408: loss = 0.0398 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 19409: loss = 0.1314 (0.322 sec/step)\n",
            "I0923 10:07:47.089289 139631849019264 learning.py:507] global step 19409: loss = 0.1314 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 19410: loss = 0.0965 (0.325 sec/step)\n",
            "I0923 10:07:47.416093 139631849019264 learning.py:507] global step 19410: loss = 0.0965 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 19411: loss = 0.0754 (0.296 sec/step)\n",
            "I0923 10:07:47.715510 139631849019264 learning.py:507] global step 19411: loss = 0.0754 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 19412: loss = 0.1914 (0.313 sec/step)\n",
            "I0923 10:07:48.030831 139631849019264 learning.py:507] global step 19412: loss = 0.1914 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 19413: loss = 0.2417 (0.294 sec/step)\n",
            "I0923 10:07:48.326395 139631849019264 learning.py:507] global step 19413: loss = 0.2417 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 19414: loss = 0.0571 (0.288 sec/step)\n",
            "I0923 10:07:48.616398 139631849019264 learning.py:507] global step 19414: loss = 0.0571 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 19415: loss = 0.0710 (0.277 sec/step)\n",
            "I0923 10:07:48.895210 139631849019264 learning.py:507] global step 19415: loss = 0.0710 (0.277 sec/step)\n",
            "INFO:tensorflow:global step 19416: loss = 0.2044 (0.328 sec/step)\n",
            "I0923 10:07:49.225235 139631849019264 learning.py:507] global step 19416: loss = 0.2044 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 19417: loss = 0.1039 (0.343 sec/step)\n",
            "I0923 10:07:49.570138 139631849019264 learning.py:507] global step 19417: loss = 0.1039 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 19418: loss = 0.0808 (0.297 sec/step)\n",
            "I0923 10:07:49.869335 139631849019264 learning.py:507] global step 19418: loss = 0.0808 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 19419: loss = 0.0510 (0.290 sec/step)\n",
            "I0923 10:07:50.161568 139631849019264 learning.py:507] global step 19419: loss = 0.0510 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 19420: loss = 0.0481 (0.303 sec/step)\n",
            "I0923 10:07:50.466578 139631849019264 learning.py:507] global step 19420: loss = 0.0481 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 19421: loss = 0.1308 (0.283 sec/step)\n",
            "I0923 10:07:50.751440 139631849019264 learning.py:507] global step 19421: loss = 0.1308 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 19422: loss = 0.2123 (0.394 sec/step)\n",
            "I0923 10:07:51.146963 139631849019264 learning.py:507] global step 19422: loss = 0.2123 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 19423: loss = 0.0965 (0.322 sec/step)\n",
            "I0923 10:07:51.470425 139631849019264 learning.py:507] global step 19423: loss = 0.0965 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 19424: loss = 0.0830 (0.305 sec/step)\n",
            "I0923 10:07:51.777570 139631849019264 learning.py:507] global step 19424: loss = 0.0830 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 19425: loss = 0.3150 (0.358 sec/step)\n",
            "I0923 10:07:52.137219 139631849019264 learning.py:507] global step 19425: loss = 0.3150 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 19426: loss = 0.0561 (0.300 sec/step)\n",
            "I0923 10:07:52.439039 139631849019264 learning.py:507] global step 19426: loss = 0.0561 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 19427: loss = 0.3199 (0.287 sec/step)\n",
            "I0923 10:07:52.728114 139631849019264 learning.py:507] global step 19427: loss = 0.3199 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 19428: loss = 0.1533 (0.362 sec/step)\n",
            "I0923 10:07:53.092512 139631849019264 learning.py:507] global step 19428: loss = 0.1533 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 19429: loss = 0.1428 (0.304 sec/step)\n",
            "I0923 10:07:53.398153 139631849019264 learning.py:507] global step 19429: loss = 0.1428 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 19430: loss = 0.0502 (0.295 sec/step)\n",
            "I0923 10:07:53.695250 139631849019264 learning.py:507] global step 19430: loss = 0.0502 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 19431: loss = 0.0862 (0.354 sec/step)\n",
            "I0923 10:07:54.051460 139631849019264 learning.py:507] global step 19431: loss = 0.0862 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 19432: loss = 0.0726 (0.331 sec/step)\n",
            "I0923 10:07:54.384616 139631849019264 learning.py:507] global step 19432: loss = 0.0726 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 19433: loss = 0.1776 (0.298 sec/step)\n",
            "I0923 10:07:54.684310 139631849019264 learning.py:507] global step 19433: loss = 0.1776 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 19434: loss = 0.1601 (0.323 sec/step)\n",
            "I0923 10:07:55.008874 139631849019264 learning.py:507] global step 19434: loss = 0.1601 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 19435: loss = 0.0647 (0.282 sec/step)\n",
            "I0923 10:07:55.292431 139631849019264 learning.py:507] global step 19435: loss = 0.0647 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 19436: loss = 0.0684 (0.339 sec/step)\n",
            "I0923 10:07:55.633363 139631849019264 learning.py:507] global step 19436: loss = 0.0684 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 19437: loss = 0.2336 (0.366 sec/step)\n",
            "I0923 10:07:56.001184 139631849019264 learning.py:507] global step 19437: loss = 0.2336 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 19438: loss = 0.1621 (0.284 sec/step)\n",
            "I0923 10:07:56.287178 139631849019264 learning.py:507] global step 19438: loss = 0.1621 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19439: loss = 0.0843 (0.311 sec/step)\n",
            "I0923 10:07:56.600127 139631849019264 learning.py:507] global step 19439: loss = 0.0843 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 19440: loss = 0.0654 (0.267 sec/step)\n",
            "I0923 10:07:56.869044 139631849019264 learning.py:507] global step 19440: loss = 0.0654 (0.267 sec/step)\n",
            "INFO:tensorflow:global step 19441: loss = 0.0980 (0.346 sec/step)\n",
            "I0923 10:07:57.217156 139631849019264 learning.py:507] global step 19441: loss = 0.0980 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 19442: loss = 0.0671 (0.303 sec/step)\n",
            "I0923 10:07:57.521927 139631849019264 learning.py:507] global step 19442: loss = 0.0671 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 19443: loss = 0.0865 (0.307 sec/step)\n",
            "I0923 10:07:57.830910 139631849019264 learning.py:507] global step 19443: loss = 0.0865 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 19444: loss = 0.1000 (0.327 sec/step)\n",
            "I0923 10:07:58.159733 139631849019264 learning.py:507] global step 19444: loss = 0.1000 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19445: loss = 0.0781 (0.342 sec/step)\n",
            "I0923 10:07:58.504795 139631849019264 learning.py:507] global step 19445: loss = 0.0781 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 19446: loss = 0.0364 (0.291 sec/step)\n",
            "I0923 10:07:58.797770 139631849019264 learning.py:507] global step 19446: loss = 0.0364 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 19447: loss = 0.1078 (0.335 sec/step)\n",
            "I0923 10:07:59.134979 139631849019264 learning.py:507] global step 19447: loss = 0.1078 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 19448: loss = 0.0806 (0.329 sec/step)\n",
            "I0923 10:07:59.466245 139631849019264 learning.py:507] global step 19448: loss = 0.0806 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 19449: loss = 0.0719 (0.325 sec/step)\n",
            "I0923 10:07:59.796213 139631849019264 learning.py:507] global step 19449: loss = 0.0719 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 19450: loss = 0.0927 (0.346 sec/step)\n",
            "I0923 10:08:00.146889 139631849019264 learning.py:507] global step 19450: loss = 0.0927 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 19451: loss = 0.0781 (0.284 sec/step)\n",
            "I0923 10:08:00.432789 139631849019264 learning.py:507] global step 19451: loss = 0.0781 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19452: loss = 0.1053 (0.324 sec/step)\n",
            "I0923 10:08:00.758584 139631849019264 learning.py:507] global step 19452: loss = 0.1053 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 19453: loss = 0.0649 (0.339 sec/step)\n",
            "I0923 10:08:01.098975 139631849019264 learning.py:507] global step 19453: loss = 0.0649 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 19454: loss = 0.0890 (0.302 sec/step)\n",
            "I0923 10:08:01.403003 139631849019264 learning.py:507] global step 19454: loss = 0.0890 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 19455: loss = 0.0921 (0.325 sec/step)\n",
            "I0923 10:08:01.729894 139631849019264 learning.py:507] global step 19455: loss = 0.0921 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 19456: loss = 0.1435 (0.357 sec/step)\n",
            "I0923 10:08:02.088257 139631849019264 learning.py:507] global step 19456: loss = 0.1435 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 19457: loss = 0.0371 (0.339 sec/step)\n",
            "I0923 10:08:02.429579 139631849019264 learning.py:507] global step 19457: loss = 0.0371 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 19458: loss = 0.0885 (0.324 sec/step)\n",
            "I0923 10:08:02.755454 139631849019264 learning.py:507] global step 19458: loss = 0.0885 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 19459: loss = 0.0602 (0.323 sec/step)\n",
            "I0923 10:08:03.080672 139631849019264 learning.py:507] global step 19459: loss = 0.0602 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 19460: loss = 0.1701 (0.290 sec/step)\n",
            "I0923 10:08:03.372283 139631849019264 learning.py:507] global step 19460: loss = 0.1701 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 19461: loss = 0.3675 (0.380 sec/step)\n",
            "I0923 10:08:03.753542 139631849019264 learning.py:507] global step 19461: loss = 0.3675 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 19462: loss = 0.1089 (0.296 sec/step)\n",
            "I0923 10:08:04.051624 139631849019264 learning.py:507] global step 19462: loss = 0.1089 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 19463: loss = 0.1224 (0.311 sec/step)\n",
            "I0923 10:08:04.363960 139631849019264 learning.py:507] global step 19463: loss = 0.1224 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 19464: loss = 0.1499 (0.276 sec/step)\n",
            "I0923 10:08:04.641967 139631849019264 learning.py:507] global step 19464: loss = 0.1499 (0.276 sec/step)\n",
            "INFO:tensorflow:global step 19465: loss = 0.1618 (0.318 sec/step)\n",
            "I0923 10:08:04.961794 139631849019264 learning.py:507] global step 19465: loss = 0.1618 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 19466: loss = 0.0577 (0.287 sec/step)\n",
            "I0923 10:08:05.250480 139631849019264 learning.py:507] global step 19466: loss = 0.0577 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 19467: loss = 0.1192 (0.297 sec/step)\n",
            "I0923 10:08:05.549466 139631849019264 learning.py:507] global step 19467: loss = 0.1192 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 19468: loss = 0.0740 (0.316 sec/step)\n",
            "I0923 10:08:05.866996 139631849019264 learning.py:507] global step 19468: loss = 0.0740 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 19469: loss = 0.0833 (0.280 sec/step)\n",
            "I0923 10:08:06.149303 139631849019264 learning.py:507] global step 19469: loss = 0.0833 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 19470: loss = 0.0687 (0.297 sec/step)\n",
            "I0923 10:08:06.447887 139631849019264 learning.py:507] global step 19470: loss = 0.0687 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 19471: loss = 0.0645 (0.303 sec/step)\n",
            "I0923 10:08:06.752125 139631849019264 learning.py:507] global step 19471: loss = 0.0645 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 19472: loss = 0.1452 (0.280 sec/step)\n",
            "I0923 10:08:07.033687 139631849019264 learning.py:507] global step 19472: loss = 0.1452 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 19473: loss = 0.0686 (0.330 sec/step)\n",
            "I0923 10:08:07.365937 139631849019264 learning.py:507] global step 19473: loss = 0.0686 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 19474: loss = 0.1263 (0.299 sec/step)\n",
            "I0923 10:08:07.666395 139631849019264 learning.py:507] global step 19474: loss = 0.1263 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 19475: loss = 0.0423 (0.418 sec/step)\n",
            "I0923 10:08:08.086284 139631849019264 learning.py:507] global step 19475: loss = 0.0423 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 19476: loss = 0.1094 (0.320 sec/step)\n",
            "I0923 10:08:08.407797 139631849019264 learning.py:507] global step 19476: loss = 0.1094 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19477: loss = 0.2017 (0.334 sec/step)\n",
            "I0923 10:08:08.743544 139631849019264 learning.py:507] global step 19477: loss = 0.2017 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 19478: loss = 0.1074 (0.312 sec/step)\n",
            "I0923 10:08:09.057100 139631849019264 learning.py:507] global step 19478: loss = 0.1074 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 19479: loss = 0.0460 (0.274 sec/step)\n",
            "I0923 10:08:09.332726 139631849019264 learning.py:507] global step 19479: loss = 0.0460 (0.274 sec/step)\n",
            "INFO:tensorflow:global step 19480: loss = 0.2628 (0.302 sec/step)\n",
            "I0923 10:08:09.636356 139631849019264 learning.py:507] global step 19480: loss = 0.2628 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 19481: loss = 0.0438 (0.302 sec/step)\n",
            "I0923 10:08:09.939847 139631849019264 learning.py:507] global step 19481: loss = 0.0438 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 19482: loss = 0.1069 (0.327 sec/step)\n",
            "I0923 10:08:10.268419 139631849019264 learning.py:507] global step 19482: loss = 0.1069 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19483: loss = 0.0865 (0.340 sec/step)\n",
            "I0923 10:08:10.610267 139631849019264 learning.py:507] global step 19483: loss = 0.0865 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 19484: loss = 0.0443 (0.307 sec/step)\n",
            "I0923 10:08:10.918576 139631849019264 learning.py:507] global step 19484: loss = 0.0443 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 19485: loss = 0.1219 (0.294 sec/step)\n",
            "I0923 10:08:11.213913 139631849019264 learning.py:507] global step 19485: loss = 0.1219 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 19486: loss = 0.0948 (0.292 sec/step)\n",
            "I0923 10:08:11.508125 139631849019264 learning.py:507] global step 19486: loss = 0.0948 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19487: loss = 0.0483 (0.322 sec/step)\n",
            "I0923 10:08:11.831587 139631849019264 learning.py:507] global step 19487: loss = 0.0483 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 19488: loss = 0.1505 (0.312 sec/step)\n",
            "I0923 10:08:12.145802 139631849019264 learning.py:507] global step 19488: loss = 0.1505 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 19489: loss = 0.1077 (0.337 sec/step)\n",
            "I0923 10:08:12.484864 139631849019264 learning.py:507] global step 19489: loss = 0.1077 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 19490: loss = 0.0938 (0.333 sec/step)\n",
            "I0923 10:08:12.819870 139631849019264 learning.py:507] global step 19490: loss = 0.0938 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 19491: loss = 0.0729 (0.317 sec/step)\n",
            "I0923 10:08:13.138644 139631849019264 learning.py:507] global step 19491: loss = 0.0729 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 19492: loss = 0.0437 (0.289 sec/step)\n",
            "I0923 10:08:13.431206 139631849019264 learning.py:507] global step 19492: loss = 0.0437 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 19493: loss = 0.0828 (0.333 sec/step)\n",
            "I0923 10:08:13.766568 139631849019264 learning.py:507] global step 19493: loss = 0.0828 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 19494: loss = 0.2921 (0.309 sec/step)\n",
            "I0923 10:08:14.077235 139631849019264 learning.py:507] global step 19494: loss = 0.2921 (0.309 sec/step)\n",
            "INFO:tensorflow:global step 19495: loss = 0.1423 (0.292 sec/step)\n",
            "I0923 10:08:14.371237 139631849019264 learning.py:507] global step 19495: loss = 0.1423 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19496: loss = 0.0437 (0.326 sec/step)\n",
            "I0923 10:08:14.698876 139631849019264 learning.py:507] global step 19496: loss = 0.0437 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 19497: loss = 0.0702 (0.282 sec/step)\n",
            "I0923 10:08:14.982598 139631849019264 learning.py:507] global step 19497: loss = 0.0702 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 19498: loss = 0.1096 (0.278 sec/step)\n",
            "I0923 10:08:15.263220 139631849019264 learning.py:507] global step 19498: loss = 0.1096 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 19499: loss = 0.2503 (0.337 sec/step)\n",
            "I0923 10:08:15.603840 139631849019264 learning.py:507] global step 19499: loss = 0.2503 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 19500: loss = 0.0550 (0.301 sec/step)\n",
            "I0923 10:08:15.906411 139631849019264 learning.py:507] global step 19500: loss = 0.0550 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 19501: loss = 0.0838 (0.322 sec/step)\n",
            "I0923 10:08:16.229794 139631849019264 learning.py:507] global step 19501: loss = 0.0838 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 19502: loss = 0.0690 (0.292 sec/step)\n",
            "I0923 10:08:16.523293 139631849019264 learning.py:507] global step 19502: loss = 0.0690 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19503: loss = 0.0553 (0.331 sec/step)\n",
            "I0923 10:08:16.855729 139631849019264 learning.py:507] global step 19503: loss = 0.0553 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 19504: loss = 0.2613 (0.306 sec/step)\n",
            "I0923 10:08:17.163514 139631849019264 learning.py:507] global step 19504: loss = 0.2613 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 19505: loss = 0.0599 (0.329 sec/step)\n",
            "I0923 10:08:17.493953 139631849019264 learning.py:507] global step 19505: loss = 0.0599 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 19506: loss = 0.1402 (0.347 sec/step)\n",
            "I0923 10:08:17.843017 139631849019264 learning.py:507] global step 19506: loss = 0.1402 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 19507: loss = 0.0749 (0.373 sec/step)\n",
            "I0923 10:08:18.228409 139631849019264 learning.py:507] global step 19507: loss = 0.0749 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 19508: loss = 0.0927 (0.502 sec/step)\n",
            "I0923 10:08:18.740810 139631849019264 learning.py:507] global step 19508: loss = 0.0927 (0.502 sec/step)\n",
            "INFO:tensorflow:global step 19509: loss = 0.0450 (0.359 sec/step)\n",
            "I0923 10:08:19.114511 139631849019264 learning.py:507] global step 19509: loss = 0.0450 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 19510: loss = 0.0264 (0.433 sec/step)\n",
            "I0923 10:08:19.559774 139631849019264 learning.py:507] global step 19510: loss = 0.0264 (0.433 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 19510.\n",
            "I0923 10:08:19.607248 139628630939392 supervisor.py:1050] Recording summary at step 19510.\n",
            "INFO:tensorflow:global step 19511: loss = 0.0803 (0.341 sec/step)\n",
            "I0923 10:08:19.903289 139631849019264 learning.py:507] global step 19511: loss = 0.0803 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 19512: loss = 0.0609 (0.336 sec/step)\n",
            "I0923 10:08:20.241146 139631849019264 learning.py:507] global step 19512: loss = 0.0609 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 19513: loss = 0.1946 (0.323 sec/step)\n",
            "I0923 10:08:20.565664 139631849019264 learning.py:507] global step 19513: loss = 0.1946 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 19514: loss = 0.0796 (0.334 sec/step)\n",
            "I0923 10:08:20.901257 139631849019264 learning.py:507] global step 19514: loss = 0.0796 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 19515: loss = 0.0587 (0.320 sec/step)\n",
            "I0923 10:08:21.223645 139631849019264 learning.py:507] global step 19515: loss = 0.0587 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19516: loss = 0.1025 (0.294 sec/step)\n",
            "I0923 10:08:21.519608 139631849019264 learning.py:507] global step 19516: loss = 0.1025 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 19517: loss = 0.1371 (0.272 sec/step)\n",
            "I0923 10:08:21.794226 139631849019264 learning.py:507] global step 19517: loss = 0.1371 (0.272 sec/step)\n",
            "INFO:tensorflow:global step 19518: loss = 0.0511 (0.324 sec/step)\n",
            "I0923 10:08:22.120296 139631849019264 learning.py:507] global step 19518: loss = 0.0511 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 19519: loss = 0.0999 (0.319 sec/step)\n",
            "I0923 10:08:22.441381 139631849019264 learning.py:507] global step 19519: loss = 0.0999 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 19520: loss = 0.1948 (0.284 sec/step)\n",
            "I0923 10:08:22.727209 139631849019264 learning.py:507] global step 19520: loss = 0.1948 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19521: loss = 0.0552 (0.337 sec/step)\n",
            "I0923 10:08:23.066124 139631849019264 learning.py:507] global step 19521: loss = 0.0552 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 19522: loss = 0.0446 (0.330 sec/step)\n",
            "I0923 10:08:23.397917 139631849019264 learning.py:507] global step 19522: loss = 0.0446 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 19523: loss = 0.0816 (0.300 sec/step)\n",
            "I0923 10:08:23.699472 139631849019264 learning.py:507] global step 19523: loss = 0.0816 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 19524: loss = 0.0527 (0.325 sec/step)\n",
            "I0923 10:08:24.025895 139631849019264 learning.py:507] global step 19524: loss = 0.0527 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 19525: loss = 0.1218 (0.291 sec/step)\n",
            "I0923 10:08:24.319266 139631849019264 learning.py:507] global step 19525: loss = 0.1218 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 19526: loss = 0.0594 (0.397 sec/step)\n",
            "I0923 10:08:24.717734 139631849019264 learning.py:507] global step 19526: loss = 0.0594 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 19527: loss = 0.1904 (0.308 sec/step)\n",
            "I0923 10:08:25.027387 139631849019264 learning.py:507] global step 19527: loss = 0.1904 (0.308 sec/step)\n",
            "INFO:tensorflow:global step 19528: loss = 0.0269 (0.346 sec/step)\n",
            "I0923 10:08:25.375456 139631849019264 learning.py:507] global step 19528: loss = 0.0269 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 19529: loss = 0.0622 (0.313 sec/step)\n",
            "I0923 10:08:25.690702 139631849019264 learning.py:507] global step 19529: loss = 0.0622 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 19530: loss = 0.0549 (0.336 sec/step)\n",
            "I0923 10:08:26.028801 139631849019264 learning.py:507] global step 19530: loss = 0.0549 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 19531: loss = 0.0593 (0.284 sec/step)\n",
            "I0923 10:08:26.314365 139631849019264 learning.py:507] global step 19531: loss = 0.0593 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19532: loss = 0.2046 (0.344 sec/step)\n",
            "I0923 10:08:26.660390 139631849019264 learning.py:507] global step 19532: loss = 0.2046 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 19533: loss = 0.1183 (0.344 sec/step)\n",
            "I0923 10:08:27.005875 139631849019264 learning.py:507] global step 19533: loss = 0.1183 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 19534: loss = 0.0681 (0.277 sec/step)\n",
            "I0923 10:08:27.284872 139631849019264 learning.py:507] global step 19534: loss = 0.0681 (0.277 sec/step)\n",
            "INFO:tensorflow:global step 19535: loss = 0.1075 (0.320 sec/step)\n",
            "I0923 10:08:27.606550 139631849019264 learning.py:507] global step 19535: loss = 0.1075 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19536: loss = 0.1372 (0.348 sec/step)\n",
            "I0923 10:08:27.956898 139631849019264 learning.py:507] global step 19536: loss = 0.1372 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 19537: loss = 0.1994 (0.279 sec/step)\n",
            "I0923 10:08:28.237810 139631849019264 learning.py:507] global step 19537: loss = 0.1994 (0.279 sec/step)\n",
            "INFO:tensorflow:global step 19538: loss = 0.2222 (0.401 sec/step)\n",
            "I0923 10:08:28.640878 139631849019264 learning.py:507] global step 19538: loss = 0.2222 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 19539: loss = 0.0960 (0.291 sec/step)\n",
            "I0923 10:08:28.933131 139631849019264 learning.py:507] global step 19539: loss = 0.0960 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 19540: loss = 0.0723 (0.359 sec/step)\n",
            "I0923 10:08:29.293648 139631849019264 learning.py:507] global step 19540: loss = 0.0723 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 19541: loss = 0.0484 (0.285 sec/step)\n",
            "I0923 10:08:29.580350 139631849019264 learning.py:507] global step 19541: loss = 0.0484 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 19542: loss = 0.1155 (0.324 sec/step)\n",
            "I0923 10:08:29.905942 139631849019264 learning.py:507] global step 19542: loss = 0.1155 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 19543: loss = 0.1005 (0.320 sec/step)\n",
            "I0923 10:08:30.228033 139631849019264 learning.py:507] global step 19543: loss = 0.1005 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19544: loss = 0.1204 (0.287 sec/step)\n",
            "I0923 10:08:30.516874 139631849019264 learning.py:507] global step 19544: loss = 0.1204 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 19545: loss = 0.0237 (0.347 sec/step)\n",
            "I0923 10:08:30.865633 139631849019264 learning.py:507] global step 19545: loss = 0.0237 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 19546: loss = 0.1392 (0.308 sec/step)\n",
            "I0923 10:08:31.175357 139631849019264 learning.py:507] global step 19546: loss = 0.1392 (0.308 sec/step)\n",
            "INFO:tensorflow:global step 19547: loss = 0.0309 (0.343 sec/step)\n",
            "I0923 10:08:31.520097 139631849019264 learning.py:507] global step 19547: loss = 0.0309 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 19548: loss = 0.0933 (0.320 sec/step)\n",
            "I0923 10:08:31.841681 139631849019264 learning.py:507] global step 19548: loss = 0.0933 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19549: loss = 0.0514 (0.292 sec/step)\n",
            "I0923 10:08:32.136144 139631849019264 learning.py:507] global step 19549: loss = 0.0514 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19550: loss = 0.0689 (0.281 sec/step)\n",
            "I0923 10:08:32.418996 139631849019264 learning.py:507] global step 19550: loss = 0.0689 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 19551: loss = 0.0685 (0.290 sec/step)\n",
            "I0923 10:08:32.710724 139631849019264 learning.py:507] global step 19551: loss = 0.0685 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 19552: loss = 0.1535 (0.293 sec/step)\n",
            "I0923 10:08:33.005912 139631849019264 learning.py:507] global step 19552: loss = 0.1535 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 19553: loss = 0.2006 (0.300 sec/step)\n",
            "I0923 10:08:33.307463 139631849019264 learning.py:507] global step 19553: loss = 0.2006 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 19554: loss = 0.0373 (0.327 sec/step)\n",
            "I0923 10:08:33.636336 139631849019264 learning.py:507] global step 19554: loss = 0.0373 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19555: loss = 0.0566 (0.295 sec/step)\n",
            "I0923 10:08:33.932953 139631849019264 learning.py:507] global step 19555: loss = 0.0566 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 19556: loss = 0.1262 (0.322 sec/step)\n",
            "I0923 10:08:34.256041 139631849019264 learning.py:507] global step 19556: loss = 0.1262 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 19557: loss = 0.1647 (0.339 sec/step)\n",
            "I0923 10:08:34.596878 139631849019264 learning.py:507] global step 19557: loss = 0.1647 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 19558: loss = 0.0869 (0.286 sec/step)\n",
            "I0923 10:08:34.884544 139631849019264 learning.py:507] global step 19558: loss = 0.0869 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 19559: loss = 0.0536 (0.300 sec/step)\n",
            "I0923 10:08:35.186588 139631849019264 learning.py:507] global step 19559: loss = 0.0536 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 19560: loss = 0.0937 (0.316 sec/step)\n",
            "I0923 10:08:35.503828 139631849019264 learning.py:507] global step 19560: loss = 0.0937 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 19561: loss = 0.0479 (0.286 sec/step)\n",
            "I0923 10:08:35.791122 139631849019264 learning.py:507] global step 19561: loss = 0.0479 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 19562: loss = 0.0928 (0.319 sec/step)\n",
            "I0923 10:08:36.111646 139631849019264 learning.py:507] global step 19562: loss = 0.0928 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 19563: loss = 0.1174 (0.283 sec/step)\n",
            "I0923 10:08:36.396802 139631849019264 learning.py:507] global step 19563: loss = 0.1174 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 19564: loss = 0.1490 (0.296 sec/step)\n",
            "I0923 10:08:36.694561 139631849019264 learning.py:507] global step 19564: loss = 0.1490 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 19565: loss = 0.0752 (0.297 sec/step)\n",
            "I0923 10:08:36.992996 139631849019264 learning.py:507] global step 19565: loss = 0.0752 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 19566: loss = 0.0846 (0.305 sec/step)\n",
            "I0923 10:08:37.300374 139631849019264 learning.py:507] global step 19566: loss = 0.0846 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 19567: loss = 0.1933 (0.323 sec/step)\n",
            "I0923 10:08:37.624780 139631849019264 learning.py:507] global step 19567: loss = 0.1933 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 19568: loss = 0.1223 (0.293 sec/step)\n",
            "I0923 10:08:37.919687 139631849019264 learning.py:507] global step 19568: loss = 0.1223 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 19569: loss = 0.0601 (0.339 sec/step)\n",
            "I0923 10:08:38.260006 139631849019264 learning.py:507] global step 19569: loss = 0.0601 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 19570: loss = 0.0840 (0.313 sec/step)\n",
            "I0923 10:08:38.574567 139631849019264 learning.py:507] global step 19570: loss = 0.0840 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 19571: loss = 0.0920 (0.323 sec/step)\n",
            "I0923 10:08:38.899367 139631849019264 learning.py:507] global step 19571: loss = 0.0920 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 19572: loss = 0.1013 (0.306 sec/step)\n",
            "I0923 10:08:39.207568 139631849019264 learning.py:507] global step 19572: loss = 0.1013 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 19573: loss = 0.0725 (0.349 sec/step)\n",
            "I0923 10:08:39.558416 139631849019264 learning.py:507] global step 19573: loss = 0.0725 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 19574: loss = 0.1228 (0.321 sec/step)\n",
            "I0923 10:08:39.880527 139631849019264 learning.py:507] global step 19574: loss = 0.1228 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 19575: loss = 0.1105 (0.331 sec/step)\n",
            "I0923 10:08:40.213668 139631849019264 learning.py:507] global step 19575: loss = 0.1105 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 19576: loss = 0.0777 (0.338 sec/step)\n",
            "I0923 10:08:40.555183 139631849019264 learning.py:507] global step 19576: loss = 0.0777 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 19577: loss = 0.0800 (0.296 sec/step)\n",
            "I0923 10:08:40.853546 139631849019264 learning.py:507] global step 19577: loss = 0.0800 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 19578: loss = 0.0865 (0.356 sec/step)\n",
            "I0923 10:08:41.211564 139631849019264 learning.py:507] global step 19578: loss = 0.0865 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 19579: loss = 0.2256 (0.315 sec/step)\n",
            "I0923 10:08:41.528713 139631849019264 learning.py:507] global step 19579: loss = 0.2256 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 19580: loss = 0.0788 (0.295 sec/step)\n",
            "I0923 10:08:41.826405 139631849019264 learning.py:507] global step 19580: loss = 0.0788 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 19581: loss = 0.4332 (0.312 sec/step)\n",
            "I0923 10:08:42.140571 139631849019264 learning.py:507] global step 19581: loss = 0.4332 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 19582: loss = 0.1056 (0.327 sec/step)\n",
            "I0923 10:08:42.469799 139631849019264 learning.py:507] global step 19582: loss = 0.1056 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19583: loss = 0.0552 (0.338 sec/step)\n",
            "I0923 10:08:42.809464 139631849019264 learning.py:507] global step 19583: loss = 0.0552 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 19584: loss = 0.1754 (0.311 sec/step)\n",
            "I0923 10:08:43.121936 139631849019264 learning.py:507] global step 19584: loss = 0.1754 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 19585: loss = 0.1447 (0.290 sec/step)\n",
            "I0923 10:08:43.413674 139631849019264 learning.py:507] global step 19585: loss = 0.1447 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 19586: loss = 0.2160 (0.293 sec/step)\n",
            "I0923 10:08:43.708520 139631849019264 learning.py:507] global step 19586: loss = 0.2160 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 19587: loss = 0.0347 (0.324 sec/step)\n",
            "I0923 10:08:44.033671 139631849019264 learning.py:507] global step 19587: loss = 0.0347 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 19588: loss = 0.1023 (0.330 sec/step)\n",
            "I0923 10:08:44.365865 139631849019264 learning.py:507] global step 19588: loss = 0.1023 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 19589: loss = 0.1606 (0.296 sec/step)\n",
            "I0923 10:08:44.663666 139631849019264 learning.py:507] global step 19589: loss = 0.1606 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 19590: loss = 0.1111 (0.288 sec/step)\n",
            "I0923 10:08:44.957437 139631849019264 learning.py:507] global step 19590: loss = 0.1111 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 19591: loss = 0.0671 (0.305 sec/step)\n",
            "I0923 10:08:45.263731 139631849019264 learning.py:507] global step 19591: loss = 0.0671 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 19592: loss = 0.0777 (0.346 sec/step)\n",
            "I0923 10:08:45.611077 139631849019264 learning.py:507] global step 19592: loss = 0.0777 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 19593: loss = 0.0984 (0.302 sec/step)\n",
            "I0923 10:08:45.915333 139631849019264 learning.py:507] global step 19593: loss = 0.0984 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 19594: loss = 0.0480 (0.290 sec/step)\n",
            "I0923 10:08:46.206928 139631849019264 learning.py:507] global step 19594: loss = 0.0480 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 19595: loss = 0.0547 (0.291 sec/step)\n",
            "I0923 10:08:46.499161 139631849019264 learning.py:507] global step 19595: loss = 0.0547 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 19596: loss = 0.0362 (0.349 sec/step)\n",
            "I0923 10:08:46.850231 139631849019264 learning.py:507] global step 19596: loss = 0.0362 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 19597: loss = 0.1204 (0.319 sec/step)\n",
            "I0923 10:08:47.171694 139631849019264 learning.py:507] global step 19597: loss = 0.1204 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 19598: loss = 0.0331 (0.292 sec/step)\n",
            "I0923 10:08:47.465324 139631849019264 learning.py:507] global step 19598: loss = 0.0331 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19599: loss = 0.0514 (0.331 sec/step)\n",
            "I0923 10:08:47.798503 139631849019264 learning.py:507] global step 19599: loss = 0.0514 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 19600: loss = 0.1399 (0.294 sec/step)\n",
            "I0923 10:08:48.094333 139631849019264 learning.py:507] global step 19600: loss = 0.1399 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 19601: loss = 0.1109 (0.350 sec/step)\n",
            "I0923 10:08:48.446456 139631849019264 learning.py:507] global step 19601: loss = 0.1109 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 19602: loss = 0.0921 (0.273 sec/step)\n",
            "I0923 10:08:48.721311 139631849019264 learning.py:507] global step 19602: loss = 0.0921 (0.273 sec/step)\n",
            "INFO:tensorflow:global step 19603: loss = 0.0972 (0.282 sec/step)\n",
            "I0923 10:08:49.005429 139631849019264 learning.py:507] global step 19603: loss = 0.0972 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 19604: loss = 0.0994 (0.372 sec/step)\n",
            "I0923 10:08:49.380242 139631849019264 learning.py:507] global step 19604: loss = 0.0994 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 19605: loss = 0.0447 (0.325 sec/step)\n",
            "I0923 10:08:49.707576 139631849019264 learning.py:507] global step 19605: loss = 0.0447 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 19606: loss = 0.0601 (0.277 sec/step)\n",
            "I0923 10:08:49.986849 139631849019264 learning.py:507] global step 19606: loss = 0.0601 (0.277 sec/step)\n",
            "INFO:tensorflow:global step 19607: loss = 0.0739 (0.290 sec/step)\n",
            "I0923 10:08:50.278812 139631849019264 learning.py:507] global step 19607: loss = 0.0739 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 19608: loss = 0.1129 (0.328 sec/step)\n",
            "I0923 10:08:50.609098 139631849019264 learning.py:507] global step 19608: loss = 0.1129 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 19609: loss = 0.1049 (0.330 sec/step)\n",
            "I0923 10:08:50.941426 139631849019264 learning.py:507] global step 19609: loss = 0.1049 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 19610: loss = 0.0786 (0.284 sec/step)\n",
            "I0923 10:08:51.235314 139631849019264 learning.py:507] global step 19610: loss = 0.0786 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19611: loss = 0.1324 (0.310 sec/step)\n",
            "I0923 10:08:51.547546 139631849019264 learning.py:507] global step 19611: loss = 0.1324 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 19612: loss = 0.0500 (0.282 sec/step)\n",
            "I0923 10:08:51.831115 139631849019264 learning.py:507] global step 19612: loss = 0.0500 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 19613: loss = 0.0528 (0.289 sec/step)\n",
            "I0923 10:08:52.122565 139631849019264 learning.py:507] global step 19613: loss = 0.0528 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 19614: loss = 0.1298 (0.293 sec/step)\n",
            "I0923 10:08:52.417225 139631849019264 learning.py:507] global step 19614: loss = 0.1298 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 19615: loss = 0.1072 (0.280 sec/step)\n",
            "I0923 10:08:52.699091 139631849019264 learning.py:507] global step 19615: loss = 0.1072 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 19616: loss = 0.0480 (0.284 sec/step)\n",
            "I0923 10:08:52.985372 139631849019264 learning.py:507] global step 19616: loss = 0.0480 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19617: loss = 0.0627 (0.292 sec/step)\n",
            "I0923 10:08:53.279421 139631849019264 learning.py:507] global step 19617: loss = 0.0627 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19618: loss = 0.1933 (0.335 sec/step)\n",
            "I0923 10:08:53.615801 139631849019264 learning.py:507] global step 19618: loss = 0.1933 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 19619: loss = 0.0860 (0.299 sec/step)\n",
            "I0923 10:08:53.916255 139631849019264 learning.py:507] global step 19619: loss = 0.0860 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 19620: loss = 0.1181 (0.296 sec/step)\n",
            "I0923 10:08:54.214018 139631849019264 learning.py:507] global step 19620: loss = 0.1181 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 19621: loss = 0.1435 (0.306 sec/step)\n",
            "I0923 10:08:54.522348 139631849019264 learning.py:507] global step 19621: loss = 0.1435 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 19622: loss = 0.0710 (0.299 sec/step)\n",
            "I0923 10:08:54.822958 139631849019264 learning.py:507] global step 19622: loss = 0.0710 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 19623: loss = 0.0864 (0.323 sec/step)\n",
            "I0923 10:08:55.147679 139631849019264 learning.py:507] global step 19623: loss = 0.0864 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 19624: loss = 0.1290 (0.292 sec/step)\n",
            "I0923 10:08:55.441448 139631849019264 learning.py:507] global step 19624: loss = 0.1290 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19625: loss = 0.0671 (0.299 sec/step)\n",
            "I0923 10:08:55.741721 139631849019264 learning.py:507] global step 19625: loss = 0.0671 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 19626: loss = 0.2228 (0.291 sec/step)\n",
            "I0923 10:08:56.034268 139631849019264 learning.py:507] global step 19626: loss = 0.2228 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 19627: loss = 0.0781 (0.321 sec/step)\n",
            "I0923 10:08:56.357207 139631849019264 learning.py:507] global step 19627: loss = 0.0781 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 19628: loss = 0.0939 (0.333 sec/step)\n",
            "I0923 10:08:56.691814 139631849019264 learning.py:507] global step 19628: loss = 0.0939 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 19629: loss = 0.1917 (0.335 sec/step)\n",
            "I0923 10:08:57.029040 139631849019264 learning.py:507] global step 19629: loss = 0.1917 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 19630: loss = 0.0861 (0.283 sec/step)\n",
            "I0923 10:08:57.313452 139631849019264 learning.py:507] global step 19630: loss = 0.0861 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 19631: loss = 0.1105 (0.325 sec/step)\n",
            "I0923 10:08:57.640632 139631849019264 learning.py:507] global step 19631: loss = 0.1105 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 19632: loss = 0.0444 (0.341 sec/step)\n",
            "I0923 10:08:57.983394 139631849019264 learning.py:507] global step 19632: loss = 0.0444 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 19633: loss = 0.0518 (0.295 sec/step)\n",
            "I0923 10:08:58.280387 139631849019264 learning.py:507] global step 19633: loss = 0.0518 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 19634: loss = 0.1223 (0.289 sec/step)\n",
            "I0923 10:08:58.571574 139631849019264 learning.py:507] global step 19634: loss = 0.1223 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 19635: loss = 0.1329 (0.334 sec/step)\n",
            "I0923 10:08:58.907258 139631849019264 learning.py:507] global step 19635: loss = 0.1329 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 19636: loss = 0.1239 (0.318 sec/step)\n",
            "I0923 10:08:59.227377 139631849019264 learning.py:507] global step 19636: loss = 0.1239 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 19637: loss = 0.0579 (0.330 sec/step)\n",
            "I0923 10:08:59.559012 139631849019264 learning.py:507] global step 19637: loss = 0.0579 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 19638: loss = 0.0555 (0.306 sec/step)\n",
            "I0923 10:08:59.866878 139631849019264 learning.py:507] global step 19638: loss = 0.0555 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 19639: loss = 0.0623 (0.347 sec/step)\n",
            "I0923 10:09:00.215992 139631849019264 learning.py:507] global step 19639: loss = 0.0623 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 19640: loss = 0.0637 (0.332 sec/step)\n",
            "I0923 10:09:00.550047 139631849019264 learning.py:507] global step 19640: loss = 0.0637 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 19641: loss = 0.0353 (0.324 sec/step)\n",
            "I0923 10:09:00.875720 139631849019264 learning.py:507] global step 19641: loss = 0.0353 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 19642: loss = 0.1877 (0.339 sec/step)\n",
            "I0923 10:09:01.216638 139631849019264 learning.py:507] global step 19642: loss = 0.1877 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 19643: loss = 0.0873 (0.290 sec/step)\n",
            "I0923 10:09:01.508249 139631849019264 learning.py:507] global step 19643: loss = 0.0873 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 19644: loss = 0.0363 (0.341 sec/step)\n",
            "I0923 10:09:01.852490 139631849019264 learning.py:507] global step 19644: loss = 0.0363 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 19645: loss = 0.0567 (0.328 sec/step)\n",
            "I0923 10:09:02.182559 139631849019264 learning.py:507] global step 19645: loss = 0.0567 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 19646: loss = 0.1178 (0.316 sec/step)\n",
            "I0923 10:09:02.500098 139631849019264 learning.py:507] global step 19646: loss = 0.1178 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 19647: loss = 0.0671 (0.342 sec/step)\n",
            "I0923 10:09:02.844114 139631849019264 learning.py:507] global step 19647: loss = 0.0671 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 19648: loss = 0.0978 (0.368 sec/step)\n",
            "I0923 10:09:03.213993 139631849019264 learning.py:507] global step 19648: loss = 0.0978 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 19649: loss = 0.0668 (0.365 sec/step)\n",
            "I0923 10:09:03.580454 139631849019264 learning.py:507] global step 19649: loss = 0.0668 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 19650: loss = 0.2019 (0.319 sec/step)\n",
            "I0923 10:09:03.901494 139631849019264 learning.py:507] global step 19650: loss = 0.2019 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 19651: loss = 0.1465 (0.334 sec/step)\n",
            "I0923 10:09:04.237879 139631849019264 learning.py:507] global step 19651: loss = 0.1465 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 19652: loss = 0.0818 (0.330 sec/step)\n",
            "I0923 10:09:04.569694 139631849019264 learning.py:507] global step 19652: loss = 0.0818 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 19653: loss = 0.0443 (0.324 sec/step)\n",
            "I0923 10:09:04.895669 139631849019264 learning.py:507] global step 19653: loss = 0.0443 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 19654: loss = 0.3034 (0.318 sec/step)\n",
            "I0923 10:09:05.215807 139631849019264 learning.py:507] global step 19654: loss = 0.3034 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 19655: loss = 0.1997 (0.314 sec/step)\n",
            "I0923 10:09:05.531879 139631849019264 learning.py:507] global step 19655: loss = 0.1997 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 19656: loss = 0.0858 (0.294 sec/step)\n",
            "I0923 10:09:05.828343 139631849019264 learning.py:507] global step 19656: loss = 0.0858 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 19657: loss = 0.1559 (0.317 sec/step)\n",
            "I0923 10:09:06.147510 139631849019264 learning.py:507] global step 19657: loss = 0.1559 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 19658: loss = 0.1125 (0.314 sec/step)\n",
            "I0923 10:09:06.462912 139631849019264 learning.py:507] global step 19658: loss = 0.1125 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 19659: loss = 0.0883 (0.328 sec/step)\n",
            "I0923 10:09:06.793017 139631849019264 learning.py:507] global step 19659: loss = 0.0883 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 19660: loss = 0.1146 (0.320 sec/step)\n",
            "I0923 10:09:07.114396 139631849019264 learning.py:507] global step 19660: loss = 0.1146 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19661: loss = 0.0831 (0.330 sec/step)\n",
            "I0923 10:09:07.446112 139631849019264 learning.py:507] global step 19661: loss = 0.0831 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 19662: loss = 0.1280 (0.344 sec/step)\n",
            "I0923 10:09:07.791854 139631849019264 learning.py:507] global step 19662: loss = 0.1280 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 19663: loss = 0.0627 (0.288 sec/step)\n",
            "I0923 10:09:08.081518 139631849019264 learning.py:507] global step 19663: loss = 0.0627 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 19664: loss = 0.1006 (0.316 sec/step)\n",
            "I0923 10:09:08.399104 139631849019264 learning.py:507] global step 19664: loss = 0.1006 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 19665: loss = 0.1427 (0.334 sec/step)\n",
            "I0923 10:09:08.735370 139631849019264 learning.py:507] global step 19665: loss = 0.1427 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 19666: loss = 0.0434 (0.291 sec/step)\n",
            "I0923 10:09:09.027994 139631849019264 learning.py:507] global step 19666: loss = 0.0434 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 19667: loss = 0.0569 (0.316 sec/step)\n",
            "I0923 10:09:09.345528 139631849019264 learning.py:507] global step 19667: loss = 0.0569 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 19668: loss = 0.0766 (0.343 sec/step)\n",
            "I0923 10:09:09.690294 139631849019264 learning.py:507] global step 19668: loss = 0.0766 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 19669: loss = 0.0892 (0.339 sec/step)\n",
            "I0923 10:09:10.030777 139631849019264 learning.py:507] global step 19669: loss = 0.0892 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 19670: loss = 0.0829 (0.339 sec/step)\n",
            "I0923 10:09:10.371419 139631849019264 learning.py:507] global step 19670: loss = 0.0829 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 19671: loss = 0.0655 (0.317 sec/step)\n",
            "I0923 10:09:10.690164 139631849019264 learning.py:507] global step 19671: loss = 0.0655 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 19672: loss = 0.3058 (0.291 sec/step)\n",
            "I0923 10:09:10.983422 139631849019264 learning.py:507] global step 19672: loss = 0.3058 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 19673: loss = 0.0804 (0.317 sec/step)\n",
            "I0923 10:09:11.302609 139631849019264 learning.py:507] global step 19673: loss = 0.0804 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 19674: loss = 0.0927 (0.333 sec/step)\n",
            "I0923 10:09:11.637701 139631849019264 learning.py:507] global step 19674: loss = 0.0927 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 19675: loss = 0.0745 (0.317 sec/step)\n",
            "I0923 10:09:11.956427 139631849019264 learning.py:507] global step 19675: loss = 0.0745 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 19676: loss = 0.0633 (0.284 sec/step)\n",
            "I0923 10:09:12.241986 139631849019264 learning.py:507] global step 19676: loss = 0.0633 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19677: loss = 0.0548 (0.274 sec/step)\n",
            "I0923 10:09:12.517818 139631849019264 learning.py:507] global step 19677: loss = 0.0548 (0.274 sec/step)\n",
            "INFO:tensorflow:global step 19678: loss = 0.0584 (0.355 sec/step)\n",
            "I0923 10:09:12.874845 139631849019264 learning.py:507] global step 19678: loss = 0.0584 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 19679: loss = 0.0755 (0.337 sec/step)\n",
            "I0923 10:09:13.213996 139631849019264 learning.py:507] global step 19679: loss = 0.0755 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 19680: loss = 0.0462 (0.287 sec/step)\n",
            "I0923 10:09:13.502741 139631849019264 learning.py:507] global step 19680: loss = 0.0462 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 19681: loss = 0.1304 (0.308 sec/step)\n",
            "I0923 10:09:13.812841 139631849019264 learning.py:507] global step 19681: loss = 0.1304 (0.308 sec/step)\n",
            "INFO:tensorflow:global step 19682: loss = 0.0575 (0.313 sec/step)\n",
            "I0923 10:09:14.128355 139631849019264 learning.py:507] global step 19682: loss = 0.0575 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 19683: loss = 0.0264 (0.339 sec/step)\n",
            "I0923 10:09:14.469357 139631849019264 learning.py:507] global step 19683: loss = 0.0264 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 19684: loss = 0.0726 (0.298 sec/step)\n",
            "I0923 10:09:14.769231 139631849019264 learning.py:507] global step 19684: loss = 0.0726 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 19685: loss = 0.0570 (0.332 sec/step)\n",
            "I0923 10:09:15.103724 139631849019264 learning.py:507] global step 19685: loss = 0.0570 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 19686: loss = 0.2068 (0.286 sec/step)\n",
            "I0923 10:09:15.391571 139631849019264 learning.py:507] global step 19686: loss = 0.2068 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 19687: loss = 0.1249 (0.327 sec/step)\n",
            "I0923 10:09:15.720450 139631849019264 learning.py:507] global step 19687: loss = 0.1249 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19688: loss = 0.1829 (0.300 sec/step)\n",
            "I0923 10:09:16.022912 139631849019264 learning.py:507] global step 19688: loss = 0.1829 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 19689: loss = 0.0432 (0.288 sec/step)\n",
            "I0923 10:09:16.312360 139631849019264 learning.py:507] global step 19689: loss = 0.0432 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 19690: loss = 0.1917 (0.358 sec/step)\n",
            "I0923 10:09:16.672209 139631849019264 learning.py:507] global step 19690: loss = 0.1917 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 19691: loss = 0.0924 (0.292 sec/step)\n",
            "I0923 10:09:16.966176 139631849019264 learning.py:507] global step 19691: loss = 0.0924 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19692: loss = 0.2170 (0.317 sec/step)\n",
            "I0923 10:09:17.285101 139631849019264 learning.py:507] global step 19692: loss = 0.2170 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 19693: loss = 0.0488 (0.314 sec/step)\n",
            "I0923 10:09:17.600987 139631849019264 learning.py:507] global step 19693: loss = 0.0488 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 19694: loss = 0.1210 (0.313 sec/step)\n",
            "I0923 10:09:17.916007 139631849019264 learning.py:507] global step 19694: loss = 0.1210 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 19695: loss = 0.0352 (0.283 sec/step)\n",
            "I0923 10:09:18.200354 139631849019264 learning.py:507] global step 19695: loss = 0.0352 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 19696: loss = 0.0857 (0.317 sec/step)\n",
            "I0923 10:09:18.523813 139631849019264 learning.py:507] global step 19696: loss = 0.0857 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 19697: loss = 0.0320 (0.276 sec/step)\n",
            "I0923 10:09:18.801657 139631849019264 learning.py:507] global step 19697: loss = 0.0320 (0.276 sec/step)\n",
            "INFO:tensorflow:global step 19698: loss = 0.1053 (0.373 sec/step)\n",
            "I0923 10:09:19.175983 139631849019264 learning.py:507] global step 19698: loss = 0.1053 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 19699: loss = 0.0411 (0.333 sec/step)\n",
            "I0923 10:09:19.510858 139631849019264 learning.py:507] global step 19699: loss = 0.0411 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 19700: loss = 0.1616 (0.295 sec/step)\n",
            "I0923 10:09:19.807197 139631849019264 learning.py:507] global step 19700: loss = 0.1616 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 19701: loss = 0.0980 (0.310 sec/step)\n",
            "I0923 10:09:20.118664 139631849019264 learning.py:507] global step 19701: loss = 0.0980 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 19702: loss = 0.0622 (0.337 sec/step)\n",
            "I0923 10:09:20.456926 139631849019264 learning.py:507] global step 19702: loss = 0.0622 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 19703: loss = 0.0913 (0.288 sec/step)\n",
            "I0923 10:09:20.746617 139631849019264 learning.py:507] global step 19703: loss = 0.0913 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 19704: loss = 0.1487 (0.336 sec/step)\n",
            "I0923 10:09:21.084045 139631849019264 learning.py:507] global step 19704: loss = 0.1487 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 19705: loss = 0.0982 (0.327 sec/step)\n",
            "I0923 10:09:21.413114 139631849019264 learning.py:507] global step 19705: loss = 0.0982 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19706: loss = 0.0901 (0.336 sec/step)\n",
            "I0923 10:09:21.751467 139631849019264 learning.py:507] global step 19706: loss = 0.0901 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 19707: loss = 0.0359 (0.366 sec/step)\n",
            "I0923 10:09:22.119535 139631849019264 learning.py:507] global step 19707: loss = 0.0359 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 19708: loss = 0.0431 (0.298 sec/step)\n",
            "I0923 10:09:22.418915 139631849019264 learning.py:507] global step 19708: loss = 0.0431 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 19709: loss = 0.0891 (0.325 sec/step)\n",
            "I0923 10:09:22.745724 139631849019264 learning.py:507] global step 19709: loss = 0.0891 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 19710: loss = 0.0788 (0.327 sec/step)\n",
            "I0923 10:09:23.075363 139631849019264 learning.py:507] global step 19710: loss = 0.0788 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19711: loss = 0.0318 (0.307 sec/step)\n",
            "I0923 10:09:23.383746 139631849019264 learning.py:507] global step 19711: loss = 0.0318 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 19712: loss = 0.0424 (0.297 sec/step)\n",
            "I0923 10:09:23.682676 139631849019264 learning.py:507] global step 19712: loss = 0.0424 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 19713: loss = 0.0572 (0.328 sec/step)\n",
            "I0923 10:09:24.012682 139631849019264 learning.py:507] global step 19713: loss = 0.0572 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 19714: loss = 0.1041 (0.347 sec/step)\n",
            "I0923 10:09:24.361652 139631849019264 learning.py:507] global step 19714: loss = 0.1041 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 19715: loss = 0.0870 (0.320 sec/step)\n",
            "I0923 10:09:24.684130 139631849019264 learning.py:507] global step 19715: loss = 0.0870 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19716: loss = 0.1090 (0.345 sec/step)\n",
            "I0923 10:09:25.030659 139631849019264 learning.py:507] global step 19716: loss = 0.1090 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 19717: loss = 0.0468 (0.286 sec/step)\n",
            "I0923 10:09:25.318416 139631849019264 learning.py:507] global step 19717: loss = 0.0468 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 19718: loss = 0.0644 (0.340 sec/step)\n",
            "I0923 10:09:25.660470 139631849019264 learning.py:507] global step 19718: loss = 0.0644 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 19719: loss = 0.1818 (0.313 sec/step)\n",
            "I0923 10:09:25.975269 139631849019264 learning.py:507] global step 19719: loss = 0.1818 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 19720: loss = 0.0363 (0.328 sec/step)\n",
            "I0923 10:09:26.305170 139631849019264 learning.py:507] global step 19720: loss = 0.0363 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 19721: loss = 0.0683 (0.291 sec/step)\n",
            "I0923 10:09:26.598947 139631849019264 learning.py:507] global step 19721: loss = 0.0683 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 19722: loss = 0.0654 (0.312 sec/step)\n",
            "I0923 10:09:26.913381 139631849019264 learning.py:507] global step 19722: loss = 0.0654 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 19723: loss = 0.0720 (0.318 sec/step)\n",
            "I0923 10:09:27.233187 139631849019264 learning.py:507] global step 19723: loss = 0.0720 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 19724: loss = 0.0856 (0.328 sec/step)\n",
            "I0923 10:09:27.563463 139631849019264 learning.py:507] global step 19724: loss = 0.0856 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 19725: loss = 0.1220 (0.323 sec/step)\n",
            "I0923 10:09:27.888134 139631849019264 learning.py:507] global step 19725: loss = 0.1220 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 19726: loss = 0.0708 (0.324 sec/step)\n",
            "I0923 10:09:28.213723 139631849019264 learning.py:507] global step 19726: loss = 0.0708 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 19727: loss = 0.0952 (0.266 sec/step)\n",
            "I0923 10:09:28.481622 139631849019264 learning.py:507] global step 19727: loss = 0.0952 (0.266 sec/step)\n",
            "INFO:tensorflow:global step 19728: loss = 0.0622 (0.292 sec/step)\n",
            "I0923 10:09:28.775646 139631849019264 learning.py:507] global step 19728: loss = 0.0622 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19729: loss = 0.0479 (0.366 sec/step)\n",
            "I0923 10:09:29.143078 139631849019264 learning.py:507] global step 19729: loss = 0.0479 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 19730: loss = 0.0456 (0.330 sec/step)\n",
            "I0923 10:09:29.475145 139631849019264 learning.py:507] global step 19730: loss = 0.0456 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 19731: loss = 0.1151 (0.319 sec/step)\n",
            "I0923 10:09:29.795763 139631849019264 learning.py:507] global step 19731: loss = 0.1151 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 19732: loss = 0.0615 (0.336 sec/step)\n",
            "I0923 10:09:30.133708 139631849019264 learning.py:507] global step 19732: loss = 0.0615 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 19733: loss = 0.0408 (0.311 sec/step)\n",
            "I0923 10:09:30.446028 139631849019264 learning.py:507] global step 19733: loss = 0.0408 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 19734: loss = 0.0877 (0.431 sec/step)\n",
            "I0923 10:09:30.879413 139631849019264 learning.py:507] global step 19734: loss = 0.0877 (0.431 sec/step)\n",
            "INFO:tensorflow:global step 19735: loss = 0.0329 (0.321 sec/step)\n",
            "I0923 10:09:31.204812 139631849019264 learning.py:507] global step 19735: loss = 0.0329 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 19736: loss = 0.0526 (0.270 sec/step)\n",
            "I0923 10:09:31.476106 139631849019264 learning.py:507] global step 19736: loss = 0.0526 (0.270 sec/step)\n",
            "INFO:tensorflow:global step 19737: loss = 0.1231 (0.345 sec/step)\n",
            "I0923 10:09:31.822599 139631849019264 learning.py:507] global step 19737: loss = 0.1231 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 19738: loss = 0.0536 (0.336 sec/step)\n",
            "I0923 10:09:32.160523 139631849019264 learning.py:507] global step 19738: loss = 0.0536 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 19739: loss = 0.0724 (0.284 sec/step)\n",
            "I0923 10:09:32.446295 139631849019264 learning.py:507] global step 19739: loss = 0.0724 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19740: loss = 0.0835 (0.345 sec/step)\n",
            "I0923 10:09:32.792930 139631849019264 learning.py:507] global step 19740: loss = 0.0835 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 19741: loss = 0.0415 (0.280 sec/step)\n",
            "I0923 10:09:33.075160 139631849019264 learning.py:507] global step 19741: loss = 0.0415 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 19742: loss = 0.1428 (0.321 sec/step)\n",
            "I0923 10:09:33.398488 139631849019264 learning.py:507] global step 19742: loss = 0.1428 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 19743: loss = 0.0495 (0.314 sec/step)\n",
            "I0923 10:09:33.713898 139631849019264 learning.py:507] global step 19743: loss = 0.0495 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 19744: loss = 0.0422 (0.303 sec/step)\n",
            "I0923 10:09:34.019043 139631849019264 learning.py:507] global step 19744: loss = 0.0422 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 19745: loss = 0.1378 (0.289 sec/step)\n",
            "I0923 10:09:34.310146 139631849019264 learning.py:507] global step 19745: loss = 0.1378 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 19746: loss = 0.0605 (0.299 sec/step)\n",
            "I0923 10:09:34.611020 139631849019264 learning.py:507] global step 19746: loss = 0.0605 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 19747: loss = 0.0621 (0.328 sec/step)\n",
            "I0923 10:09:34.940972 139631849019264 learning.py:507] global step 19747: loss = 0.0621 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 19748: loss = 0.0787 (0.290 sec/step)\n",
            "I0923 10:09:35.232434 139631849019264 learning.py:507] global step 19748: loss = 0.0787 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 19749: loss = 0.1194 (0.285 sec/step)\n",
            "I0923 10:09:35.518975 139631849019264 learning.py:507] global step 19749: loss = 0.1194 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 19750: loss = 0.0827 (0.295 sec/step)\n",
            "I0923 10:09:35.815881 139631849019264 learning.py:507] global step 19750: loss = 0.0827 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 19751: loss = 0.0688 (0.298 sec/step)\n",
            "I0923 10:09:36.120205 139631849019264 learning.py:507] global step 19751: loss = 0.0688 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 19752: loss = 0.1441 (0.324 sec/step)\n",
            "I0923 10:09:36.445916 139631849019264 learning.py:507] global step 19752: loss = 0.1441 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 19753: loss = 0.0829 (0.336 sec/step)\n",
            "I0923 10:09:36.784213 139631849019264 learning.py:507] global step 19753: loss = 0.0829 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 19754: loss = 0.1060 (0.280 sec/step)\n",
            "I0923 10:09:37.065645 139631849019264 learning.py:507] global step 19754: loss = 0.1060 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 19755: loss = 0.5674 (0.309 sec/step)\n",
            "I0923 10:09:37.377593 139631849019264 learning.py:507] global step 19755: loss = 0.5674 (0.309 sec/step)\n",
            "INFO:tensorflow:global step 19756: loss = 0.0843 (0.283 sec/step)\n",
            "I0923 10:09:37.662420 139631849019264 learning.py:507] global step 19756: loss = 0.0843 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 19757: loss = 0.0507 (0.327 sec/step)\n",
            "I0923 10:09:37.991154 139631849019264 learning.py:507] global step 19757: loss = 0.0507 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19758: loss = 0.0269 (0.293 sec/step)\n",
            "I0923 10:09:38.286206 139631849019264 learning.py:507] global step 19758: loss = 0.0269 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 19759: loss = 0.0453 (0.308 sec/step)\n",
            "I0923 10:09:38.596378 139631849019264 learning.py:507] global step 19759: loss = 0.0453 (0.308 sec/step)\n",
            "INFO:tensorflow:global step 19760: loss = 0.0839 (0.322 sec/step)\n",
            "I0923 10:09:38.921201 139631849019264 learning.py:507] global step 19760: loss = 0.0839 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 19761: loss = 0.0414 (0.356 sec/step)\n",
            "I0923 10:09:39.280026 139631849019264 learning.py:507] global step 19761: loss = 0.0414 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 19762: loss = 0.1564 (0.373 sec/step)\n",
            "I0923 10:09:39.655215 139631849019264 learning.py:507] global step 19762: loss = 0.1564 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 19763: loss = 0.0284 (0.322 sec/step)\n",
            "I0923 10:09:39.979387 139631849019264 learning.py:507] global step 19763: loss = 0.0284 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 19764: loss = 0.1711 (0.293 sec/step)\n",
            "I0923 10:09:40.274353 139631849019264 learning.py:507] global step 19764: loss = 0.1711 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 19765: loss = 0.0505 (0.310 sec/step)\n",
            "I0923 10:09:40.586675 139631849019264 learning.py:507] global step 19765: loss = 0.0505 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 19766: loss = 0.0402 (0.324 sec/step)\n",
            "I0923 10:09:40.912126 139631849019264 learning.py:507] global step 19766: loss = 0.0402 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 19767: loss = 0.0245 (0.320 sec/step)\n",
            "I0923 10:09:41.234210 139631849019264 learning.py:507] global step 19767: loss = 0.0245 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19768: loss = 0.2106 (0.373 sec/step)\n",
            "I0923 10:09:41.609116 139631849019264 learning.py:507] global step 19768: loss = 0.2106 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 19769: loss = 0.0798 (0.348 sec/step)\n",
            "I0923 10:09:41.958858 139631849019264 learning.py:507] global step 19769: loss = 0.0798 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 19770: loss = 0.0433 (0.335 sec/step)\n",
            "I0923 10:09:42.295286 139631849019264 learning.py:507] global step 19770: loss = 0.0433 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 19771: loss = 0.0224 (0.309 sec/step)\n",
            "I0923 10:09:42.605593 139631849019264 learning.py:507] global step 19771: loss = 0.0224 (0.309 sec/step)\n",
            "INFO:tensorflow:global step 19772: loss = 0.1021 (0.324 sec/step)\n",
            "I0923 10:09:42.931558 139631849019264 learning.py:507] global step 19772: loss = 0.1021 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 19773: loss = 0.0629 (0.356 sec/step)\n",
            "I0923 10:09:43.289717 139631849019264 learning.py:507] global step 19773: loss = 0.0629 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 19774: loss = 0.0937 (0.292 sec/step)\n",
            "I0923 10:09:43.583990 139631849019264 learning.py:507] global step 19774: loss = 0.0937 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19775: loss = 0.0988 (0.292 sec/step)\n",
            "I0923 10:09:43.877770 139631849019264 learning.py:507] global step 19775: loss = 0.0988 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19776: loss = 0.1061 (0.284 sec/step)\n",
            "I0923 10:09:44.163622 139631849019264 learning.py:507] global step 19776: loss = 0.1061 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19777: loss = 0.0926 (0.306 sec/step)\n",
            "I0923 10:09:44.470970 139631849019264 learning.py:507] global step 19777: loss = 0.0926 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 19778: loss = 0.1467 (0.320 sec/step)\n",
            "I0923 10:09:44.793094 139631849019264 learning.py:507] global step 19778: loss = 0.1467 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19779: loss = 0.0585 (0.326 sec/step)\n",
            "I0923 10:09:45.120808 139631849019264 learning.py:507] global step 19779: loss = 0.0585 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 19780: loss = 0.0645 (0.321 sec/step)\n",
            "I0923 10:09:45.443346 139631849019264 learning.py:507] global step 19780: loss = 0.0645 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 19781: loss = 0.1178 (0.326 sec/step)\n",
            "I0923 10:09:45.771310 139631849019264 learning.py:507] global step 19781: loss = 0.1178 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 19782: loss = 0.0982 (0.272 sec/step)\n",
            "I0923 10:09:46.045206 139631849019264 learning.py:507] global step 19782: loss = 0.0982 (0.272 sec/step)\n",
            "INFO:tensorflow:global step 19783: loss = 0.1185 (0.324 sec/step)\n",
            "I0923 10:09:46.371019 139631849019264 learning.py:507] global step 19783: loss = 0.1185 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 19784: loss = 0.0650 (0.298 sec/step)\n",
            "I0923 10:09:46.670530 139631849019264 learning.py:507] global step 19784: loss = 0.0650 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 19785: loss = 0.1793 (0.272 sec/step)\n",
            "I0923 10:09:46.943880 139631849019264 learning.py:507] global step 19785: loss = 0.1793 (0.272 sec/step)\n",
            "INFO:tensorflow:global step 19786: loss = 0.1324 (0.306 sec/step)\n",
            "I0923 10:09:47.251091 139631849019264 learning.py:507] global step 19786: loss = 0.1324 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 19787: loss = 0.0768 (0.336 sec/step)\n",
            "I0923 10:09:47.588925 139631849019264 learning.py:507] global step 19787: loss = 0.0768 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 19788: loss = 0.0632 (0.325 sec/step)\n",
            "I0923 10:09:47.915823 139631849019264 learning.py:507] global step 19788: loss = 0.0632 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 19789: loss = 0.1043 (0.332 sec/step)\n",
            "I0923 10:09:48.249574 139631849019264 learning.py:507] global step 19789: loss = 0.1043 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 19790: loss = 0.2406 (0.326 sec/step)\n",
            "I0923 10:09:48.577518 139631849019264 learning.py:507] global step 19790: loss = 0.2406 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 19791: loss = 0.0545 (0.278 sec/step)\n",
            "I0923 10:09:48.857346 139631849019264 learning.py:507] global step 19791: loss = 0.0545 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 19792: loss = 0.1124 (0.330 sec/step)\n",
            "I0923 10:09:49.189296 139631849019264 learning.py:507] global step 19792: loss = 0.1124 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 19793: loss = 0.0344 (0.333 sec/step)\n",
            "I0923 10:09:49.524600 139631849019264 learning.py:507] global step 19793: loss = 0.0344 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 19794: loss = 0.0774 (0.332 sec/step)\n",
            "I0923 10:09:49.858287 139631849019264 learning.py:507] global step 19794: loss = 0.0774 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 19795: loss = 0.0537 (0.341 sec/step)\n",
            "I0923 10:09:50.201312 139631849019264 learning.py:507] global step 19795: loss = 0.0537 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 19796: loss = 0.0659 (0.331 sec/step)\n",
            "I0923 10:09:50.534343 139631849019264 learning.py:507] global step 19796: loss = 0.0659 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 19797: loss = 0.0394 (0.295 sec/step)\n",
            "I0923 10:09:50.831496 139631849019264 learning.py:507] global step 19797: loss = 0.0394 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 19798: loss = 0.0650 (0.326 sec/step)\n",
            "I0923 10:09:51.158934 139631849019264 learning.py:507] global step 19798: loss = 0.0650 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 19799: loss = 0.1021 (0.350 sec/step)\n",
            "I0923 10:09:51.511106 139631849019264 learning.py:507] global step 19799: loss = 0.1021 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 19800: loss = 0.0839 (0.384 sec/step)\n",
            "I0923 10:09:51.896718 139631849019264 learning.py:507] global step 19800: loss = 0.0839 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 19801: loss = 0.0998 (0.297 sec/step)\n",
            "I0923 10:09:52.195458 139631849019264 learning.py:507] global step 19801: loss = 0.0998 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 19802: loss = 0.1336 (0.339 sec/step)\n",
            "I0923 10:09:52.536045 139631849019264 learning.py:507] global step 19802: loss = 0.1336 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 19803: loss = 0.1690 (0.366 sec/step)\n",
            "I0923 10:09:52.903957 139631849019264 learning.py:507] global step 19803: loss = 0.1690 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 19804: loss = 0.0772 (0.328 sec/step)\n",
            "I0923 10:09:53.233420 139631849019264 learning.py:507] global step 19804: loss = 0.0772 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 19805: loss = 0.2158 (0.284 sec/step)\n",
            "I0923 10:09:53.519219 139631849019264 learning.py:507] global step 19805: loss = 0.2158 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19806: loss = 0.1917 (0.361 sec/step)\n",
            "I0923 10:09:53.882105 139631849019264 learning.py:507] global step 19806: loss = 0.1917 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 19807: loss = 0.0682 (0.349 sec/step)\n",
            "I0923 10:09:54.232763 139631849019264 learning.py:507] global step 19807: loss = 0.0682 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 19808: loss = 0.0848 (0.350 sec/step)\n",
            "I0923 10:09:54.584755 139631849019264 learning.py:507] global step 19808: loss = 0.0848 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 19809: loss = 0.1122 (0.296 sec/step)\n",
            "I0923 10:09:54.882890 139631849019264 learning.py:507] global step 19809: loss = 0.1122 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 19810: loss = 0.1205 (0.298 sec/step)\n",
            "I0923 10:09:55.183299 139631849019264 learning.py:507] global step 19810: loss = 0.1205 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 19811: loss = 0.0424 (0.354 sec/step)\n",
            "I0923 10:09:55.539037 139631849019264 learning.py:507] global step 19811: loss = 0.0424 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 19812: loss = 0.0877 (0.340 sec/step)\n",
            "I0923 10:09:55.881143 139631849019264 learning.py:507] global step 19812: loss = 0.0877 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 19813: loss = 0.0610 (0.281 sec/step)\n",
            "I0923 10:09:56.164489 139631849019264 learning.py:507] global step 19813: loss = 0.0610 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 19814: loss = 0.1200 (0.344 sec/step)\n",
            "I0923 10:09:56.510792 139631849019264 learning.py:507] global step 19814: loss = 0.1200 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 19815: loss = 0.0855 (0.333 sec/step)\n",
            "I0923 10:09:56.846092 139631849019264 learning.py:507] global step 19815: loss = 0.0855 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 19816: loss = 0.0729 (0.285 sec/step)\n",
            "I0923 10:09:57.132381 139631849019264 learning.py:507] global step 19816: loss = 0.0729 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 19817: loss = 0.2610 (0.304 sec/step)\n",
            "I0923 10:09:57.437981 139631849019264 learning.py:507] global step 19817: loss = 0.2610 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 19818: loss = 0.1183 (0.333 sec/step)\n",
            "I0923 10:09:57.772304 139631849019264 learning.py:507] global step 19818: loss = 0.1183 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 19819: loss = 0.1588 (0.315 sec/step)\n",
            "I0923 10:09:58.089191 139631849019264 learning.py:507] global step 19819: loss = 0.1588 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 19820: loss = 0.1946 (0.335 sec/step)\n",
            "I0923 10:09:58.426515 139631849019264 learning.py:507] global step 19820: loss = 0.1946 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 19821: loss = 0.1483 (0.289 sec/step)\n",
            "I0923 10:09:58.717146 139631849019264 learning.py:507] global step 19821: loss = 0.1483 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 19822: loss = 0.1441 (0.278 sec/step)\n",
            "I0923 10:09:58.997167 139631849019264 learning.py:507] global step 19822: loss = 0.1441 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 19823: loss = 0.1201 (0.316 sec/step)\n",
            "I0923 10:09:59.314823 139631849019264 learning.py:507] global step 19823: loss = 0.1201 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 19824: loss = 0.1129 (0.303 sec/step)\n",
            "I0923 10:09:59.619729 139631849019264 learning.py:507] global step 19824: loss = 0.1129 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 19825: loss = 0.0603 (0.283 sec/step)\n",
            "I0923 10:09:59.904574 139631849019264 learning.py:507] global step 19825: loss = 0.0603 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 19826: loss = 0.0694 (0.288 sec/step)\n",
            "I0923 10:10:00.194274 139631849019264 learning.py:507] global step 19826: loss = 0.0694 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 19827: loss = 0.0896 (0.332 sec/step)\n",
            "I0923 10:10:00.528358 139631849019264 learning.py:507] global step 19827: loss = 0.0896 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 19828: loss = 0.0482 (0.353 sec/step)\n",
            "I0923 10:10:00.883125 139631849019264 learning.py:507] global step 19828: loss = 0.0482 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 19829: loss = 0.0809 (0.327 sec/step)\n",
            "I0923 10:10:01.212502 139631849019264 learning.py:507] global step 19829: loss = 0.0809 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19830: loss = 0.0395 (0.319 sec/step)\n",
            "I0923 10:10:01.533554 139631849019264 learning.py:507] global step 19830: loss = 0.0395 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 19831: loss = 0.1137 (0.308 sec/step)\n",
            "I0923 10:10:01.843612 139631849019264 learning.py:507] global step 19831: loss = 0.1137 (0.308 sec/step)\n",
            "INFO:tensorflow:global step 19832: loss = 0.0873 (0.327 sec/step)\n",
            "I0923 10:10:02.172778 139631849019264 learning.py:507] global step 19832: loss = 0.0873 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19833: loss = 0.2880 (0.333 sec/step)\n",
            "I0923 10:10:02.507593 139631849019264 learning.py:507] global step 19833: loss = 0.2880 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 19834: loss = 0.0717 (0.321 sec/step)\n",
            "I0923 10:10:02.830632 139631849019264 learning.py:507] global step 19834: loss = 0.0717 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 19835: loss = 0.0893 (0.315 sec/step)\n",
            "I0923 10:10:03.147220 139631849019264 learning.py:507] global step 19835: loss = 0.0893 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 19836: loss = 0.0564 (0.285 sec/step)\n",
            "I0923 10:10:03.434130 139631849019264 learning.py:507] global step 19836: loss = 0.0564 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 19837: loss = 0.0886 (0.319 sec/step)\n",
            "I0923 10:10:03.754549 139631849019264 learning.py:507] global step 19837: loss = 0.0886 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 19838: loss = 0.0915 (0.292 sec/step)\n",
            "I0923 10:10:04.048236 139631849019264 learning.py:507] global step 19838: loss = 0.0915 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19839: loss = 0.0783 (0.325 sec/step)\n",
            "I0923 10:10:04.375249 139631849019264 learning.py:507] global step 19839: loss = 0.0783 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 19840: loss = 0.0429 (0.313 sec/step)\n",
            "I0923 10:10:04.691869 139631849019264 learning.py:507] global step 19840: loss = 0.0429 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 19841: loss = 0.1035 (0.307 sec/step)\n",
            "I0923 10:10:05.000119 139631849019264 learning.py:507] global step 19841: loss = 0.1035 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 19842: loss = 0.1064 (0.302 sec/step)\n",
            "I0923 10:10:05.304191 139631849019264 learning.py:507] global step 19842: loss = 0.1064 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 19843: loss = 0.1145 (0.332 sec/step)\n",
            "I0923 10:10:05.637929 139631849019264 learning.py:507] global step 19843: loss = 0.1145 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 19844: loss = 0.1285 (0.281 sec/step)\n",
            "I0923 10:10:05.922152 139631849019264 learning.py:507] global step 19844: loss = 0.1285 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 19845: loss = 0.0947 (0.290 sec/step)\n",
            "I0923 10:10:06.214354 139631849019264 learning.py:507] global step 19845: loss = 0.0947 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 19846: loss = 0.0848 (0.332 sec/step)\n",
            "I0923 10:10:06.548686 139631849019264 learning.py:507] global step 19846: loss = 0.0848 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 19847: loss = 0.1868 (0.348 sec/step)\n",
            "I0923 10:10:06.899040 139631849019264 learning.py:507] global step 19847: loss = 0.1868 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 19848: loss = 0.0363 (0.278 sec/step)\n",
            "I0923 10:10:07.179112 139631849019264 learning.py:507] global step 19848: loss = 0.0363 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 19849: loss = 0.1260 (0.273 sec/step)\n",
            "I0923 10:10:07.453736 139631849019264 learning.py:507] global step 19849: loss = 0.1260 (0.273 sec/step)\n",
            "INFO:tensorflow:global step 19850: loss = 0.1034 (0.372 sec/step)\n",
            "I0923 10:10:07.828327 139631849019264 learning.py:507] global step 19850: loss = 0.1034 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 19851: loss = 0.1219 (0.334 sec/step)\n",
            "I0923 10:10:08.165409 139631849019264 learning.py:507] global step 19851: loss = 0.1219 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 19852: loss = 0.0718 (0.339 sec/step)\n",
            "I0923 10:10:08.505924 139631849019264 learning.py:507] global step 19852: loss = 0.0718 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 19853: loss = 0.0456 (0.274 sec/step)\n",
            "I0923 10:10:08.782346 139631849019264 learning.py:507] global step 19853: loss = 0.0456 (0.274 sec/step)\n",
            "INFO:tensorflow:global step 19854: loss = 0.0458 (0.326 sec/step)\n",
            "I0923 10:10:09.109847 139631849019264 learning.py:507] global step 19854: loss = 0.0458 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 19855: loss = 0.0813 (0.341 sec/step)\n",
            "I0923 10:10:09.452425 139631849019264 learning.py:507] global step 19855: loss = 0.0813 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 19856: loss = 0.1873 (0.289 sec/step)\n",
            "I0923 10:10:09.746319 139631849019264 learning.py:507] global step 19856: loss = 0.1873 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 19857: loss = 0.1282 (0.326 sec/step)\n",
            "I0923 10:10:10.074193 139631849019264 learning.py:507] global step 19857: loss = 0.1282 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 19858: loss = 0.0317 (0.288 sec/step)\n",
            "I0923 10:10:10.364018 139631849019264 learning.py:507] global step 19858: loss = 0.0317 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 19859: loss = 0.0445 (0.291 sec/step)\n",
            "I0923 10:10:10.656324 139631849019264 learning.py:507] global step 19859: loss = 0.0445 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 19860: loss = 0.1836 (0.345 sec/step)\n",
            "I0923 10:10:11.002807 139631849019264 learning.py:507] global step 19860: loss = 0.1836 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 19861: loss = 0.0787 (0.329 sec/step)\n",
            "I0923 10:10:11.334107 139631849019264 learning.py:507] global step 19861: loss = 0.0787 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 19862: loss = 0.1485 (0.341 sec/step)\n",
            "I0923 10:10:11.676571 139631849019264 learning.py:507] global step 19862: loss = 0.1485 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 19863: loss = 0.0330 (0.331 sec/step)\n",
            "I0923 10:10:12.009145 139631849019264 learning.py:507] global step 19863: loss = 0.0330 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 19864: loss = 0.1897 (0.312 sec/step)\n",
            "I0923 10:10:12.323236 139631849019264 learning.py:507] global step 19864: loss = 0.1897 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 19865: loss = 0.0479 (0.319 sec/step)\n",
            "I0923 10:10:12.644088 139631849019264 learning.py:507] global step 19865: loss = 0.0479 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 19866: loss = 0.0316 (0.330 sec/step)\n",
            "I0923 10:10:12.975580 139631849019264 learning.py:507] global step 19866: loss = 0.0316 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 19867: loss = 0.0692 (0.354 sec/step)\n",
            "I0923 10:10:13.330725 139631849019264 learning.py:507] global step 19867: loss = 0.0692 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 19868: loss = 0.0783 (0.271 sec/step)\n",
            "I0923 10:10:13.603862 139631849019264 learning.py:507] global step 19868: loss = 0.0783 (0.271 sec/step)\n",
            "INFO:tensorflow:global step 19869: loss = 0.1468 (0.320 sec/step)\n",
            "I0923 10:10:13.925713 139631849019264 learning.py:507] global step 19869: loss = 0.1468 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19870: loss = 0.0615 (0.305 sec/step)\n",
            "I0923 10:10:14.232503 139631849019264 learning.py:507] global step 19870: loss = 0.0615 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 19871: loss = 0.2741 (0.304 sec/step)\n",
            "I0923 10:10:14.538239 139631849019264 learning.py:507] global step 19871: loss = 0.2741 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 19872: loss = 0.1229 (0.350 sec/step)\n",
            "I0923 10:10:14.889596 139631849019264 learning.py:507] global step 19872: loss = 0.1229 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 19873: loss = 0.1028 (0.387 sec/step)\n",
            "I0923 10:10:15.278401 139631849019264 learning.py:507] global step 19873: loss = 0.1028 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 19874: loss = 0.0611 (0.285 sec/step)\n",
            "I0923 10:10:15.564855 139631849019264 learning.py:507] global step 19874: loss = 0.0611 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 19875: loss = 0.1574 (0.320 sec/step)\n",
            "I0923 10:10:15.891168 139631849019264 learning.py:507] global step 19875: loss = 0.1574 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19876: loss = 0.0404 (0.305 sec/step)\n",
            "I0923 10:10:16.199302 139631849019264 learning.py:507] global step 19876: loss = 0.0404 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 19877: loss = 0.1236 (0.308 sec/step)\n",
            "I0923 10:10:16.509362 139631849019264 learning.py:507] global step 19877: loss = 0.1236 (0.308 sec/step)\n",
            "INFO:tensorflow:global step 19878: loss = 0.0970 (0.352 sec/step)\n",
            "I0923 10:10:16.862945 139631849019264 learning.py:507] global step 19878: loss = 0.0970 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 19879: loss = 0.1423 (0.348 sec/step)\n",
            "I0923 10:10:17.212467 139631849019264 learning.py:507] global step 19879: loss = 0.1423 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 19880: loss = 0.0338 (0.284 sec/step)\n",
            "I0923 10:10:17.498020 139631849019264 learning.py:507] global step 19880: loss = 0.0338 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19881: loss = 0.1710 (0.296 sec/step)\n",
            "I0923 10:10:17.796212 139631849019264 learning.py:507] global step 19881: loss = 0.1710 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 19882: loss = 0.0612 (0.391 sec/step)\n",
            "I0923 10:10:18.188919 139631849019264 learning.py:507] global step 19882: loss = 0.0612 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 19883: loss = 0.0560 (0.544 sec/step)\n",
            "I0923 10:10:18.736848 139631849019264 learning.py:507] global step 19883: loss = 0.0560 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 19884: loss = 0.0918 (0.386 sec/step)\n",
            "I0923 10:10:19.140599 139631849019264 learning.py:507] global step 19884: loss = 0.0918 (0.386 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 19884.\n",
            "I0923 10:10:19.246506 139628630939392 supervisor.py:1050] Recording summary at step 19884.\n",
            "INFO:tensorflow:global step 19885: loss = 0.0526 (0.318 sec/step)\n",
            "I0923 10:10:19.475585 139631849019264 learning.py:507] global step 19885: loss = 0.0526 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 19886: loss = 0.0438 (0.272 sec/step)\n",
            "I0923 10:10:19.748934 139631849019264 learning.py:507] global step 19886: loss = 0.0438 (0.272 sec/step)\n",
            "INFO:tensorflow:global step 19887: loss = 0.0726 (0.339 sec/step)\n",
            "I0923 10:10:20.089917 139631849019264 learning.py:507] global step 19887: loss = 0.0726 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 19888: loss = 0.1083 (0.326 sec/step)\n",
            "I0923 10:10:20.417341 139631849019264 learning.py:507] global step 19888: loss = 0.1083 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 19889: loss = 0.0535 (0.312 sec/step)\n",
            "I0923 10:10:20.731031 139631849019264 learning.py:507] global step 19889: loss = 0.0535 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 19890: loss = 0.0579 (0.353 sec/step)\n",
            "I0923 10:10:21.085439 139631849019264 learning.py:507] global step 19890: loss = 0.0579 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 19891: loss = 0.0821 (0.378 sec/step)\n",
            "I0923 10:10:21.465273 139631849019264 learning.py:507] global step 19891: loss = 0.0821 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 19892: loss = 0.0440 (0.316 sec/step)\n",
            "I0923 10:10:21.783343 139631849019264 learning.py:507] global step 19892: loss = 0.0440 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 19893: loss = 0.1078 (0.347 sec/step)\n",
            "I0923 10:10:22.132050 139631849019264 learning.py:507] global step 19893: loss = 0.1078 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 19894: loss = 0.0575 (0.284 sec/step)\n",
            "I0923 10:10:22.417917 139631849019264 learning.py:507] global step 19894: loss = 0.0575 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19895: loss = 0.2297 (0.289 sec/step)\n",
            "I0923 10:10:22.709078 139631849019264 learning.py:507] global step 19895: loss = 0.2297 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 19896: loss = 0.1449 (0.322 sec/step)\n",
            "I0923 10:10:23.033704 139631849019264 learning.py:507] global step 19896: loss = 0.1449 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 19897: loss = 0.1506 (0.352 sec/step)\n",
            "I0923 10:10:23.387406 139631849019264 learning.py:507] global step 19897: loss = 0.1506 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 19898: loss = 0.2099 (0.313 sec/step)\n",
            "I0923 10:10:23.702484 139631849019264 learning.py:507] global step 19898: loss = 0.2099 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 19899: loss = 0.1052 (0.339 sec/step)\n",
            "I0923 10:10:24.046051 139631849019264 learning.py:507] global step 19899: loss = 0.1052 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 19900: loss = 0.0567 (0.345 sec/step)\n",
            "I0923 10:10:24.394242 139631849019264 learning.py:507] global step 19900: loss = 0.0567 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 19901: loss = 0.0619 (0.281 sec/step)\n",
            "I0923 10:10:24.676710 139631849019264 learning.py:507] global step 19901: loss = 0.0619 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 19902: loss = 0.0433 (0.295 sec/step)\n",
            "I0923 10:10:24.973961 139631849019264 learning.py:507] global step 19902: loss = 0.0433 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 19903: loss = 0.0587 (0.288 sec/step)\n",
            "I0923 10:10:25.263736 139631849019264 learning.py:507] global step 19903: loss = 0.0587 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 19904: loss = 0.0884 (0.292 sec/step)\n",
            "I0923 10:10:25.557723 139631849019264 learning.py:507] global step 19904: loss = 0.0884 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19905: loss = 0.0639 (0.293 sec/step)\n",
            "I0923 10:10:25.852509 139631849019264 learning.py:507] global step 19905: loss = 0.0639 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 19906: loss = 0.1234 (0.324 sec/step)\n",
            "I0923 10:10:26.177947 139631849019264 learning.py:507] global step 19906: loss = 0.1234 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 19907: loss = 0.0535 (0.299 sec/step)\n",
            "I0923 10:10:26.479129 139631849019264 learning.py:507] global step 19907: loss = 0.0535 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 19908: loss = 0.0740 (0.322 sec/step)\n",
            "I0923 10:10:26.803092 139631849019264 learning.py:507] global step 19908: loss = 0.0740 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 19909: loss = 0.0599 (0.319 sec/step)\n",
            "I0923 10:10:27.124125 139631849019264 learning.py:507] global step 19909: loss = 0.0599 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 19910: loss = 0.1217 (0.280 sec/step)\n",
            "I0923 10:10:27.405176 139631849019264 learning.py:507] global step 19910: loss = 0.1217 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 19911: loss = 0.0926 (0.340 sec/step)\n",
            "I0923 10:10:27.746799 139631849019264 learning.py:507] global step 19911: loss = 0.0926 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 19912: loss = 0.1276 (0.312 sec/step)\n",
            "I0923 10:10:28.060729 139631849019264 learning.py:507] global step 19912: loss = 0.1276 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 19913: loss = 0.0352 (0.288 sec/step)\n",
            "I0923 10:10:28.350133 139631849019264 learning.py:507] global step 19913: loss = 0.0352 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 19914: loss = 0.1016 (0.273 sec/step)\n",
            "I0923 10:10:28.625469 139631849019264 learning.py:507] global step 19914: loss = 0.1016 (0.273 sec/step)\n",
            "INFO:tensorflow:global step 19915: loss = 0.1001 (0.518 sec/step)\n",
            "I0923 10:10:29.145369 139631849019264 learning.py:507] global step 19915: loss = 0.1001 (0.518 sec/step)\n",
            "INFO:tensorflow:global step 19916: loss = 0.0359 (0.342 sec/step)\n",
            "I0923 10:10:29.489633 139631849019264 learning.py:507] global step 19916: loss = 0.0359 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 19917: loss = 0.1809 (0.292 sec/step)\n",
            "I0923 10:10:29.782912 139631849019264 learning.py:507] global step 19917: loss = 0.1809 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 19918: loss = 0.1193 (0.269 sec/step)\n",
            "I0923 10:10:30.053956 139631849019264 learning.py:507] global step 19918: loss = 0.1193 (0.269 sec/step)\n",
            "INFO:tensorflow:global step 19919: loss = 0.1410 (0.323 sec/step)\n",
            "I0923 10:10:30.378504 139631849019264 learning.py:507] global step 19919: loss = 0.1410 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 19920: loss = 0.0553 (0.334 sec/step)\n",
            "I0923 10:10:30.714363 139631849019264 learning.py:507] global step 19920: loss = 0.0553 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 19921: loss = 0.1452 (0.289 sec/step)\n",
            "I0923 10:10:31.005101 139631849019264 learning.py:507] global step 19921: loss = 0.1452 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 19922: loss = 0.0889 (0.289 sec/step)\n",
            "I0923 10:10:31.296002 139631849019264 learning.py:507] global step 19922: loss = 0.0889 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 19923: loss = 0.0861 (0.310 sec/step)\n",
            "I0923 10:10:31.607952 139631849019264 learning.py:507] global step 19923: loss = 0.0861 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 19924: loss = 0.0599 (0.286 sec/step)\n",
            "I0923 10:10:31.896397 139631849019264 learning.py:507] global step 19924: loss = 0.0599 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 19925: loss = 0.0806 (0.332 sec/step)\n",
            "I0923 10:10:32.230701 139631849019264 learning.py:507] global step 19925: loss = 0.0806 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 19926: loss = 0.2643 (0.286 sec/step)\n",
            "I0923 10:10:32.518437 139631849019264 learning.py:507] global step 19926: loss = 0.2643 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 19927: loss = 0.1277 (0.332 sec/step)\n",
            "I0923 10:10:32.852216 139631849019264 learning.py:507] global step 19927: loss = 0.1277 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 19928: loss = 0.0867 (0.290 sec/step)\n",
            "I0923 10:10:33.143667 139631849019264 learning.py:507] global step 19928: loss = 0.0867 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 19929: loss = 0.0703 (0.275 sec/step)\n",
            "I0923 10:10:33.420635 139631849019264 learning.py:507] global step 19929: loss = 0.0703 (0.275 sec/step)\n",
            "INFO:tensorflow:global step 19930: loss = 0.0898 (0.363 sec/step)\n",
            "I0923 10:10:33.785675 139631849019264 learning.py:507] global step 19930: loss = 0.0898 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 19931: loss = 0.1531 (0.346 sec/step)\n",
            "I0923 10:10:34.133525 139631849019264 learning.py:507] global step 19931: loss = 0.1531 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 19932: loss = 0.1003 (0.323 sec/step)\n",
            "I0923 10:10:34.458175 139631849019264 learning.py:507] global step 19932: loss = 0.1003 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 19933: loss = 0.1294 (0.323 sec/step)\n",
            "I0923 10:10:34.782589 139631849019264 learning.py:507] global step 19933: loss = 0.1294 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 19934: loss = 0.0923 (0.308 sec/step)\n",
            "I0923 10:10:35.092830 139631849019264 learning.py:507] global step 19934: loss = 0.0923 (0.308 sec/step)\n",
            "INFO:tensorflow:global step 19935: loss = 0.0656 (0.290 sec/step)\n",
            "I0923 10:10:35.385053 139631849019264 learning.py:507] global step 19935: loss = 0.0656 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 19936: loss = 0.1448 (0.339 sec/step)\n",
            "I0923 10:10:35.725655 139631849019264 learning.py:507] global step 19936: loss = 0.1448 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 19937: loss = 0.1550 (0.333 sec/step)\n",
            "I0923 10:10:36.060859 139631849019264 learning.py:507] global step 19937: loss = 0.1550 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 19938: loss = 0.0596 (0.336 sec/step)\n",
            "I0923 10:10:36.398826 139631849019264 learning.py:507] global step 19938: loss = 0.0596 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 19939: loss = 0.0983 (0.384 sec/step)\n",
            "I0923 10:10:36.785151 139631849019264 learning.py:507] global step 19939: loss = 0.0983 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 19940: loss = 0.0639 (0.330 sec/step)\n",
            "I0923 10:10:37.116839 139631849019264 learning.py:507] global step 19940: loss = 0.0639 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 19941: loss = 0.0833 (0.282 sec/step)\n",
            "I0923 10:10:37.400393 139631849019264 learning.py:507] global step 19941: loss = 0.0833 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 19942: loss = 0.0948 (0.317 sec/step)\n",
            "I0923 10:10:37.719155 139631849019264 learning.py:507] global step 19942: loss = 0.0948 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 19943: loss = 0.1110 (0.325 sec/step)\n",
            "I0923 10:10:38.045644 139631849019264 learning.py:507] global step 19943: loss = 0.1110 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 19944: loss = 0.0704 (0.315 sec/step)\n",
            "I0923 10:10:38.362116 139631849019264 learning.py:507] global step 19944: loss = 0.0704 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 19945: loss = 0.1329 (0.286 sec/step)\n",
            "I0923 10:10:38.649845 139631849019264 learning.py:507] global step 19945: loss = 0.1329 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 19946: loss = 0.1172 (0.350 sec/step)\n",
            "I0923 10:10:39.001469 139631849019264 learning.py:507] global step 19946: loss = 0.1172 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 19947: loss = 0.0674 (0.275 sec/step)\n",
            "I0923 10:10:39.278838 139631849019264 learning.py:507] global step 19947: loss = 0.0674 (0.275 sec/step)\n",
            "INFO:tensorflow:global step 19948: loss = 0.0585 (0.345 sec/step)\n",
            "I0923 10:10:39.626000 139631849019264 learning.py:507] global step 19948: loss = 0.0585 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 19949: loss = 0.0913 (0.339 sec/step)\n",
            "I0923 10:10:39.967326 139631849019264 learning.py:507] global step 19949: loss = 0.0913 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 19950: loss = 0.0364 (0.315 sec/step)\n",
            "I0923 10:10:40.284028 139631849019264 learning.py:507] global step 19950: loss = 0.0364 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 19951: loss = 0.0784 (0.290 sec/step)\n",
            "I0923 10:10:40.575436 139631849019264 learning.py:507] global step 19951: loss = 0.0784 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 19952: loss = 0.0581 (0.291 sec/step)\n",
            "I0923 10:10:40.867822 139631849019264 learning.py:507] global step 19952: loss = 0.0581 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 19953: loss = 0.1428 (0.285 sec/step)\n",
            "I0923 10:10:41.154901 139631849019264 learning.py:507] global step 19953: loss = 0.1428 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 19954: loss = 0.0185 (0.315 sec/step)\n",
            "I0923 10:10:41.471783 139631849019264 learning.py:507] global step 19954: loss = 0.0185 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 19955: loss = 0.0667 (0.279 sec/step)\n",
            "I0923 10:10:41.757355 139631849019264 learning.py:507] global step 19955: loss = 0.0667 (0.279 sec/step)\n",
            "INFO:tensorflow:global step 19956: loss = 0.0973 (0.320 sec/step)\n",
            "I0923 10:10:42.079175 139631849019264 learning.py:507] global step 19956: loss = 0.0973 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19957: loss = 0.0815 (0.332 sec/step)\n",
            "I0923 10:10:42.413095 139631849019264 learning.py:507] global step 19957: loss = 0.0815 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 19958: loss = 0.2335 (0.368 sec/step)\n",
            "I0923 10:10:42.783415 139631849019264 learning.py:507] global step 19958: loss = 0.2335 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 19959: loss = 0.0503 (0.322 sec/step)\n",
            "I0923 10:10:43.106767 139631849019264 learning.py:507] global step 19959: loss = 0.0503 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 19960: loss = 0.0715 (0.341 sec/step)\n",
            "I0923 10:10:43.450112 139631849019264 learning.py:507] global step 19960: loss = 0.0715 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 19961: loss = 0.0701 (0.370 sec/step)\n",
            "I0923 10:10:43.822630 139631849019264 learning.py:507] global step 19961: loss = 0.0701 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 19962: loss = 0.0950 (0.329 sec/step)\n",
            "I0923 10:10:44.153603 139631849019264 learning.py:507] global step 19962: loss = 0.0950 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 19963: loss = 0.0739 (0.333 sec/step)\n",
            "I0923 10:10:44.488868 139631849019264 learning.py:507] global step 19963: loss = 0.0739 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 19964: loss = 0.0443 (0.314 sec/step)\n",
            "I0923 10:10:44.804249 139631849019264 learning.py:507] global step 19964: loss = 0.0443 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 19965: loss = 0.1017 (0.352 sec/step)\n",
            "I0923 10:10:45.157614 139631849019264 learning.py:507] global step 19965: loss = 0.1017 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 19966: loss = 0.0922 (0.286 sec/step)\n",
            "I0923 10:10:45.446094 139631849019264 learning.py:507] global step 19966: loss = 0.0922 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 19967: loss = 0.0512 (0.337 sec/step)\n",
            "I0923 10:10:45.785537 139631849019264 learning.py:507] global step 19967: loss = 0.0512 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 19968: loss = 0.2383 (0.303 sec/step)\n",
            "I0923 10:10:46.091467 139631849019264 learning.py:507] global step 19968: loss = 0.2383 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 19969: loss = 0.0847 (0.283 sec/step)\n",
            "I0923 10:10:46.376145 139631849019264 learning.py:507] global step 19969: loss = 0.0847 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 19970: loss = 0.0474 (0.327 sec/step)\n",
            "I0923 10:10:46.705089 139631849019264 learning.py:507] global step 19970: loss = 0.0474 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 19971: loss = 0.2133 (0.282 sec/step)\n",
            "I0923 10:10:46.989101 139631849019264 learning.py:507] global step 19971: loss = 0.2133 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 19972: loss = 0.0598 (0.331 sec/step)\n",
            "I0923 10:10:47.321908 139631849019264 learning.py:507] global step 19972: loss = 0.0598 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 19973: loss = 0.1130 (0.340 sec/step)\n",
            "I0923 10:10:47.664430 139631849019264 learning.py:507] global step 19973: loss = 0.1130 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 19974: loss = 0.0552 (0.334 sec/step)\n",
            "I0923 10:10:48.000183 139631849019264 learning.py:507] global step 19974: loss = 0.0552 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 19975: loss = 0.0505 (0.328 sec/step)\n",
            "I0923 10:10:48.329719 139631849019264 learning.py:507] global step 19975: loss = 0.0505 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 19976: loss = 0.0817 (0.320 sec/step)\n",
            "I0923 10:10:48.651247 139631849019264 learning.py:507] global step 19976: loss = 0.0817 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 19977: loss = 0.0355 (0.274 sec/step)\n",
            "I0923 10:10:48.926881 139631849019264 learning.py:507] global step 19977: loss = 0.0355 (0.274 sec/step)\n",
            "INFO:tensorflow:global step 19978: loss = 0.2187 (0.318 sec/step)\n",
            "I0923 10:10:49.246558 139631849019264 learning.py:507] global step 19978: loss = 0.2187 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 19979: loss = 0.2344 (0.313 sec/step)\n",
            "I0923 10:10:49.561191 139631849019264 learning.py:507] global step 19979: loss = 0.2344 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 19980: loss = 0.0972 (0.297 sec/step)\n",
            "I0923 10:10:49.860341 139631849019264 learning.py:507] global step 19980: loss = 0.0972 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 19981: loss = 0.2421 (0.378 sec/step)\n",
            "I0923 10:10:50.240081 139631849019264 learning.py:507] global step 19981: loss = 0.2421 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 19982: loss = 0.2161 (0.322 sec/step)\n",
            "I0923 10:10:50.563668 139631849019264 learning.py:507] global step 19982: loss = 0.2161 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 19983: loss = 0.0478 (0.314 sec/step)\n",
            "I0923 10:10:50.880032 139631849019264 learning.py:507] global step 19983: loss = 0.0478 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 19984: loss = 0.0940 (0.295 sec/step)\n",
            "I0923 10:10:51.176985 139631849019264 learning.py:507] global step 19984: loss = 0.0940 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 19985: loss = 0.2490 (0.315 sec/step)\n",
            "I0923 10:10:51.493661 139631849019264 learning.py:507] global step 19985: loss = 0.2490 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 19986: loss = 0.0908 (0.329 sec/step)\n",
            "I0923 10:10:51.826618 139631849019264 learning.py:507] global step 19986: loss = 0.0908 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 19987: loss = 0.0728 (0.284 sec/step)\n",
            "I0923 10:10:52.112795 139631849019264 learning.py:507] global step 19987: loss = 0.0728 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 19988: loss = 0.1968 (0.328 sec/step)\n",
            "I0923 10:10:52.443241 139631849019264 learning.py:507] global step 19988: loss = 0.1968 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 19989: loss = 0.0746 (0.287 sec/step)\n",
            "I0923 10:10:52.732285 139631849019264 learning.py:507] global step 19989: loss = 0.0746 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 19990: loss = 0.0512 (0.285 sec/step)\n",
            "I0923 10:10:53.019159 139631849019264 learning.py:507] global step 19990: loss = 0.0512 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 19991: loss = 0.1104 (0.346 sec/step)\n",
            "I0923 10:10:53.367427 139631849019264 learning.py:507] global step 19991: loss = 0.1104 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 19992: loss = 0.0363 (0.299 sec/step)\n",
            "I0923 10:10:53.668170 139631849019264 learning.py:507] global step 19992: loss = 0.0363 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 19993: loss = 0.0424 (0.345 sec/step)\n",
            "I0923 10:10:54.015010 139631849019264 learning.py:507] global step 19993: loss = 0.0424 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 19994: loss = 0.1160 (0.328 sec/step)\n",
            "I0923 10:10:54.345378 139631849019264 learning.py:507] global step 19994: loss = 0.1160 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 19995: loss = 0.1796 (0.331 sec/step)\n",
            "I0923 10:10:54.678470 139631849019264 learning.py:507] global step 19995: loss = 0.1796 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 19996: loss = 0.0868 (0.294 sec/step)\n",
            "I0923 10:10:54.974596 139631849019264 learning.py:507] global step 19996: loss = 0.0868 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 19997: loss = 0.2202 (0.318 sec/step)\n",
            "I0923 10:10:55.295314 139631849019264 learning.py:507] global step 19997: loss = 0.2202 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 19998: loss = 0.0755 (0.312 sec/step)\n",
            "I0923 10:10:55.609184 139631849019264 learning.py:507] global step 19998: loss = 0.0755 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 19999: loss = 0.0712 (0.331 sec/step)\n",
            "I0923 10:10:55.944544 139631849019264 learning.py:507] global step 19999: loss = 0.0712 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 20000: loss = 0.0431 (0.321 sec/step)\n",
            "I0923 10:10:56.267432 139631849019264 learning.py:507] global step 20000: loss = 0.0431 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 20001: loss = 0.0860 (0.327 sec/step)\n",
            "I0923 10:10:56.596246 139631849019264 learning.py:507] global step 20001: loss = 0.0860 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 20002: loss = 0.0718 (0.307 sec/step)\n",
            "I0923 10:10:56.904747 139631849019264 learning.py:507] global step 20002: loss = 0.0718 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 20003: loss = 0.0501 (0.331 sec/step)\n",
            "I0923 10:10:57.237990 139631849019264 learning.py:507] global step 20003: loss = 0.0501 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 20004: loss = 0.0447 (0.352 sec/step)\n",
            "I0923 10:10:57.591392 139631849019264 learning.py:507] global step 20004: loss = 0.0447 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 20005: loss = 0.1307 (0.402 sec/step)\n",
            "I0923 10:10:57.995482 139631849019264 learning.py:507] global step 20005: loss = 0.1307 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 20006: loss = 0.0634 (0.323 sec/step)\n",
            "I0923 10:10:58.320242 139631849019264 learning.py:507] global step 20006: loss = 0.0634 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 20007: loss = 0.1254 (0.299 sec/step)\n",
            "I0923 10:10:58.620591 139631849019264 learning.py:507] global step 20007: loss = 0.1254 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 20008: loss = 0.0833 (0.341 sec/step)\n",
            "I0923 10:10:58.963363 139631849019264 learning.py:507] global step 20008: loss = 0.0833 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 20009: loss = 0.1223 (0.305 sec/step)\n",
            "I0923 10:10:59.270248 139631849019264 learning.py:507] global step 20009: loss = 0.1223 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 20010: loss = 0.3031 (0.297 sec/step)\n",
            "I0923 10:10:59.569459 139631849019264 learning.py:507] global step 20010: loss = 0.3031 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 20011: loss = 0.2687 (0.283 sec/step)\n",
            "I0923 10:10:59.854151 139631849019264 learning.py:507] global step 20011: loss = 0.2687 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 20012: loss = 0.1449 (0.281 sec/step)\n",
            "I0923 10:11:00.137048 139631849019264 learning.py:507] global step 20012: loss = 0.1449 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 20013: loss = 0.1430 (0.278 sec/step)\n",
            "I0923 10:11:00.417337 139631849019264 learning.py:507] global step 20013: loss = 0.1430 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 20014: loss = 0.1132 (0.296 sec/step)\n",
            "I0923 10:11:00.715467 139631849019264 learning.py:507] global step 20014: loss = 0.1132 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 20015: loss = 0.1046 (0.378 sec/step)\n",
            "I0923 10:11:01.094928 139631849019264 learning.py:507] global step 20015: loss = 0.1046 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 20016: loss = 0.0590 (0.335 sec/step)\n",
            "I0923 10:11:01.431954 139631849019264 learning.py:507] global step 20016: loss = 0.0590 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 20017: loss = 0.0906 (0.277 sec/step)\n",
            "I0923 10:11:01.714065 139631849019264 learning.py:507] global step 20017: loss = 0.0906 (0.277 sec/step)\n",
            "INFO:tensorflow:global step 20018: loss = 0.0666 (0.282 sec/step)\n",
            "I0923 10:11:02.001522 139631849019264 learning.py:507] global step 20018: loss = 0.0666 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 20019: loss = 0.0233 (0.337 sec/step)\n",
            "I0923 10:11:02.340610 139631849019264 learning.py:507] global step 20019: loss = 0.0233 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 20020: loss = 0.0653 (0.348 sec/step)\n",
            "I0923 10:11:02.690949 139631849019264 learning.py:507] global step 20020: loss = 0.0653 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 20021: loss = 0.0732 (0.321 sec/step)\n",
            "I0923 10:11:03.013598 139631849019264 learning.py:507] global step 20021: loss = 0.0732 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 20022: loss = 0.2053 (0.277 sec/step)\n",
            "I0923 10:11:03.292833 139631849019264 learning.py:507] global step 20022: loss = 0.2053 (0.277 sec/step)\n",
            "INFO:tensorflow:global step 20023: loss = 0.0711 (0.348 sec/step)\n",
            "I0923 10:11:03.642594 139631849019264 learning.py:507] global step 20023: loss = 0.0711 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 20024: loss = 0.0268 (0.324 sec/step)\n",
            "I0923 10:11:03.968809 139631849019264 learning.py:507] global step 20024: loss = 0.0268 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 20025: loss = 0.0844 (0.293 sec/step)\n",
            "I0923 10:11:04.263252 139631849019264 learning.py:507] global step 20025: loss = 0.0844 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 20026: loss = 0.2428 (0.276 sec/step)\n",
            "I0923 10:11:04.540894 139631849019264 learning.py:507] global step 20026: loss = 0.2428 (0.276 sec/step)\n",
            "INFO:tensorflow:global step 20027: loss = 0.0745 (0.345 sec/step)\n",
            "I0923 10:11:04.887781 139631849019264 learning.py:507] global step 20027: loss = 0.0745 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 20028: loss = 0.0802 (0.309 sec/step)\n",
            "I0923 10:11:05.198620 139631849019264 learning.py:507] global step 20028: loss = 0.0802 (0.309 sec/step)\n",
            "INFO:tensorflow:global step 20029: loss = 0.0768 (0.322 sec/step)\n",
            "I0923 10:11:05.522413 139631849019264 learning.py:507] global step 20029: loss = 0.0768 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 20030: loss = 0.0673 (0.418 sec/step)\n",
            "I0923 10:11:05.942422 139631849019264 learning.py:507] global step 20030: loss = 0.0673 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 20031: loss = 0.1238 (0.317 sec/step)\n",
            "I0923 10:11:06.261221 139631849019264 learning.py:507] global step 20031: loss = 0.1238 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 20032: loss = 0.0556 (0.328 sec/step)\n",
            "I0923 10:11:06.591334 139631849019264 learning.py:507] global step 20032: loss = 0.0556 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 20033: loss = 0.0556 (0.346 sec/step)\n",
            "I0923 10:11:06.938948 139631849019264 learning.py:507] global step 20033: loss = 0.0556 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 20034: loss = 0.0590 (0.281 sec/step)\n",
            "I0923 10:11:07.221510 139631849019264 learning.py:507] global step 20034: loss = 0.0590 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 20035: loss = 0.1226 (0.347 sec/step)\n",
            "I0923 10:11:07.569978 139631849019264 learning.py:507] global step 20035: loss = 0.1226 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 20036: loss = 0.1644 (0.383 sec/step)\n",
            "I0923 10:11:07.955090 139631849019264 learning.py:507] global step 20036: loss = 0.1644 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 20037: loss = 0.0814 (0.333 sec/step)\n",
            "I0923 10:11:08.289632 139631849019264 learning.py:507] global step 20037: loss = 0.0814 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 20038: loss = 0.3021 (0.310 sec/step)\n",
            "I0923 10:11:08.600930 139631849019264 learning.py:507] global step 20038: loss = 0.3021 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 20039: loss = 0.0701 (0.360 sec/step)\n",
            "I0923 10:11:08.963120 139631849019264 learning.py:507] global step 20039: loss = 0.0701 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 20040: loss = 0.1397 (0.376 sec/step)\n",
            "I0923 10:11:09.340985 139631849019264 learning.py:507] global step 20040: loss = 0.1397 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 20041: loss = 0.0815 (0.341 sec/step)\n",
            "I0923 10:11:09.683968 139631849019264 learning.py:507] global step 20041: loss = 0.0815 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 20042: loss = 0.2467 (0.312 sec/step)\n",
            "I0923 10:11:09.997813 139631849019264 learning.py:507] global step 20042: loss = 0.2467 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 20043: loss = 0.1178 (0.296 sec/step)\n",
            "I0923 10:11:10.296024 139631849019264 learning.py:507] global step 20043: loss = 0.1178 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 20044: loss = 0.1199 (0.333 sec/step)\n",
            "I0923 10:11:10.630549 139631849019264 learning.py:507] global step 20044: loss = 0.1199 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 20045: loss = 0.1528 (0.289 sec/step)\n",
            "I0923 10:11:10.921954 139631849019264 learning.py:507] global step 20045: loss = 0.1528 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 20046: loss = 0.1533 (0.285 sec/step)\n",
            "I0923 10:11:11.208677 139631849019264 learning.py:507] global step 20046: loss = 0.1533 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 20047: loss = 0.1425 (0.275 sec/step)\n",
            "I0923 10:11:11.485321 139631849019264 learning.py:507] global step 20047: loss = 0.1425 (0.275 sec/step)\n",
            "INFO:tensorflow:global step 20048: loss = 0.0990 (0.306 sec/step)\n",
            "I0923 10:11:11.794409 139631849019264 learning.py:507] global step 20048: loss = 0.0990 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 20049: loss = 0.1374 (0.331 sec/step)\n",
            "I0923 10:11:12.129146 139631849019264 learning.py:507] global step 20049: loss = 0.1374 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 20050: loss = 0.0537 (0.279 sec/step)\n",
            "I0923 10:11:12.409937 139631849019264 learning.py:507] global step 20050: loss = 0.0537 (0.279 sec/step)\n",
            "INFO:tensorflow:global step 20051: loss = 0.1086 (0.323 sec/step)\n",
            "I0923 10:11:12.734636 139631849019264 learning.py:507] global step 20051: loss = 0.1086 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 20052: loss = 0.0896 (0.303 sec/step)\n",
            "I0923 10:11:13.039234 139631849019264 learning.py:507] global step 20052: loss = 0.0896 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 20053: loss = 0.0397 (0.332 sec/step)\n",
            "I0923 10:11:13.372827 139631849019264 learning.py:507] global step 20053: loss = 0.0397 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20054: loss = 0.1038 (0.325 sec/step)\n",
            "I0923 10:11:13.699300 139631849019264 learning.py:507] global step 20054: loss = 0.1038 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 20055: loss = 0.0631 (0.285 sec/step)\n",
            "I0923 10:11:13.986149 139631849019264 learning.py:507] global step 20055: loss = 0.0631 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 20056: loss = 0.0922 (0.301 sec/step)\n",
            "I0923 10:11:14.289318 139631849019264 learning.py:507] global step 20056: loss = 0.0922 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 20057: loss = 0.4040 (0.278 sec/step)\n",
            "I0923 10:11:14.569602 139631849019264 learning.py:507] global step 20057: loss = 0.4040 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 20058: loss = 0.0757 (0.281 sec/step)\n",
            "I0923 10:11:14.852457 139631849019264 learning.py:507] global step 20058: loss = 0.0757 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 20059: loss = 0.0295 (0.293 sec/step)\n",
            "I0923 10:11:15.147211 139631849019264 learning.py:507] global step 20059: loss = 0.0295 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 20060: loss = 0.1264 (0.320 sec/step)\n",
            "I0923 10:11:15.469341 139631849019264 learning.py:507] global step 20060: loss = 0.1264 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 20061: loss = 0.1070 (0.311 sec/step)\n",
            "I0923 10:11:15.781883 139631849019264 learning.py:507] global step 20061: loss = 0.1070 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 20062: loss = 0.0878 (0.348 sec/step)\n",
            "I0923 10:11:16.131556 139631849019264 learning.py:507] global step 20062: loss = 0.0878 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 20063: loss = 0.1116 (0.291 sec/step)\n",
            "I0923 10:11:16.424884 139631849019264 learning.py:507] global step 20063: loss = 0.1116 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 20064: loss = 0.0676 (0.279 sec/step)\n",
            "I0923 10:11:16.710664 139631849019264 learning.py:507] global step 20064: loss = 0.0676 (0.279 sec/step)\n",
            "INFO:tensorflow:global step 20065: loss = 0.0567 (0.317 sec/step)\n",
            "I0923 10:11:17.029692 139631849019264 learning.py:507] global step 20065: loss = 0.0567 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 20066: loss = 0.0598 (0.317 sec/step)\n",
            "I0923 10:11:17.348478 139631849019264 learning.py:507] global step 20066: loss = 0.0598 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 20067: loss = 0.1455 (0.293 sec/step)\n",
            "I0923 10:11:17.643142 139631849019264 learning.py:507] global step 20067: loss = 0.1455 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 20068: loss = 0.0492 (0.294 sec/step)\n",
            "I0923 10:11:17.938487 139631849019264 learning.py:507] global step 20068: loss = 0.0492 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 20069: loss = 0.0704 (0.343 sec/step)\n",
            "I0923 10:11:18.282937 139631849019264 learning.py:507] global step 20069: loss = 0.0704 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 20070: loss = 0.0678 (0.282 sec/step)\n",
            "I0923 10:11:18.567203 139631849019264 learning.py:507] global step 20070: loss = 0.0678 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 20071: loss = 0.0792 (0.292 sec/step)\n",
            "I0923 10:11:18.860550 139631849019264 learning.py:507] global step 20071: loss = 0.0792 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 20072: loss = 0.0914 (0.330 sec/step)\n",
            "I0923 10:11:19.192128 139631849019264 learning.py:507] global step 20072: loss = 0.0914 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 20073: loss = 0.3542 (0.321 sec/step)\n",
            "I0923 10:11:19.514889 139631849019264 learning.py:507] global step 20073: loss = 0.3542 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 20074: loss = 0.0389 (0.280 sec/step)\n",
            "I0923 10:11:19.796620 139631849019264 learning.py:507] global step 20074: loss = 0.0389 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 20075: loss = 0.0391 (0.312 sec/step)\n",
            "I0923 10:11:20.110503 139631849019264 learning.py:507] global step 20075: loss = 0.0391 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 20076: loss = 0.0773 (0.294 sec/step)\n",
            "I0923 10:11:20.406469 139631849019264 learning.py:507] global step 20076: loss = 0.0773 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 20077: loss = 0.1290 (0.292 sec/step)\n",
            "I0923 10:11:20.699923 139631849019264 learning.py:507] global step 20077: loss = 0.1290 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 20078: loss = 0.1213 (0.293 sec/step)\n",
            "I0923 10:11:20.994891 139631849019264 learning.py:507] global step 20078: loss = 0.1213 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 20079: loss = 0.1268 (0.362 sec/step)\n",
            "I0923 10:11:21.359182 139631849019264 learning.py:507] global step 20079: loss = 0.1268 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 20080: loss = 0.1193 (0.304 sec/step)\n",
            "I0923 10:11:21.665249 139631849019264 learning.py:507] global step 20080: loss = 0.1193 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 20081: loss = 0.1081 (0.363 sec/step)\n",
            "I0923 10:11:22.030578 139631849019264 learning.py:507] global step 20081: loss = 0.1081 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 20082: loss = 0.1559 (0.299 sec/step)\n",
            "I0923 10:11:22.330723 139631849019264 learning.py:507] global step 20082: loss = 0.1559 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 20083: loss = 0.0627 (0.313 sec/step)\n",
            "I0923 10:11:22.645457 139631849019264 learning.py:507] global step 20083: loss = 0.0627 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 20084: loss = 0.1575 (0.291 sec/step)\n",
            "I0923 10:11:22.938630 139631849019264 learning.py:507] global step 20084: loss = 0.1575 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 20085: loss = 0.0370 (0.312 sec/step)\n",
            "I0923 10:11:23.252626 139631849019264 learning.py:507] global step 20085: loss = 0.0370 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 20086: loss = 0.0613 (0.287 sec/step)\n",
            "I0923 10:11:23.541754 139631849019264 learning.py:507] global step 20086: loss = 0.0613 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 20087: loss = 0.0988 (0.298 sec/step)\n",
            "I0923 10:11:23.841676 139631849019264 learning.py:507] global step 20087: loss = 0.0988 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 20088: loss = 0.0801 (0.288 sec/step)\n",
            "I0923 10:11:24.131959 139631849019264 learning.py:507] global step 20088: loss = 0.0801 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 20089: loss = 0.0684 (0.413 sec/step)\n",
            "I0923 10:11:24.546270 139631849019264 learning.py:507] global step 20089: loss = 0.0684 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 20090: loss = 0.0427 (0.300 sec/step)\n",
            "I0923 10:11:24.848129 139631849019264 learning.py:507] global step 20090: loss = 0.0427 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 20091: loss = 0.1597 (0.304 sec/step)\n",
            "I0923 10:11:25.154098 139631849019264 learning.py:507] global step 20091: loss = 0.1597 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 20092: loss = 0.1949 (0.318 sec/step)\n",
            "I0923 10:11:25.473809 139631849019264 learning.py:507] global step 20092: loss = 0.1949 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 20093: loss = 0.0477 (0.282 sec/step)\n",
            "I0923 10:11:25.757704 139631849019264 learning.py:507] global step 20093: loss = 0.0477 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 20094: loss = 0.1342 (0.326 sec/step)\n",
            "I0923 10:11:26.085906 139631849019264 learning.py:507] global step 20094: loss = 0.1342 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20095: loss = 0.2004 (0.355 sec/step)\n",
            "I0923 10:11:26.442903 139631849019264 learning.py:507] global step 20095: loss = 0.2004 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 20096: loss = 0.0615 (0.315 sec/step)\n",
            "I0923 10:11:26.759909 139631849019264 learning.py:507] global step 20096: loss = 0.0615 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 20097: loss = 0.1254 (0.325 sec/step)\n",
            "I0923 10:11:27.086362 139631849019264 learning.py:507] global step 20097: loss = 0.1254 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 20098: loss = 0.0843 (0.282 sec/step)\n",
            "I0923 10:11:27.370242 139631849019264 learning.py:507] global step 20098: loss = 0.0843 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 20099: loss = 0.0798 (0.301 sec/step)\n",
            "I0923 10:11:27.672892 139631849019264 learning.py:507] global step 20099: loss = 0.0798 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 20100: loss = 0.0947 (0.345 sec/step)\n",
            "I0923 10:11:28.020338 139631849019264 learning.py:507] global step 20100: loss = 0.0947 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 20101: loss = 0.0924 (0.341 sec/step)\n",
            "I0923 10:11:28.363927 139631849019264 learning.py:507] global step 20101: loss = 0.0924 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 20102: loss = 0.1170 (0.338 sec/step)\n",
            "I0923 10:11:28.704126 139631849019264 learning.py:507] global step 20102: loss = 0.1170 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 20103: loss = 0.0623 (0.296 sec/step)\n",
            "I0923 10:11:29.001611 139631849019264 learning.py:507] global step 20103: loss = 0.0623 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 20104: loss = 0.1474 (0.318 sec/step)\n",
            "I0923 10:11:29.321508 139631849019264 learning.py:507] global step 20104: loss = 0.1474 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 20105: loss = 0.0636 (0.297 sec/step)\n",
            "I0923 10:11:29.620692 139631849019264 learning.py:507] global step 20105: loss = 0.0636 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 20106: loss = 0.0609 (0.339 sec/step)\n",
            "I0923 10:11:29.961514 139631849019264 learning.py:507] global step 20106: loss = 0.0609 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 20107: loss = 0.1655 (0.322 sec/step)\n",
            "I0923 10:11:30.285742 139631849019264 learning.py:507] global step 20107: loss = 0.1655 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 20108: loss = 0.1426 (0.305 sec/step)\n",
            "I0923 10:11:30.593078 139631849019264 learning.py:507] global step 20108: loss = 0.1426 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 20109: loss = 0.0712 (0.342 sec/step)\n",
            "I0923 10:11:30.937303 139631849019264 learning.py:507] global step 20109: loss = 0.0712 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 20110: loss = 0.1769 (0.285 sec/step)\n",
            "I0923 10:11:31.224122 139631849019264 learning.py:507] global step 20110: loss = 0.1769 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 20111: loss = 0.1529 (0.301 sec/step)\n",
            "I0923 10:11:31.527148 139631849019264 learning.py:507] global step 20111: loss = 0.1529 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 20112: loss = 0.0613 (0.314 sec/step)\n",
            "I0923 10:11:31.843362 139631849019264 learning.py:507] global step 20112: loss = 0.0613 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 20113: loss = 0.1034 (0.314 sec/step)\n",
            "I0923 10:11:32.158785 139631849019264 learning.py:507] global step 20113: loss = 0.1034 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 20114: loss = 0.1053 (0.288 sec/step)\n",
            "I0923 10:11:32.448495 139631849019264 learning.py:507] global step 20114: loss = 0.1053 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 20115: loss = 0.0501 (0.353 sec/step)\n",
            "I0923 10:11:32.803754 139631849019264 learning.py:507] global step 20115: loss = 0.0501 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 20116: loss = 0.0537 (0.311 sec/step)\n",
            "I0923 10:11:33.116254 139631849019264 learning.py:507] global step 20116: loss = 0.0537 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 20117: loss = 0.0799 (0.339 sec/step)\n",
            "I0923 10:11:33.457552 139631849019264 learning.py:507] global step 20117: loss = 0.0799 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 20118: loss = 0.0304 (0.317 sec/step)\n",
            "I0923 10:11:33.776251 139631849019264 learning.py:507] global step 20118: loss = 0.0304 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 20119: loss = 0.1358 (0.339 sec/step)\n",
            "I0923 10:11:34.116854 139631849019264 learning.py:507] global step 20119: loss = 0.1358 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 20120: loss = 0.1237 (0.318 sec/step)\n",
            "I0923 10:11:34.436376 139631849019264 learning.py:507] global step 20120: loss = 0.1237 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 20121: loss = 0.0884 (0.290 sec/step)\n",
            "I0923 10:11:34.728009 139631849019264 learning.py:507] global step 20121: loss = 0.0884 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 20122: loss = 0.1549 (0.324 sec/step)\n",
            "I0923 10:11:35.053604 139631849019264 learning.py:507] global step 20122: loss = 0.1549 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 20123: loss = 0.0436 (0.333 sec/step)\n",
            "I0923 10:11:35.389270 139631849019264 learning.py:507] global step 20123: loss = 0.0436 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 20124: loss = 0.0852 (0.367 sec/step)\n",
            "I0923 10:11:35.758568 139631849019264 learning.py:507] global step 20124: loss = 0.0852 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 20125: loss = 0.0593 (0.313 sec/step)\n",
            "I0923 10:11:36.073837 139631849019264 learning.py:507] global step 20125: loss = 0.0593 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 20126: loss = 0.1520 (0.307 sec/step)\n",
            "I0923 10:11:36.382304 139631849019264 learning.py:507] global step 20126: loss = 0.1520 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 20127: loss = 0.0876 (0.307 sec/step)\n",
            "I0923 10:11:36.691119 139631849019264 learning.py:507] global step 20127: loss = 0.0876 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 20128: loss = 0.0891 (0.361 sec/step)\n",
            "I0923 10:11:37.053295 139631849019264 learning.py:507] global step 20128: loss = 0.0891 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 20129: loss = 0.0485 (0.301 sec/step)\n",
            "I0923 10:11:37.356021 139631849019264 learning.py:507] global step 20129: loss = 0.0485 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 20130: loss = 0.0545 (0.300 sec/step)\n",
            "I0923 10:11:37.658252 139631849019264 learning.py:507] global step 20130: loss = 0.0545 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 20131: loss = 0.0455 (0.287 sec/step)\n",
            "I0923 10:11:37.946805 139631849019264 learning.py:507] global step 20131: loss = 0.0455 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 20132: loss = 0.0570 (0.278 sec/step)\n",
            "I0923 10:11:38.226027 139631849019264 learning.py:507] global step 20132: loss = 0.0570 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 20133: loss = 0.2127 (0.301 sec/step)\n",
            "I0923 10:11:38.529109 139631849019264 learning.py:507] global step 20133: loss = 0.2127 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 20134: loss = 0.0985 (0.341 sec/step)\n",
            "I0923 10:11:38.871775 139631849019264 learning.py:507] global step 20134: loss = 0.0985 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 20135: loss = 0.0685 (0.329 sec/step)\n",
            "I0923 10:11:39.202494 139631849019264 learning.py:507] global step 20135: loss = 0.0685 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 20136: loss = 0.0621 (0.334 sec/step)\n",
            "I0923 10:11:39.538914 139631849019264 learning.py:507] global step 20136: loss = 0.0621 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 20137: loss = 0.1003 (0.280 sec/step)\n",
            "I0923 10:11:39.820734 139631849019264 learning.py:507] global step 20137: loss = 0.1003 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 20138: loss = 0.0655 (0.337 sec/step)\n",
            "I0923 10:11:40.159547 139631849019264 learning.py:507] global step 20138: loss = 0.0655 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 20139: loss = 0.0814 (0.393 sec/step)\n",
            "I0923 10:11:40.554708 139631849019264 learning.py:507] global step 20139: loss = 0.0814 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 20140: loss = 0.0782 (0.322 sec/step)\n",
            "I0923 10:11:40.878188 139631849019264 learning.py:507] global step 20140: loss = 0.0782 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 20141: loss = 0.1482 (0.309 sec/step)\n",
            "I0923 10:11:41.189332 139631849019264 learning.py:507] global step 20141: loss = 0.1482 (0.309 sec/step)\n",
            "INFO:tensorflow:global step 20142: loss = 0.1389 (0.328 sec/step)\n",
            "I0923 10:11:41.519374 139631849019264 learning.py:507] global step 20142: loss = 0.1389 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 20143: loss = 0.1214 (0.356 sec/step)\n",
            "I0923 10:11:41.876933 139631849019264 learning.py:507] global step 20143: loss = 0.1214 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 20144: loss = 0.0594 (0.276 sec/step)\n",
            "I0923 10:11:42.154867 139631849019264 learning.py:507] global step 20144: loss = 0.0594 (0.276 sec/step)\n",
            "INFO:tensorflow:global step 20145: loss = 0.1686 (0.334 sec/step)\n",
            "I0923 10:11:42.490996 139631849019264 learning.py:507] global step 20145: loss = 0.1686 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 20146: loss = 0.2104 (0.318 sec/step)\n",
            "I0923 10:11:42.811029 139631849019264 learning.py:507] global step 20146: loss = 0.2104 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 20147: loss = 0.3475 (0.323 sec/step)\n",
            "I0923 10:11:43.136307 139631849019264 learning.py:507] global step 20147: loss = 0.3475 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 20148: loss = 0.0554 (0.326 sec/step)\n",
            "I0923 10:11:43.464216 139631849019264 learning.py:507] global step 20148: loss = 0.0554 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20149: loss = 0.0863 (0.339 sec/step)\n",
            "I0923 10:11:43.804702 139631849019264 learning.py:507] global step 20149: loss = 0.0863 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 20150: loss = 0.0973 (0.346 sec/step)\n",
            "I0923 10:11:44.153346 139631849019264 learning.py:507] global step 20150: loss = 0.0973 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 20151: loss = 0.0624 (0.331 sec/step)\n",
            "I0923 10:11:44.486724 139631849019264 learning.py:507] global step 20151: loss = 0.0624 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 20152: loss = 0.1038 (0.330 sec/step)\n",
            "I0923 10:11:44.819056 139631849019264 learning.py:507] global step 20152: loss = 0.1038 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 20153: loss = 0.0766 (0.313 sec/step)\n",
            "I0923 10:11:45.134662 139631849019264 learning.py:507] global step 20153: loss = 0.0766 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 20154: loss = 0.0495 (0.305 sec/step)\n",
            "I0923 10:11:45.441542 139631849019264 learning.py:507] global step 20154: loss = 0.0495 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 20155: loss = 0.0959 (0.304 sec/step)\n",
            "I0923 10:11:45.747817 139631849019264 learning.py:507] global step 20155: loss = 0.0959 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 20156: loss = 0.1433 (0.282 sec/step)\n",
            "I0923 10:11:46.031437 139631849019264 learning.py:507] global step 20156: loss = 0.1433 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 20157: loss = 0.0457 (0.285 sec/step)\n",
            "I0923 10:11:46.319136 139631849019264 learning.py:507] global step 20157: loss = 0.0457 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 20158: loss = 0.2089 (0.286 sec/step)\n",
            "I0923 10:11:46.610794 139631849019264 learning.py:507] global step 20158: loss = 0.2089 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 20159: loss = 0.1108 (0.342 sec/step)\n",
            "I0923 10:11:46.954442 139631849019264 learning.py:507] global step 20159: loss = 0.1108 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 20160: loss = 0.1047 (0.335 sec/step)\n",
            "I0923 10:11:47.291083 139631849019264 learning.py:507] global step 20160: loss = 0.1047 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 20161: loss = 0.1793 (0.295 sec/step)\n",
            "I0923 10:11:47.588119 139631849019264 learning.py:507] global step 20161: loss = 0.1793 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 20162: loss = 0.1127 (0.290 sec/step)\n",
            "I0923 10:11:47.880217 139631849019264 learning.py:507] global step 20162: loss = 0.1127 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 20163: loss = 0.1202 (0.345 sec/step)\n",
            "I0923 10:11:48.227584 139631849019264 learning.py:507] global step 20163: loss = 0.1202 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 20164: loss = 0.0449 (0.373 sec/step)\n",
            "I0923 10:11:48.603193 139631849019264 learning.py:507] global step 20164: loss = 0.0449 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 20165: loss = 0.0272 (0.299 sec/step)\n",
            "I0923 10:11:48.904904 139631849019264 learning.py:507] global step 20165: loss = 0.0272 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 20166: loss = 0.0740 (0.325 sec/step)\n",
            "I0923 10:11:49.232580 139631849019264 learning.py:507] global step 20166: loss = 0.0740 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 20167: loss = 0.1132 (0.345 sec/step)\n",
            "I0923 10:11:49.579203 139631849019264 learning.py:507] global step 20167: loss = 0.1132 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 20168: loss = 0.1565 (0.347 sec/step)\n",
            "I0923 10:11:49.927467 139631849019264 learning.py:507] global step 20168: loss = 0.1565 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 20169: loss = 0.1888 (0.358 sec/step)\n",
            "I0923 10:11:50.287200 139631849019264 learning.py:507] global step 20169: loss = 0.1888 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 20170: loss = 0.0460 (0.282 sec/step)\n",
            "I0923 10:11:50.570871 139631849019264 learning.py:507] global step 20170: loss = 0.0460 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 20171: loss = 0.0424 (0.298 sec/step)\n",
            "I0923 10:11:50.870866 139631849019264 learning.py:507] global step 20171: loss = 0.0424 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 20172: loss = 0.3044 (0.323 sec/step)\n",
            "I0923 10:11:51.195903 139631849019264 learning.py:507] global step 20172: loss = 0.3044 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 20173: loss = 0.1125 (0.272 sec/step)\n",
            "I0923 10:11:51.469819 139631849019264 learning.py:507] global step 20173: loss = 0.1125 (0.272 sec/step)\n",
            "INFO:tensorflow:global step 20174: loss = 0.1544 (0.332 sec/step)\n",
            "I0923 10:11:51.804013 139631849019264 learning.py:507] global step 20174: loss = 0.1544 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20175: loss = 0.0483 (0.294 sec/step)\n",
            "I0923 10:11:52.100224 139631849019264 learning.py:507] global step 20175: loss = 0.0483 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 20176: loss = 0.0271 (0.290 sec/step)\n",
            "I0923 10:11:52.392275 139631849019264 learning.py:507] global step 20176: loss = 0.0271 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 20177: loss = 0.0700 (0.347 sec/step)\n",
            "I0923 10:11:52.742193 139631849019264 learning.py:507] global step 20177: loss = 0.0700 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 20178: loss = 0.0514 (0.294 sec/step)\n",
            "I0923 10:11:53.041366 139631849019264 learning.py:507] global step 20178: loss = 0.0514 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 20179: loss = 0.2236 (0.294 sec/step)\n",
            "I0923 10:11:53.337418 139631849019264 learning.py:507] global step 20179: loss = 0.2236 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 20180: loss = 0.0500 (0.302 sec/step)\n",
            "I0923 10:11:53.641513 139631849019264 learning.py:507] global step 20180: loss = 0.0500 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 20181: loss = 0.0749 (0.328 sec/step)\n",
            "I0923 10:11:53.971470 139631849019264 learning.py:507] global step 20181: loss = 0.0749 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 20182: loss = 0.0852 (0.344 sec/step)\n",
            "I0923 10:11:54.317413 139631849019264 learning.py:507] global step 20182: loss = 0.0852 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 20183: loss = 0.0558 (0.304 sec/step)\n",
            "I0923 10:11:54.622924 139631849019264 learning.py:507] global step 20183: loss = 0.0558 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 20184: loss = 0.1454 (0.318 sec/step)\n",
            "I0923 10:11:54.943349 139631849019264 learning.py:507] global step 20184: loss = 0.1454 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 20185: loss = 0.0319 (0.378 sec/step)\n",
            "I0923 10:11:55.322717 139631849019264 learning.py:507] global step 20185: loss = 0.0319 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 20186: loss = 0.0407 (0.314 sec/step)\n",
            "I0923 10:11:55.639105 139631849019264 learning.py:507] global step 20186: loss = 0.0407 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 20187: loss = 0.1026 (0.268 sec/step)\n",
            "I0923 10:11:55.909418 139631849019264 learning.py:507] global step 20187: loss = 0.1026 (0.268 sec/step)\n",
            "INFO:tensorflow:global step 20188: loss = 0.0783 (0.345 sec/step)\n",
            "I0923 10:11:56.256267 139631849019264 learning.py:507] global step 20188: loss = 0.0783 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 20189: loss = 0.1094 (0.331 sec/step)\n",
            "I0923 10:11:56.589082 139631849019264 learning.py:507] global step 20189: loss = 0.1094 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 20190: loss = 0.0980 (0.377 sec/step)\n",
            "I0923 10:11:56.968153 139631849019264 learning.py:507] global step 20190: loss = 0.0980 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 20191: loss = 0.1540 (0.336 sec/step)\n",
            "I0923 10:11:57.306629 139631849019264 learning.py:507] global step 20191: loss = 0.1540 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 20192: loss = 0.1184 (0.290 sec/step)\n",
            "I0923 10:11:57.598914 139631849019264 learning.py:507] global step 20192: loss = 0.1184 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 20193: loss = 0.1439 (0.318 sec/step)\n",
            "I0923 10:11:57.918494 139631849019264 learning.py:507] global step 20193: loss = 0.1439 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 20194: loss = 0.1240 (0.273 sec/step)\n",
            "I0923 10:11:58.193035 139631849019264 learning.py:507] global step 20194: loss = 0.1240 (0.273 sec/step)\n",
            "INFO:tensorflow:global step 20195: loss = 0.0762 (0.333 sec/step)\n",
            "I0923 10:11:58.527941 139631849019264 learning.py:507] global step 20195: loss = 0.0762 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 20196: loss = 0.2532 (0.307 sec/step)\n",
            "I0923 10:11:58.837308 139631849019264 learning.py:507] global step 20196: loss = 0.2532 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 20197: loss = 0.0361 (0.340 sec/step)\n",
            "I0923 10:11:59.179404 139631849019264 learning.py:507] global step 20197: loss = 0.0361 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 20198: loss = 0.0689 (0.297 sec/step)\n",
            "I0923 10:11:59.478515 139631849019264 learning.py:507] global step 20198: loss = 0.0689 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 20199: loss = 0.0960 (0.290 sec/step)\n",
            "I0923 10:11:59.771120 139631849019264 learning.py:507] global step 20199: loss = 0.0960 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 20200: loss = 0.2747 (0.335 sec/step)\n",
            "I0923 10:12:00.108114 139631849019264 learning.py:507] global step 20200: loss = 0.2747 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 20201: loss = 0.5132 (0.414 sec/step)\n",
            "I0923 10:12:00.524382 139631849019264 learning.py:507] global step 20201: loss = 0.5132 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 20202: loss = 0.0796 (0.283 sec/step)\n",
            "I0923 10:12:00.808729 139631849019264 learning.py:507] global step 20202: loss = 0.0796 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 20203: loss = 0.1140 (0.368 sec/step)\n",
            "I0923 10:12:01.178989 139631849019264 learning.py:507] global step 20203: loss = 0.1140 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 20204: loss = 0.1668 (0.354 sec/step)\n",
            "I0923 10:12:01.535423 139631849019264 learning.py:507] global step 20204: loss = 0.1668 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 20205: loss = 0.0527 (0.332 sec/step)\n",
            "I0923 10:12:01.869412 139631849019264 learning.py:507] global step 20205: loss = 0.0527 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20206: loss = 0.1400 (0.341 sec/step)\n",
            "I0923 10:12:02.212837 139631849019264 learning.py:507] global step 20206: loss = 0.1400 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 20207: loss = 0.0430 (0.303 sec/step)\n",
            "I0923 10:12:02.517575 139631849019264 learning.py:507] global step 20207: loss = 0.0430 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 20208: loss = 0.0928 (0.291 sec/step)\n",
            "I0923 10:12:02.810868 139631849019264 learning.py:507] global step 20208: loss = 0.0928 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 20209: loss = 0.1091 (0.343 sec/step)\n",
            "I0923 10:12:03.155218 139631849019264 learning.py:507] global step 20209: loss = 0.1091 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 20210: loss = 0.0445 (0.331 sec/step)\n",
            "I0923 10:12:03.487670 139631849019264 learning.py:507] global step 20210: loss = 0.0445 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 20211: loss = 0.0813 (0.283 sec/step)\n",
            "I0923 10:12:03.772038 139631849019264 learning.py:507] global step 20211: loss = 0.0813 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 20212: loss = 0.1186 (0.322 sec/step)\n",
            "I0923 10:12:04.096346 139631849019264 learning.py:507] global step 20212: loss = 0.1186 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 20213: loss = 0.1066 (0.316 sec/step)\n",
            "I0923 10:12:04.413768 139631849019264 learning.py:507] global step 20213: loss = 0.1066 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 20214: loss = 0.1909 (0.296 sec/step)\n",
            "I0923 10:12:04.711513 139631849019264 learning.py:507] global step 20214: loss = 0.1909 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 20215: loss = 0.0805 (0.316 sec/step)\n",
            "I0923 10:12:05.029586 139631849019264 learning.py:507] global step 20215: loss = 0.0805 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 20216: loss = 0.1657 (0.330 sec/step)\n",
            "I0923 10:12:05.361156 139631849019264 learning.py:507] global step 20216: loss = 0.1657 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 20217: loss = 0.0615 (0.271 sec/step)\n",
            "I0923 10:12:05.634330 139631849019264 learning.py:507] global step 20217: loss = 0.0615 (0.271 sec/step)\n",
            "INFO:tensorflow:global step 20218: loss = 0.0428 (0.322 sec/step)\n",
            "I0923 10:12:05.958153 139631849019264 learning.py:507] global step 20218: loss = 0.0428 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 20219: loss = 0.2178 (0.307 sec/step)\n",
            "I0923 10:12:06.267025 139631849019264 learning.py:507] global step 20219: loss = 0.2178 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 20220: loss = 0.0569 (0.302 sec/step)\n",
            "I0923 10:12:06.570698 139631849019264 learning.py:507] global step 20220: loss = 0.0569 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 20221: loss = 0.2399 (0.331 sec/step)\n",
            "I0923 10:12:06.904042 139631849019264 learning.py:507] global step 20221: loss = 0.2399 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 20222: loss = 0.0721 (0.277 sec/step)\n",
            "I0923 10:12:07.182908 139631849019264 learning.py:507] global step 20222: loss = 0.0721 (0.277 sec/step)\n",
            "INFO:tensorflow:global step 20223: loss = 0.0883 (0.312 sec/step)\n",
            "I0923 10:12:07.496686 139631849019264 learning.py:507] global step 20223: loss = 0.0883 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 20224: loss = 0.0736 (0.332 sec/step)\n",
            "I0923 10:12:07.830765 139631849019264 learning.py:507] global step 20224: loss = 0.0736 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20225: loss = 0.0772 (0.328 sec/step)\n",
            "I0923 10:12:08.161130 139631849019264 learning.py:507] global step 20225: loss = 0.0772 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 20226: loss = 0.0988 (0.288 sec/step)\n",
            "I0923 10:12:08.451241 139631849019264 learning.py:507] global step 20226: loss = 0.0988 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 20227: loss = 0.1046 (0.316 sec/step)\n",
            "I0923 10:12:08.769236 139631849019264 learning.py:507] global step 20227: loss = 0.1046 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 20228: loss = 0.1040 (0.323 sec/step)\n",
            "I0923 10:12:09.094523 139631849019264 learning.py:507] global step 20228: loss = 0.1040 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 20229: loss = 0.0594 (0.328 sec/step)\n",
            "I0923 10:12:09.424305 139631849019264 learning.py:507] global step 20229: loss = 0.0594 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 20230: loss = 0.1917 (0.375 sec/step)\n",
            "I0923 10:12:09.801409 139631849019264 learning.py:507] global step 20230: loss = 0.1917 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 20231: loss = 0.0728 (0.319 sec/step)\n",
            "I0923 10:12:10.122351 139631849019264 learning.py:507] global step 20231: loss = 0.0728 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 20232: loss = 0.0468 (0.285 sec/step)\n",
            "I0923 10:12:10.410052 139631849019264 learning.py:507] global step 20232: loss = 0.0468 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 20233: loss = 0.0580 (0.319 sec/step)\n",
            "I0923 10:12:10.731100 139631849019264 learning.py:507] global step 20233: loss = 0.0580 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 20234: loss = 0.0607 (0.296 sec/step)\n",
            "I0923 10:12:11.028831 139631849019264 learning.py:507] global step 20234: loss = 0.0607 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 20235: loss = 0.0611 (0.306 sec/step)\n",
            "I0923 10:12:11.336621 139631849019264 learning.py:507] global step 20235: loss = 0.0611 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 20236: loss = 0.0841 (0.291 sec/step)\n",
            "I0923 10:12:11.629228 139631849019264 learning.py:507] global step 20236: loss = 0.0841 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 20237: loss = 0.2964 (0.313 sec/step)\n",
            "I0923 10:12:11.944186 139631849019264 learning.py:507] global step 20237: loss = 0.2964 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 20238: loss = 0.0453 (0.278 sec/step)\n",
            "I0923 10:12:12.223870 139631849019264 learning.py:507] global step 20238: loss = 0.0453 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 20239: loss = 0.0543 (0.396 sec/step)\n",
            "I0923 10:12:12.621944 139631849019264 learning.py:507] global step 20239: loss = 0.0543 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 20240: loss = 0.0357 (0.296 sec/step)\n",
            "I0923 10:12:12.920049 139631849019264 learning.py:507] global step 20240: loss = 0.0357 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 20241: loss = 0.0238 (0.291 sec/step)\n",
            "I0923 10:12:13.212890 139631849019264 learning.py:507] global step 20241: loss = 0.0238 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 20242: loss = 0.0820 (0.287 sec/step)\n",
            "I0923 10:12:13.501837 139631849019264 learning.py:507] global step 20242: loss = 0.0820 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 20243: loss = 0.2320 (0.341 sec/step)\n",
            "I0923 10:12:13.845986 139631849019264 learning.py:507] global step 20243: loss = 0.2320 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 20244: loss = 0.0845 (0.297 sec/step)\n",
            "I0923 10:12:14.145198 139631849019264 learning.py:507] global step 20244: loss = 0.0845 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 20245: loss = 0.2524 (0.354 sec/step)\n",
            "I0923 10:12:14.500983 139631849019264 learning.py:507] global step 20245: loss = 0.2524 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 20246: loss = 0.0588 (0.280 sec/step)\n",
            "I0923 10:12:14.782718 139631849019264 learning.py:507] global step 20246: loss = 0.0588 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 20247: loss = 0.1483 (0.350 sec/step)\n",
            "I0923 10:12:15.135169 139631849019264 learning.py:507] global step 20247: loss = 0.1483 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 20248: loss = 0.0626 (0.331 sec/step)\n",
            "I0923 10:12:15.467781 139631849019264 learning.py:507] global step 20248: loss = 0.0626 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 20249: loss = 0.0740 (0.331 sec/step)\n",
            "I0923 10:12:15.801275 139631849019264 learning.py:507] global step 20249: loss = 0.0740 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 20250: loss = 0.0529 (0.296 sec/step)\n",
            "I0923 10:12:16.099723 139631849019264 learning.py:507] global step 20250: loss = 0.0529 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 20251: loss = 0.1019 (0.300 sec/step)\n",
            "I0923 10:12:16.401496 139631849019264 learning.py:507] global step 20251: loss = 0.1019 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 20252: loss = 0.1104 (0.288 sec/step)\n",
            "I0923 10:12:16.691176 139631849019264 learning.py:507] global step 20252: loss = 0.1104 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 20253: loss = 0.1519 (0.370 sec/step)\n",
            "I0923 10:12:17.063367 139631849019264 learning.py:507] global step 20253: loss = 0.1519 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 20254: loss = 0.0531 (0.291 sec/step)\n",
            "I0923 10:12:17.356736 139631849019264 learning.py:507] global step 20254: loss = 0.0531 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 20255: loss = 0.1327 (0.282 sec/step)\n",
            "I0923 10:12:17.641036 139631849019264 learning.py:507] global step 20255: loss = 0.1327 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 20256: loss = 0.0626 (0.290 sec/step)\n",
            "I0923 10:12:17.932600 139631849019264 learning.py:507] global step 20256: loss = 0.0626 (0.290 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path training/model.ckpt\n",
            "I0923 10:12:17.973710 139628647724800 supervisor.py:1117] Saving checkpoint to path training/model.ckpt\n",
            "INFO:tensorflow:global step 20257: loss = 0.1312 (0.929 sec/step)\n",
            "I0923 10:12:18.894371 139631849019264 learning.py:507] global step 20257: loss = 0.1312 (0.929 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 20258.\n",
            "I0923 10:12:19.839103 139628630939392 supervisor.py:1050] Recording summary at step 20258.\n",
            "INFO:tensorflow:global step 20258: loss = 0.1233 (0.932 sec/step)\n",
            "I0923 10:12:19.872239 139631849019264 learning.py:507] global step 20258: loss = 0.1233 (0.932 sec/step)\n",
            "INFO:tensorflow:global step 20259: loss = 0.2197 (0.502 sec/step)\n",
            "I0923 10:12:20.392652 139631849019264 learning.py:507] global step 20259: loss = 0.2197 (0.502 sec/step)\n",
            "INFO:tensorflow:global step 20260: loss = 0.1954 (0.378 sec/step)\n",
            "I0923 10:12:20.772523 139631849019264 learning.py:507] global step 20260: loss = 0.1954 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 20261: loss = 0.1895 (0.280 sec/step)\n",
            "I0923 10:12:21.054912 139631849019264 learning.py:507] global step 20261: loss = 0.1895 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 20262: loss = 0.0650 (0.321 sec/step)\n",
            "I0923 10:12:21.377894 139631849019264 learning.py:507] global step 20262: loss = 0.0650 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 20263: loss = 0.0676 (0.285 sec/step)\n",
            "I0923 10:12:21.664862 139631849019264 learning.py:507] global step 20263: loss = 0.0676 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 20264: loss = 0.1399 (0.330 sec/step)\n",
            "I0923 10:12:21.996407 139631849019264 learning.py:507] global step 20264: loss = 0.1399 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 20265: loss = 0.1491 (0.363 sec/step)\n",
            "I0923 10:12:22.361020 139631849019264 learning.py:507] global step 20265: loss = 0.1491 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 20266: loss = 0.0778 (0.329 sec/step)\n",
            "I0923 10:12:22.692072 139631849019264 learning.py:507] global step 20266: loss = 0.0778 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 20267: loss = 0.0683 (0.285 sec/step)\n",
            "I0923 10:12:22.978729 139631849019264 learning.py:507] global step 20267: loss = 0.0683 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 20268: loss = 0.0797 (0.282 sec/step)\n",
            "I0923 10:12:23.265166 139631849019264 learning.py:507] global step 20268: loss = 0.0797 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 20269: loss = 0.1334 (0.333 sec/step)\n",
            "I0923 10:12:23.601153 139631849019264 learning.py:507] global step 20269: loss = 0.1334 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 20270: loss = 0.0927 (0.288 sec/step)\n",
            "I0923 10:12:23.891539 139631849019264 learning.py:507] global step 20270: loss = 0.0927 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 20271: loss = 0.0714 (0.291 sec/step)\n",
            "I0923 10:12:24.184224 139631849019264 learning.py:507] global step 20271: loss = 0.0714 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 20272: loss = 0.1021 (0.326 sec/step)\n",
            "I0923 10:12:24.511729 139631849019264 learning.py:507] global step 20272: loss = 0.1021 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20273: loss = 0.1001 (0.311 sec/step)\n",
            "I0923 10:12:24.824720 139631849019264 learning.py:507] global step 20273: loss = 0.1001 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 20274: loss = 0.1118 (0.338 sec/step)\n",
            "I0923 10:12:25.164861 139631849019264 learning.py:507] global step 20274: loss = 0.1118 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 20275: loss = 0.0301 (0.354 sec/step)\n",
            "I0923 10:12:25.521004 139631849019264 learning.py:507] global step 20275: loss = 0.0301 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 20276: loss = 0.0854 (0.310 sec/step)\n",
            "I0923 10:12:25.833022 139631849019264 learning.py:507] global step 20276: loss = 0.0854 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 20277: loss = 0.0434 (0.300 sec/step)\n",
            "I0923 10:12:26.135304 139631849019264 learning.py:507] global step 20277: loss = 0.0434 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 20278: loss = 0.0916 (0.336 sec/step)\n",
            "I0923 10:12:26.475201 139631849019264 learning.py:507] global step 20278: loss = 0.0916 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 20279: loss = 0.1342 (0.289 sec/step)\n",
            "I0923 10:12:26.765817 139631849019264 learning.py:507] global step 20279: loss = 0.1342 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 20280: loss = 0.1044 (0.288 sec/step)\n",
            "I0923 10:12:27.055946 139631849019264 learning.py:507] global step 20280: loss = 0.1044 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 20281: loss = 0.1428 (0.299 sec/step)\n",
            "I0923 10:12:27.356974 139631849019264 learning.py:507] global step 20281: loss = 0.1428 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 20282: loss = 0.0435 (0.279 sec/step)\n",
            "I0923 10:12:27.638244 139631849019264 learning.py:507] global step 20282: loss = 0.0435 (0.279 sec/step)\n",
            "INFO:tensorflow:global step 20283: loss = 0.0559 (0.283 sec/step)\n",
            "I0923 10:12:27.922418 139631849019264 learning.py:507] global step 20283: loss = 0.0559 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 20284: loss = 0.0889 (0.403 sec/step)\n",
            "I0923 10:12:28.327947 139631849019264 learning.py:507] global step 20284: loss = 0.0889 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 20285: loss = 0.1302 (0.390 sec/step)\n",
            "I0923 10:12:28.720101 139631849019264 learning.py:507] global step 20285: loss = 0.1302 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 20286: loss = 0.0410 (0.345 sec/step)\n",
            "I0923 10:12:29.066847 139631849019264 learning.py:507] global step 20286: loss = 0.0410 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 20287: loss = 0.0891 (0.342 sec/step)\n",
            "I0923 10:12:29.411102 139631849019264 learning.py:507] global step 20287: loss = 0.0891 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 20288: loss = 0.1018 (0.272 sec/step)\n",
            "I0923 10:12:29.685392 139631849019264 learning.py:507] global step 20288: loss = 0.1018 (0.272 sec/step)\n",
            "INFO:tensorflow:global step 20289: loss = 0.0943 (0.322 sec/step)\n",
            "I0923 10:12:30.009525 139631849019264 learning.py:507] global step 20289: loss = 0.0943 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 20290: loss = 0.1269 (0.365 sec/step)\n",
            "I0923 10:12:30.376342 139631849019264 learning.py:507] global step 20290: loss = 0.1269 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 20291: loss = 0.1548 (0.331 sec/step)\n",
            "I0923 10:12:30.708662 139631849019264 learning.py:507] global step 20291: loss = 0.1548 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 20292: loss = 0.0644 (0.339 sec/step)\n",
            "I0923 10:12:31.050178 139631849019264 learning.py:507] global step 20292: loss = 0.0644 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 20293: loss = 0.1478 (0.301 sec/step)\n",
            "I0923 10:12:31.353084 139631849019264 learning.py:507] global step 20293: loss = 0.1478 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 20294: loss = 0.1485 (0.286 sec/step)\n",
            "I0923 10:12:31.640625 139631849019264 learning.py:507] global step 20294: loss = 0.1485 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 20295: loss = 0.1711 (0.292 sec/step)\n",
            "I0923 10:12:31.935046 139631849019264 learning.py:507] global step 20295: loss = 0.1711 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 20296: loss = 0.1236 (0.332 sec/step)\n",
            "I0923 10:12:32.269230 139631849019264 learning.py:507] global step 20296: loss = 0.1236 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20297: loss = 0.0991 (0.336 sec/step)\n",
            "I0923 10:12:32.607474 139631849019264 learning.py:507] global step 20297: loss = 0.0991 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 20298: loss = 0.1985 (0.277 sec/step)\n",
            "I0923 10:12:32.886500 139631849019264 learning.py:507] global step 20298: loss = 0.1985 (0.277 sec/step)\n",
            "INFO:tensorflow:global step 20299: loss = 0.0833 (0.326 sec/step)\n",
            "I0923 10:12:33.214872 139631849019264 learning.py:507] global step 20299: loss = 0.0833 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20300: loss = 0.1148 (0.292 sec/step)\n",
            "I0923 10:12:33.508575 139631849019264 learning.py:507] global step 20300: loss = 0.1148 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 20301: loss = 0.0847 (0.357 sec/step)\n",
            "I0923 10:12:33.867514 139631849019264 learning.py:507] global step 20301: loss = 0.0847 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 20302: loss = 0.0674 (0.275 sec/step)\n",
            "I0923 10:12:34.144844 139631849019264 learning.py:507] global step 20302: loss = 0.0674 (0.275 sec/step)\n",
            "INFO:tensorflow:global step 20303: loss = 0.1072 (0.311 sec/step)\n",
            "I0923 10:12:34.457406 139631849019264 learning.py:507] global step 20303: loss = 0.1072 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 20304: loss = 0.1006 (0.312 sec/step)\n",
            "I0923 10:12:34.771600 139631849019264 learning.py:507] global step 20304: loss = 0.1006 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 20305: loss = 0.0504 (0.296 sec/step)\n",
            "I0923 10:12:35.068865 139631849019264 learning.py:507] global step 20305: loss = 0.0504 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 20306: loss = 0.0775 (0.283 sec/step)\n",
            "I0923 10:12:35.353508 139631849019264 learning.py:507] global step 20306: loss = 0.0775 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 20307: loss = 0.1860 (0.335 sec/step)\n",
            "I0923 10:12:35.690687 139631849019264 learning.py:507] global step 20307: loss = 0.1860 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 20308: loss = 0.0707 (0.293 sec/step)\n",
            "I0923 10:12:35.985810 139631849019264 learning.py:507] global step 20308: loss = 0.0707 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 20309: loss = 0.0755 (0.284 sec/step)\n",
            "I0923 10:12:36.271850 139631849019264 learning.py:507] global step 20309: loss = 0.0755 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 20310: loss = 0.2188 (0.303 sec/step)\n",
            "I0923 10:12:36.577614 139631849019264 learning.py:507] global step 20310: loss = 0.2188 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 20311: loss = 0.1091 (0.340 sec/step)\n",
            "I0923 10:12:36.919410 139631849019264 learning.py:507] global step 20311: loss = 0.1091 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 20312: loss = 0.0606 (0.359 sec/step)\n",
            "I0923 10:12:37.280040 139631849019264 learning.py:507] global step 20312: loss = 0.0606 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 20313: loss = 0.1055 (0.339 sec/step)\n",
            "I0923 10:12:37.620733 139631849019264 learning.py:507] global step 20313: loss = 0.1055 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 20314: loss = 0.1074 (0.329 sec/step)\n",
            "I0923 10:12:37.951822 139631849019264 learning.py:507] global step 20314: loss = 0.1074 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 20315: loss = 0.0689 (0.353 sec/step)\n",
            "I0923 10:12:38.307229 139631849019264 learning.py:507] global step 20315: loss = 0.0689 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 20316: loss = 0.0489 (0.297 sec/step)\n",
            "I0923 10:12:38.609008 139631849019264 learning.py:507] global step 20316: loss = 0.0489 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 20317: loss = 0.1926 (0.282 sec/step)\n",
            "I0923 10:12:38.893206 139631849019264 learning.py:507] global step 20317: loss = 0.1926 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 20318: loss = 0.0894 (0.335 sec/step)\n",
            "I0923 10:12:39.229756 139631849019264 learning.py:507] global step 20318: loss = 0.0894 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 20319: loss = 0.0574 (0.353 sec/step)\n",
            "I0923 10:12:39.584938 139631849019264 learning.py:507] global step 20319: loss = 0.0574 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 20320: loss = 0.1386 (0.292 sec/step)\n",
            "I0923 10:12:39.879002 139631849019264 learning.py:507] global step 20320: loss = 0.1386 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 20321: loss = 0.0533 (0.282 sec/step)\n",
            "I0923 10:12:40.163362 139631849019264 learning.py:507] global step 20321: loss = 0.0533 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 20322: loss = 0.1147 (0.319 sec/step)\n",
            "I0923 10:12:40.484002 139631849019264 learning.py:507] global step 20322: loss = 0.1147 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 20323: loss = 0.0567 (0.338 sec/step)\n",
            "I0923 10:12:40.824217 139631849019264 learning.py:507] global step 20323: loss = 0.0567 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 20324: loss = 0.0918 (0.400 sec/step)\n",
            "I0923 10:12:41.225989 139631849019264 learning.py:507] global step 20324: loss = 0.0918 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 20325: loss = 0.1070 (0.365 sec/step)\n",
            "I0923 10:12:41.593408 139631849019264 learning.py:507] global step 20325: loss = 0.1070 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 20326: loss = 0.0479 (0.348 sec/step)\n",
            "I0923 10:12:41.943820 139631849019264 learning.py:507] global step 20326: loss = 0.0479 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 20327: loss = 0.0478 (0.300 sec/step)\n",
            "I0923 10:12:42.245344 139631849019264 learning.py:507] global step 20327: loss = 0.0478 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 20328: loss = 0.0607 (0.332 sec/step)\n",
            "I0923 10:12:42.579217 139631849019264 learning.py:507] global step 20328: loss = 0.0607 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20329: loss = 0.0744 (0.302 sec/step)\n",
            "I0923 10:12:42.882925 139631849019264 learning.py:507] global step 20329: loss = 0.0744 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 20330: loss = 0.0935 (0.289 sec/step)\n",
            "I0923 10:12:43.173634 139631849019264 learning.py:507] global step 20330: loss = 0.0935 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 20331: loss = 0.2241 (0.342 sec/step)\n",
            "I0923 10:12:43.517748 139631849019264 learning.py:507] global step 20331: loss = 0.2241 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 20332: loss = 0.3452 (0.305 sec/step)\n",
            "I0923 10:12:43.824870 139631849019264 learning.py:507] global step 20332: loss = 0.3452 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 20333: loss = 0.0397 (0.325 sec/step)\n",
            "I0923 10:12:44.152214 139631849019264 learning.py:507] global step 20333: loss = 0.0397 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 20334: loss = 0.0725 (0.369 sec/step)\n",
            "I0923 10:12:44.523591 139631849019264 learning.py:507] global step 20334: loss = 0.0725 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 20335: loss = 0.0853 (0.348 sec/step)\n",
            "I0923 10:12:44.873654 139631849019264 learning.py:507] global step 20335: loss = 0.0853 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 20336: loss = 0.0375 (0.334 sec/step)\n",
            "I0923 10:12:45.210110 139631849019264 learning.py:507] global step 20336: loss = 0.0375 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 20337: loss = 0.0751 (0.284 sec/step)\n",
            "I0923 10:12:45.495948 139631849019264 learning.py:507] global step 20337: loss = 0.0751 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 20338: loss = 0.0353 (0.299 sec/step)\n",
            "I0923 10:12:45.797437 139631849019264 learning.py:507] global step 20338: loss = 0.0353 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 20339: loss = 0.1135 (0.333 sec/step)\n",
            "I0923 10:12:46.133656 139631849019264 learning.py:507] global step 20339: loss = 0.1135 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 20340: loss = 0.1443 (0.320 sec/step)\n",
            "I0923 10:12:46.455595 139631849019264 learning.py:507] global step 20340: loss = 0.1443 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 20341: loss = 0.0508 (0.322 sec/step)\n",
            "I0923 10:12:46.780046 139631849019264 learning.py:507] global step 20341: loss = 0.0508 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 20342: loss = 0.1085 (0.326 sec/step)\n",
            "I0923 10:12:47.108347 139631849019264 learning.py:507] global step 20342: loss = 0.1085 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20343: loss = 0.0973 (0.318 sec/step)\n",
            "I0923 10:12:47.428202 139631849019264 learning.py:507] global step 20343: loss = 0.0973 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 20344: loss = 0.0307 (0.323 sec/step)\n",
            "I0923 10:12:47.753189 139631849019264 learning.py:507] global step 20344: loss = 0.0307 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 20345: loss = 0.1340 (0.359 sec/step)\n",
            "I0923 10:12:48.113690 139631849019264 learning.py:507] global step 20345: loss = 0.1340 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 20346: loss = 0.2962 (0.286 sec/step)\n",
            "I0923 10:12:48.401706 139631849019264 learning.py:507] global step 20346: loss = 0.2962 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 20347: loss = 0.0728 (0.351 sec/step)\n",
            "I0923 10:12:48.755016 139631849019264 learning.py:507] global step 20347: loss = 0.0728 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 20348: loss = 0.1019 (0.333 sec/step)\n",
            "I0923 10:12:49.089952 139631849019264 learning.py:507] global step 20348: loss = 0.1019 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 20349: loss = 0.0530 (0.327 sec/step)\n",
            "I0923 10:12:49.418982 139631849019264 learning.py:507] global step 20349: loss = 0.0530 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 20350: loss = 0.0718 (0.329 sec/step)\n",
            "I0923 10:12:49.749381 139631849019264 learning.py:507] global step 20350: loss = 0.0718 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 20351: loss = 0.1262 (0.344 sec/step)\n",
            "I0923 10:12:50.095687 139631849019264 learning.py:507] global step 20351: loss = 0.1262 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 20352: loss = 0.1086 (0.318 sec/step)\n",
            "I0923 10:12:50.416266 139631849019264 learning.py:507] global step 20352: loss = 0.1086 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 20353: loss = 0.2563 (0.331 sec/step)\n",
            "I0923 10:12:50.749432 139631849019264 learning.py:507] global step 20353: loss = 0.2563 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 20354: loss = 0.0451 (0.304 sec/step)\n",
            "I0923 10:12:51.055581 139631849019264 learning.py:507] global step 20354: loss = 0.0451 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 20355: loss = 0.0623 (0.336 sec/step)\n",
            "I0923 10:12:51.393768 139631849019264 learning.py:507] global step 20355: loss = 0.0623 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 20356: loss = 0.1056 (0.372 sec/step)\n",
            "I0923 10:12:51.767701 139631849019264 learning.py:507] global step 20356: loss = 0.1056 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 20357: loss = 0.2868 (0.298 sec/step)\n",
            "I0923 10:12:52.067577 139631849019264 learning.py:507] global step 20357: loss = 0.2868 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 20358: loss = 0.0453 (0.346 sec/step)\n",
            "I0923 10:12:52.415138 139631849019264 learning.py:507] global step 20358: loss = 0.0453 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 20359: loss = 0.0553 (0.332 sec/step)\n",
            "I0923 10:12:52.749577 139631849019264 learning.py:507] global step 20359: loss = 0.0553 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20360: loss = 0.1023 (0.353 sec/step)\n",
            "I0923 10:12:53.104152 139631849019264 learning.py:507] global step 20360: loss = 0.1023 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 20361: loss = 0.0395 (0.292 sec/step)\n",
            "I0923 10:12:53.398333 139631849019264 learning.py:507] global step 20361: loss = 0.0395 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 20362: loss = 0.0688 (0.273 sec/step)\n",
            "I0923 10:12:53.673032 139631849019264 learning.py:507] global step 20362: loss = 0.0688 (0.273 sec/step)\n",
            "INFO:tensorflow:global step 20363: loss = 0.0916 (0.268 sec/step)\n",
            "I0923 10:12:53.942362 139631849019264 learning.py:507] global step 20363: loss = 0.0916 (0.268 sec/step)\n",
            "INFO:tensorflow:global step 20364: loss = 0.1851 (0.359 sec/step)\n",
            "I0923 10:12:54.302577 139631849019264 learning.py:507] global step 20364: loss = 0.1851 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 20365: loss = 0.1884 (0.326 sec/step)\n",
            "I0923 10:12:54.630051 139631849019264 learning.py:507] global step 20365: loss = 0.1884 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20366: loss = 0.0630 (0.288 sec/step)\n",
            "I0923 10:12:54.921329 139631849019264 learning.py:507] global step 20366: loss = 0.0630 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 20367: loss = 0.0872 (0.380 sec/step)\n",
            "I0923 10:12:55.303982 139631849019264 learning.py:507] global step 20367: loss = 0.0872 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 20368: loss = 0.0707 (0.323 sec/step)\n",
            "I0923 10:12:55.629032 139631849019264 learning.py:507] global step 20368: loss = 0.0707 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 20369: loss = 0.1027 (0.307 sec/step)\n",
            "I0923 10:12:55.938621 139631849019264 learning.py:507] global step 20369: loss = 0.1027 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 20370: loss = 0.1995 (0.296 sec/step)\n",
            "I0923 10:12:56.237049 139631849019264 learning.py:507] global step 20370: loss = 0.1995 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 20371: loss = 0.0763 (0.288 sec/step)\n",
            "I0923 10:12:56.527281 139631849019264 learning.py:507] global step 20371: loss = 0.0763 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 20372: loss = 0.0271 (0.342 sec/step)\n",
            "I0923 10:12:56.870772 139631849019264 learning.py:507] global step 20372: loss = 0.0271 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 20373: loss = 0.1724 (0.315 sec/step)\n",
            "I0923 10:12:57.187709 139631849019264 learning.py:507] global step 20373: loss = 0.1724 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 20374: loss = 0.1393 (0.309 sec/step)\n",
            "I0923 10:12:57.498880 139631849019264 learning.py:507] global step 20374: loss = 0.1393 (0.309 sec/step)\n",
            "INFO:tensorflow:global step 20375: loss = 0.1198 (0.293 sec/step)\n",
            "I0923 10:12:57.793489 139631849019264 learning.py:507] global step 20375: loss = 0.1198 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 20376: loss = 0.0516 (0.303 sec/step)\n",
            "I0923 10:12:58.098544 139631849019264 learning.py:507] global step 20376: loss = 0.0516 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 20377: loss = 0.0939 (0.290 sec/step)\n",
            "I0923 10:12:58.390680 139631849019264 learning.py:507] global step 20377: loss = 0.0939 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 20378: loss = 0.0798 (0.312 sec/step)\n",
            "I0923 10:12:58.705164 139631849019264 learning.py:507] global step 20378: loss = 0.0798 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 20379: loss = 0.0939 (0.284 sec/step)\n",
            "I0923 10:12:58.991584 139631849019264 learning.py:507] global step 20379: loss = 0.0939 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 20380: loss = 0.1013 (0.317 sec/step)\n",
            "I0923 10:12:59.311003 139631849019264 learning.py:507] global step 20380: loss = 0.1013 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 20381: loss = 0.0331 (0.321 sec/step)\n",
            "I0923 10:12:59.633282 139631849019264 learning.py:507] global step 20381: loss = 0.0331 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 20382: loss = 0.1107 (0.293 sec/step)\n",
            "I0923 10:12:59.927677 139631849019264 learning.py:507] global step 20382: loss = 0.1107 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 20383: loss = 0.1032 (0.289 sec/step)\n",
            "I0923 10:13:00.218709 139631849019264 learning.py:507] global step 20383: loss = 0.1032 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 20384: loss = 0.0779 (0.340 sec/step)\n",
            "I0923 10:13:00.565272 139631849019264 learning.py:507] global step 20384: loss = 0.0779 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 20385: loss = 0.0681 (0.309 sec/step)\n",
            "I0923 10:13:00.876695 139631849019264 learning.py:507] global step 20385: loss = 0.0681 (0.309 sec/step)\n",
            "INFO:tensorflow:global step 20386: loss = 0.0552 (0.284 sec/step)\n",
            "I0923 10:13:01.162804 139631849019264 learning.py:507] global step 20386: loss = 0.0552 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 20387: loss = 0.0804 (0.328 sec/step)\n",
            "I0923 10:13:01.491993 139631849019264 learning.py:507] global step 20387: loss = 0.0804 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 20388: loss = 0.1978 (0.278 sec/step)\n",
            "I0923 10:13:01.772189 139631849019264 learning.py:507] global step 20388: loss = 0.1978 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 20389: loss = 0.0718 (0.278 sec/step)\n",
            "I0923 10:13:02.052150 139631849019264 learning.py:507] global step 20389: loss = 0.0718 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 20390: loss = 0.1351 (0.294 sec/step)\n",
            "I0923 10:13:02.347846 139631849019264 learning.py:507] global step 20390: loss = 0.1351 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 20391: loss = 0.1922 (0.282 sec/step)\n",
            "I0923 10:13:02.631561 139631849019264 learning.py:507] global step 20391: loss = 0.1922 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 20392: loss = 0.1476 (0.302 sec/step)\n",
            "I0923 10:13:02.935792 139631849019264 learning.py:507] global step 20392: loss = 0.1476 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 20393: loss = 0.1369 (0.367 sec/step)\n",
            "I0923 10:13:03.304538 139631849019264 learning.py:507] global step 20393: loss = 0.1369 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 20394: loss = 0.1605 (0.332 sec/step)\n",
            "I0923 10:13:03.638633 139631849019264 learning.py:507] global step 20394: loss = 0.1605 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20395: loss = 0.0946 (0.288 sec/step)\n",
            "I0923 10:13:03.928491 139631849019264 learning.py:507] global step 20395: loss = 0.0946 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 20396: loss = 0.0698 (0.345 sec/step)\n",
            "I0923 10:13:04.275053 139631849019264 learning.py:507] global step 20396: loss = 0.0698 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 20397: loss = 0.0733 (0.303 sec/step)\n",
            "I0923 10:13:04.579732 139631849019264 learning.py:507] global step 20397: loss = 0.0733 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 20398: loss = 0.0408 (0.288 sec/step)\n",
            "I0923 10:13:04.869138 139631849019264 learning.py:507] global step 20398: loss = 0.0408 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 20399: loss = 0.2655 (0.321 sec/step)\n",
            "I0923 10:13:05.192222 139631849019264 learning.py:507] global step 20399: loss = 0.2655 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 20400: loss = 0.0603 (0.352 sec/step)\n",
            "I0923 10:13:05.546093 139631849019264 learning.py:507] global step 20400: loss = 0.0603 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 20401: loss = 0.0623 (0.352 sec/step)\n",
            "I0923 10:13:05.900135 139631849019264 learning.py:507] global step 20401: loss = 0.0623 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 20402: loss = 0.3204 (0.318 sec/step)\n",
            "I0923 10:13:06.220140 139631849019264 learning.py:507] global step 20402: loss = 0.3204 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 20403: loss = 0.0587 (0.322 sec/step)\n",
            "I0923 10:13:06.544177 139631849019264 learning.py:507] global step 20403: loss = 0.0587 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 20404: loss = 0.1035 (0.337 sec/step)\n",
            "I0923 10:13:06.882553 139631849019264 learning.py:507] global step 20404: loss = 0.1035 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 20405: loss = 0.0551 (0.334 sec/step)\n",
            "I0923 10:13:07.218709 139631849019264 learning.py:507] global step 20405: loss = 0.0551 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 20406: loss = 0.1654 (0.273 sec/step)\n",
            "I0923 10:13:07.494000 139631849019264 learning.py:507] global step 20406: loss = 0.1654 (0.273 sec/step)\n",
            "INFO:tensorflow:global step 20407: loss = 0.2085 (0.319 sec/step)\n",
            "I0923 10:13:07.814795 139631849019264 learning.py:507] global step 20407: loss = 0.2085 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 20408: loss = 0.1264 (0.311 sec/step)\n",
            "I0923 10:13:08.127506 139631849019264 learning.py:507] global step 20408: loss = 0.1264 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 20409: loss = 0.0911 (0.296 sec/step)\n",
            "I0923 10:13:08.425013 139631849019264 learning.py:507] global step 20409: loss = 0.0911 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 20410: loss = 0.0315 (0.401 sec/step)\n",
            "I0923 10:13:08.828085 139631849019264 learning.py:507] global step 20410: loss = 0.0315 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 20411: loss = 0.0693 (0.325 sec/step)\n",
            "I0923 10:13:09.154538 139631849019264 learning.py:507] global step 20411: loss = 0.0693 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 20412: loss = 0.0317 (0.332 sec/step)\n",
            "I0923 10:13:09.488409 139631849019264 learning.py:507] global step 20412: loss = 0.0317 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20413: loss = 0.1250 (0.319 sec/step)\n",
            "I0923 10:13:09.809262 139631849019264 learning.py:507] global step 20413: loss = 0.1250 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 20414: loss = 0.0340 (0.281 sec/step)\n",
            "I0923 10:13:10.092327 139631849019264 learning.py:507] global step 20414: loss = 0.0340 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 20415: loss = 0.0535 (0.295 sec/step)\n",
            "I0923 10:13:10.389508 139631849019264 learning.py:507] global step 20415: loss = 0.0535 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 20416: loss = 0.0337 (0.285 sec/step)\n",
            "I0923 10:13:10.677150 139631849019264 learning.py:507] global step 20416: loss = 0.0337 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 20417: loss = 0.0741 (0.282 sec/step)\n",
            "I0923 10:13:10.960609 139631849019264 learning.py:507] global step 20417: loss = 0.0741 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 20418: loss = 0.0471 (0.400 sec/step)\n",
            "I0923 10:13:11.362574 139631849019264 learning.py:507] global step 20418: loss = 0.0471 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 20419: loss = 0.0822 (0.323 sec/step)\n",
            "I0923 10:13:11.687285 139631849019264 learning.py:507] global step 20419: loss = 0.0822 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 20420: loss = 0.0651 (0.348 sec/step)\n",
            "I0923 10:13:12.037111 139631849019264 learning.py:507] global step 20420: loss = 0.0651 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 20421: loss = 0.0795 (0.318 sec/step)\n",
            "I0923 10:13:12.357116 139631849019264 learning.py:507] global step 20421: loss = 0.0795 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 20422: loss = 0.2090 (0.312 sec/step)\n",
            "I0923 10:13:12.671145 139631849019264 learning.py:507] global step 20422: loss = 0.2090 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 20423: loss = 0.0830 (0.332 sec/step)\n",
            "I0923 10:13:13.005078 139631849019264 learning.py:507] global step 20423: loss = 0.0830 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20424: loss = 0.0953 (0.294 sec/step)\n",
            "I0923 10:13:13.301343 139631849019264 learning.py:507] global step 20424: loss = 0.0953 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 20425: loss = 0.0406 (0.300 sec/step)\n",
            "I0923 10:13:13.603361 139631849019264 learning.py:507] global step 20425: loss = 0.0406 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 20426: loss = 0.1284 (0.291 sec/step)\n",
            "I0923 10:13:13.895649 139631849019264 learning.py:507] global step 20426: loss = 0.1284 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 20427: loss = 0.4192 (0.323 sec/step)\n",
            "I0923 10:13:14.220357 139631849019264 learning.py:507] global step 20427: loss = 0.4192 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 20428: loss = 0.0911 (0.316 sec/step)\n",
            "I0923 10:13:14.538249 139631849019264 learning.py:507] global step 20428: loss = 0.0911 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 20429: loss = 0.1371 (0.330 sec/step)\n",
            "I0923 10:13:14.870325 139631849019264 learning.py:507] global step 20429: loss = 0.1371 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 20430: loss = 0.0673 (0.329 sec/step)\n",
            "I0923 10:13:15.200975 139631849019264 learning.py:507] global step 20430: loss = 0.0673 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 20431: loss = 0.2531 (0.332 sec/step)\n",
            "I0923 10:13:15.534989 139631849019264 learning.py:507] global step 20431: loss = 0.2531 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20432: loss = 0.2003 (0.326 sec/step)\n",
            "I0923 10:13:15.863272 139631849019264 learning.py:507] global step 20432: loss = 0.2003 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20433: loss = 0.1593 (0.305 sec/step)\n",
            "I0923 10:13:16.170391 139631849019264 learning.py:507] global step 20433: loss = 0.1593 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 20434: loss = 0.0557 (0.309 sec/step)\n",
            "I0923 10:13:16.481419 139631849019264 learning.py:507] global step 20434: loss = 0.0557 (0.309 sec/step)\n",
            "INFO:tensorflow:global step 20435: loss = 0.2071 (0.365 sec/step)\n",
            "I0923 10:13:16.848496 139631849019264 learning.py:507] global step 20435: loss = 0.2071 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 20436: loss = 0.0808 (0.347 sec/step)\n",
            "I0923 10:13:17.197648 139631849019264 learning.py:507] global step 20436: loss = 0.0808 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 20437: loss = 0.0539 (0.333 sec/step)\n",
            "I0923 10:13:17.532508 139631849019264 learning.py:507] global step 20437: loss = 0.0539 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 20438: loss = 0.1217 (0.354 sec/step)\n",
            "I0923 10:13:17.888034 139631849019264 learning.py:507] global step 20438: loss = 0.1217 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 20439: loss = 0.1902 (0.287 sec/step)\n",
            "I0923 10:13:18.176478 139631849019264 learning.py:507] global step 20439: loss = 0.1902 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 20440: loss = 0.0778 (0.312 sec/step)\n",
            "I0923 10:13:18.489781 139631849019264 learning.py:507] global step 20440: loss = 0.0778 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 20441: loss = 0.1498 (0.347 sec/step)\n",
            "I0923 10:13:18.838443 139631849019264 learning.py:507] global step 20441: loss = 0.1498 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 20442: loss = 0.0700 (0.329 sec/step)\n",
            "I0923 10:13:19.169307 139631849019264 learning.py:507] global step 20442: loss = 0.0700 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 20443: loss = 0.0642 (0.297 sec/step)\n",
            "I0923 10:13:19.468592 139631849019264 learning.py:507] global step 20443: loss = 0.0642 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 20444: loss = 0.0846 (0.284 sec/step)\n",
            "I0923 10:13:19.754171 139631849019264 learning.py:507] global step 20444: loss = 0.0846 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 20445: loss = 0.0181 (0.323 sec/step)\n",
            "I0923 10:13:20.078221 139631849019264 learning.py:507] global step 20445: loss = 0.0181 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 20446: loss = 0.0558 (0.321 sec/step)\n",
            "I0923 10:13:20.400906 139631849019264 learning.py:507] global step 20446: loss = 0.0558 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 20447: loss = 0.0721 (0.336 sec/step)\n",
            "I0923 10:13:20.738493 139631849019264 learning.py:507] global step 20447: loss = 0.0721 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 20448: loss = 0.1617 (0.303 sec/step)\n",
            "I0923 10:13:21.043695 139631849019264 learning.py:507] global step 20448: loss = 0.1617 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 20449: loss = 0.0785 (0.325 sec/step)\n",
            "I0923 10:13:21.370884 139631849019264 learning.py:507] global step 20449: loss = 0.0785 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 20450: loss = 0.0947 (0.320 sec/step)\n",
            "I0923 10:13:21.692400 139631849019264 learning.py:507] global step 20450: loss = 0.0947 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 20451: loss = 0.1588 (0.292 sec/step)\n",
            "I0923 10:13:21.986364 139631849019264 learning.py:507] global step 20451: loss = 0.1588 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 20452: loss = 0.0817 (0.317 sec/step)\n",
            "I0923 10:13:22.305764 139631849019264 learning.py:507] global step 20452: loss = 0.0817 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 20453: loss = 0.0554 (0.281 sec/step)\n",
            "I0923 10:13:22.588851 139631849019264 learning.py:507] global step 20453: loss = 0.0554 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 20454: loss = 0.0351 (0.339 sec/step)\n",
            "I0923 10:13:22.930142 139631849019264 learning.py:507] global step 20454: loss = 0.0351 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 20455: loss = 0.0570 (0.304 sec/step)\n",
            "I0923 10:13:23.236236 139631849019264 learning.py:507] global step 20455: loss = 0.0570 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 20456: loss = 0.0511 (0.326 sec/step)\n",
            "I0923 10:13:23.563813 139631849019264 learning.py:507] global step 20456: loss = 0.0511 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20457: loss = 0.2010 (0.304 sec/step)\n",
            "I0923 10:13:23.869862 139631849019264 learning.py:507] global step 20457: loss = 0.2010 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 20458: loss = 0.1112 (0.326 sec/step)\n",
            "I0923 10:13:24.197893 139631849019264 learning.py:507] global step 20458: loss = 0.1112 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20459: loss = 0.2397 (0.311 sec/step)\n",
            "I0923 10:13:24.510941 139631849019264 learning.py:507] global step 20459: loss = 0.2397 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 20460: loss = 0.0461 (0.293 sec/step)\n",
            "I0923 10:13:24.806147 139631849019264 learning.py:507] global step 20460: loss = 0.0461 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 20461: loss = 0.1371 (0.326 sec/step)\n",
            "I0923 10:13:25.133976 139631849019264 learning.py:507] global step 20461: loss = 0.1371 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20462: loss = 0.0716 (0.324 sec/step)\n",
            "I0923 10:13:25.459694 139631849019264 learning.py:507] global step 20462: loss = 0.0716 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 20463: loss = 0.0421 (0.288 sec/step)\n",
            "I0923 10:13:25.749355 139631849019264 learning.py:507] global step 20463: loss = 0.0421 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 20464: loss = 0.0351 (0.350 sec/step)\n",
            "I0923 10:13:26.101402 139631849019264 learning.py:507] global step 20464: loss = 0.0351 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 20465: loss = 0.0542 (0.326 sec/step)\n",
            "I0923 10:13:26.429408 139631849019264 learning.py:507] global step 20465: loss = 0.0542 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20466: loss = 0.1770 (0.311 sec/step)\n",
            "I0923 10:13:26.742809 139631849019264 learning.py:507] global step 20466: loss = 0.1770 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 20467: loss = 0.0562 (0.396 sec/step)\n",
            "I0923 10:13:27.140104 139631849019264 learning.py:507] global step 20467: loss = 0.0562 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 20468: loss = 0.0786 (0.336 sec/step)\n",
            "I0923 10:13:27.478246 139631849019264 learning.py:507] global step 20468: loss = 0.0786 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 20469: loss = 0.0440 (0.324 sec/step)\n",
            "I0923 10:13:27.805009 139631849019264 learning.py:507] global step 20469: loss = 0.0440 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 20470: loss = 0.0873 (0.328 sec/step)\n",
            "I0923 10:13:28.134771 139631849019264 learning.py:507] global step 20470: loss = 0.0873 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 20471: loss = 0.0550 (0.303 sec/step)\n",
            "I0923 10:13:28.439437 139631849019264 learning.py:507] global step 20471: loss = 0.0550 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 20472: loss = 0.0584 (0.275 sec/step)\n",
            "I0923 10:13:28.715786 139631849019264 learning.py:507] global step 20472: loss = 0.0584 (0.275 sec/step)\n",
            "INFO:tensorflow:global step 20473: loss = 0.1730 (0.327 sec/step)\n",
            "I0923 10:13:29.044276 139631849019264 learning.py:507] global step 20473: loss = 0.1730 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 20474: loss = 0.0535 (0.311 sec/step)\n",
            "I0923 10:13:29.356973 139631849019264 learning.py:507] global step 20474: loss = 0.0535 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 20475: loss = 0.1237 (0.354 sec/step)\n",
            "I0923 10:13:29.713109 139631849019264 learning.py:507] global step 20475: loss = 0.1237 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 20476: loss = 0.0878 (0.323 sec/step)\n",
            "I0923 10:13:30.037397 139631849019264 learning.py:507] global step 20476: loss = 0.0878 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 20477: loss = 0.2855 (0.304 sec/step)\n",
            "I0923 10:13:30.343523 139631849019264 learning.py:507] global step 20477: loss = 0.2855 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 20478: loss = 0.1485 (0.326 sec/step)\n",
            "I0923 10:13:30.670817 139631849019264 learning.py:507] global step 20478: loss = 0.1485 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20479: loss = 0.2923 (0.381 sec/step)\n",
            "I0923 10:13:31.053518 139631849019264 learning.py:507] global step 20479: loss = 0.2923 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 20480: loss = 0.0648 (0.289 sec/step)\n",
            "I0923 10:13:31.344335 139631849019264 learning.py:507] global step 20480: loss = 0.0648 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 20481: loss = 0.2869 (0.285 sec/step)\n",
            "I0923 10:13:31.630955 139631849019264 learning.py:507] global step 20481: loss = 0.2869 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 20482: loss = 0.0708 (0.287 sec/step)\n",
            "I0923 10:13:31.920244 139631849019264 learning.py:507] global step 20482: loss = 0.0708 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 20483: loss = 0.1946 (0.332 sec/step)\n",
            "I0923 10:13:32.254483 139631849019264 learning.py:507] global step 20483: loss = 0.1946 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20484: loss = 0.0476 (0.299 sec/step)\n",
            "I0923 10:13:32.555385 139631849019264 learning.py:507] global step 20484: loss = 0.0476 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 20485: loss = 0.1360 (0.343 sec/step)\n",
            "I0923 10:13:32.900483 139631849019264 learning.py:507] global step 20485: loss = 0.1360 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 20486: loss = 0.0907 (0.339 sec/step)\n",
            "I0923 10:13:33.241294 139631849019264 learning.py:507] global step 20486: loss = 0.0907 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 20487: loss = 0.0596 (0.342 sec/step)\n",
            "I0923 10:13:33.584760 139631849019264 learning.py:507] global step 20487: loss = 0.0596 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 20488: loss = 0.1282 (0.365 sec/step)\n",
            "I0923 10:13:33.952130 139631849019264 learning.py:507] global step 20488: loss = 0.1282 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 20489: loss = 0.0507 (0.340 sec/step)\n",
            "I0923 10:13:34.294260 139631849019264 learning.py:507] global step 20489: loss = 0.0507 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 20490: loss = 0.1359 (0.322 sec/step)\n",
            "I0923 10:13:34.618326 139631849019264 learning.py:507] global step 20490: loss = 0.1359 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 20491: loss = 0.1322 (0.314 sec/step)\n",
            "I0923 10:13:34.934370 139631849019264 learning.py:507] global step 20491: loss = 0.1322 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 20492: loss = 0.0321 (0.324 sec/step)\n",
            "I0923 10:13:35.260318 139631849019264 learning.py:507] global step 20492: loss = 0.0321 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 20493: loss = 0.0484 (0.280 sec/step)\n",
            "I0923 10:13:35.542007 139631849019264 learning.py:507] global step 20493: loss = 0.0484 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 20494: loss = 0.0867 (0.428 sec/step)\n",
            "I0923 10:13:35.972372 139631849019264 learning.py:507] global step 20494: loss = 0.0867 (0.428 sec/step)\n",
            "INFO:tensorflow:global step 20495: loss = 0.0429 (0.327 sec/step)\n",
            "I0923 10:13:36.301313 139631849019264 learning.py:507] global step 20495: loss = 0.0429 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 20496: loss = 0.0521 (0.329 sec/step)\n",
            "I0923 10:13:36.632462 139631849019264 learning.py:507] global step 20496: loss = 0.0521 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 20497: loss = 0.0423 (0.304 sec/step)\n",
            "I0923 10:13:36.938004 139631849019264 learning.py:507] global step 20497: loss = 0.0423 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 20498: loss = 0.0971 (0.332 sec/step)\n",
            "I0923 10:13:37.271893 139631849019264 learning.py:507] global step 20498: loss = 0.0971 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20499: loss = 0.0858 (0.286 sec/step)\n",
            "I0923 10:13:37.560110 139631849019264 learning.py:507] global step 20499: loss = 0.0858 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 20500: loss = 0.0881 (0.333 sec/step)\n",
            "I0923 10:13:37.894931 139631849019264 learning.py:507] global step 20500: loss = 0.0881 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 20501: loss = 0.0379 (0.326 sec/step)\n",
            "I0923 10:13:38.222614 139631849019264 learning.py:507] global step 20501: loss = 0.0379 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20502: loss = 0.0844 (0.289 sec/step)\n",
            "I0923 10:13:38.512987 139631849019264 learning.py:507] global step 20502: loss = 0.0844 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 20503: loss = 0.0448 (0.334 sec/step)\n",
            "I0923 10:13:38.849524 139631849019264 learning.py:507] global step 20503: loss = 0.0448 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 20504: loss = 0.0687 (0.317 sec/step)\n",
            "I0923 10:13:39.168386 139631849019264 learning.py:507] global step 20504: loss = 0.0687 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 20505: loss = 0.0625 (0.286 sec/step)\n",
            "I0923 10:13:39.457178 139631849019264 learning.py:507] global step 20505: loss = 0.0625 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 20506: loss = 0.1084 (0.340 sec/step)\n",
            "I0923 10:13:39.799766 139631849019264 learning.py:507] global step 20506: loss = 0.1084 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 20507: loss = 0.0972 (0.414 sec/step)\n",
            "I0923 10:13:40.216555 139631849019264 learning.py:507] global step 20507: loss = 0.0972 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 20508: loss = 0.0222 (0.331 sec/step)\n",
            "I0923 10:13:40.549425 139631849019264 learning.py:507] global step 20508: loss = 0.0222 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 20509: loss = 0.0584 (0.297 sec/step)\n",
            "I0923 10:13:40.848034 139631849019264 learning.py:507] global step 20509: loss = 0.0584 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 20510: loss = 0.0408 (0.305 sec/step)\n",
            "I0923 10:13:41.155104 139631849019264 learning.py:507] global step 20510: loss = 0.0408 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 20511: loss = 0.0763 (0.283 sec/step)\n",
            "I0923 10:13:41.440098 139631849019264 learning.py:507] global step 20511: loss = 0.0763 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 20512: loss = 0.1245 (0.313 sec/step)\n",
            "I0923 10:13:41.755167 139631849019264 learning.py:507] global step 20512: loss = 0.1245 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 20513: loss = 0.0792 (0.333 sec/step)\n",
            "I0923 10:13:42.090216 139631849019264 learning.py:507] global step 20513: loss = 0.0792 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 20514: loss = 0.0335 (0.297 sec/step)\n",
            "I0923 10:13:42.388972 139631849019264 learning.py:507] global step 20514: loss = 0.0335 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 20515: loss = 0.0561 (0.320 sec/step)\n",
            "I0923 10:13:42.710607 139631849019264 learning.py:507] global step 20515: loss = 0.0561 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 20516: loss = 0.0569 (0.311 sec/step)\n",
            "I0923 10:13:43.023787 139631849019264 learning.py:507] global step 20516: loss = 0.0569 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 20517: loss = 0.0691 (0.310 sec/step)\n",
            "I0923 10:13:43.335404 139631849019264 learning.py:507] global step 20517: loss = 0.0691 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 20518: loss = 0.0258 (0.310 sec/step)\n",
            "I0923 10:13:43.646953 139631849019264 learning.py:507] global step 20518: loss = 0.0258 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 20519: loss = 0.0936 (0.339 sec/step)\n",
            "I0923 10:13:43.987940 139631849019264 learning.py:507] global step 20519: loss = 0.0936 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 20520: loss = 0.1292 (0.330 sec/step)\n",
            "I0923 10:13:44.319842 139631849019264 learning.py:507] global step 20520: loss = 0.1292 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 20521: loss = 0.0629 (0.282 sec/step)\n",
            "I0923 10:13:44.604143 139631849019264 learning.py:507] global step 20521: loss = 0.0629 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 20522: loss = 0.0236 (0.393 sec/step)\n",
            "I0923 10:13:44.999265 139631849019264 learning.py:507] global step 20522: loss = 0.0236 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 20523: loss = 0.1200 (0.286 sec/step)\n",
            "I0923 10:13:45.287646 139631849019264 learning.py:507] global step 20523: loss = 0.1200 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 20524: loss = 0.0613 (0.289 sec/step)\n",
            "I0923 10:13:45.578806 139631849019264 learning.py:507] global step 20524: loss = 0.0613 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 20525: loss = 0.0686 (0.293 sec/step)\n",
            "I0923 10:13:45.874490 139631849019264 learning.py:507] global step 20525: loss = 0.0686 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 20526: loss = 0.1071 (0.331 sec/step)\n",
            "I0923 10:13:46.207987 139631849019264 learning.py:507] global step 20526: loss = 0.1071 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 20527: loss = 0.0364 (0.295 sec/step)\n",
            "I0923 10:13:46.505319 139631849019264 learning.py:507] global step 20527: loss = 0.0364 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 20528: loss = 0.1246 (0.318 sec/step)\n",
            "I0923 10:13:46.824529 139631849019264 learning.py:507] global step 20528: loss = 0.1246 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 20529: loss = 0.0582 (0.291 sec/step)\n",
            "I0923 10:13:47.117027 139631849019264 learning.py:507] global step 20529: loss = 0.0582 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 20530: loss = 0.0401 (0.299 sec/step)\n",
            "I0923 10:13:47.417775 139631849019264 learning.py:507] global step 20530: loss = 0.0401 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 20531: loss = 0.2473 (0.354 sec/step)\n",
            "I0923 10:13:47.773332 139631849019264 learning.py:507] global step 20531: loss = 0.2473 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 20532: loss = 0.1176 (0.287 sec/step)\n",
            "I0923 10:13:48.062300 139631849019264 learning.py:507] global step 20532: loss = 0.1176 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 20533: loss = 0.1307 (0.289 sec/step)\n",
            "I0923 10:13:48.353299 139631849019264 learning.py:507] global step 20533: loss = 0.1307 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 20534: loss = 0.0936 (0.305 sec/step)\n",
            "I0923 10:13:48.659860 139631849019264 learning.py:507] global step 20534: loss = 0.0936 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 20535: loss = 0.0715 (0.291 sec/step)\n",
            "I0923 10:13:48.952771 139631849019264 learning.py:507] global step 20535: loss = 0.0715 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 20536: loss = 0.0921 (0.333 sec/step)\n",
            "I0923 10:13:49.287249 139631849019264 learning.py:507] global step 20536: loss = 0.0921 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 20537: loss = 0.0485 (0.320 sec/step)\n",
            "I0923 10:13:49.609249 139631849019264 learning.py:507] global step 20537: loss = 0.0485 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 20538: loss = 0.0446 (0.321 sec/step)\n",
            "I0923 10:13:49.932077 139631849019264 learning.py:507] global step 20538: loss = 0.0446 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 20539: loss = 0.0823 (0.342 sec/step)\n",
            "I0923 10:13:50.276300 139631849019264 learning.py:507] global step 20539: loss = 0.0823 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 20540: loss = 0.1101 (0.327 sec/step)\n",
            "I0923 10:13:50.605433 139631849019264 learning.py:507] global step 20540: loss = 0.1101 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 20541: loss = 0.0728 (0.286 sec/step)\n",
            "I0923 10:13:50.893380 139631849019264 learning.py:507] global step 20541: loss = 0.0728 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 20542: loss = 0.2446 (0.307 sec/step)\n",
            "I0923 10:13:51.202646 139631849019264 learning.py:507] global step 20542: loss = 0.2446 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 20543: loss = 0.0644 (0.280 sec/step)\n",
            "I0923 10:13:51.484005 139631849019264 learning.py:507] global step 20543: loss = 0.0644 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 20544: loss = 0.1036 (0.304 sec/step)\n",
            "I0923 10:13:51.789605 139631849019264 learning.py:507] global step 20544: loss = 0.1036 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 20545: loss = 0.0482 (0.387 sec/step)\n",
            "I0923 10:13:52.178972 139631849019264 learning.py:507] global step 20545: loss = 0.0482 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 20546: loss = 0.0543 (0.328 sec/step)\n",
            "I0923 10:13:52.508591 139631849019264 learning.py:507] global step 20546: loss = 0.0543 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 20547: loss = 0.0865 (0.311 sec/step)\n",
            "I0923 10:13:52.821108 139631849019264 learning.py:507] global step 20547: loss = 0.0865 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 20548: loss = 0.1300 (0.333 sec/step)\n",
            "I0923 10:13:53.156149 139631849019264 learning.py:507] global step 20548: loss = 0.1300 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 20549: loss = 0.1700 (0.337 sec/step)\n",
            "I0923 10:13:53.494352 139631849019264 learning.py:507] global step 20549: loss = 0.1700 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 20550: loss = 0.1406 (0.270 sec/step)\n",
            "I0923 10:13:53.765809 139631849019264 learning.py:507] global step 20550: loss = 0.1406 (0.270 sec/step)\n",
            "INFO:tensorflow:global step 20551: loss = 0.1675 (0.301 sec/step)\n",
            "I0923 10:13:54.068646 139631849019264 learning.py:507] global step 20551: loss = 0.1675 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 20552: loss = 0.3186 (0.263 sec/step)\n",
            "I0923 10:13:54.333544 139631849019264 learning.py:507] global step 20552: loss = 0.3186 (0.263 sec/step)\n",
            "INFO:tensorflow:global step 20553: loss = 0.0338 (0.325 sec/step)\n",
            "I0923 10:13:54.660678 139631849019264 learning.py:507] global step 20553: loss = 0.0338 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 20554: loss = 0.0591 (0.285 sec/step)\n",
            "I0923 10:13:54.947050 139631849019264 learning.py:507] global step 20554: loss = 0.0591 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 20555: loss = 0.0508 (0.293 sec/step)\n",
            "I0923 10:13:55.242339 139631849019264 learning.py:507] global step 20555: loss = 0.0508 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 20556: loss = 0.0230 (0.291 sec/step)\n",
            "I0923 10:13:55.535197 139631849019264 learning.py:507] global step 20556: loss = 0.0230 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 20557: loss = 0.1100 (0.289 sec/step)\n",
            "I0923 10:13:55.825824 139631849019264 learning.py:507] global step 20557: loss = 0.1100 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 20558: loss = 0.1165 (0.344 sec/step)\n",
            "I0923 10:13:56.171696 139631849019264 learning.py:507] global step 20558: loss = 0.1165 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 20559: loss = 0.2607 (0.295 sec/step)\n",
            "I0923 10:13:56.468830 139631849019264 learning.py:507] global step 20559: loss = 0.2607 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 20560: loss = 0.0895 (0.316 sec/step)\n",
            "I0923 10:13:56.786314 139631849019264 learning.py:507] global step 20560: loss = 0.0895 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 20561: loss = 0.1381 (0.303 sec/step)\n",
            "I0923 10:13:57.091128 139631849019264 learning.py:507] global step 20561: loss = 0.1381 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 20562: loss = 0.2808 (0.306 sec/step)\n",
            "I0923 10:13:57.399146 139631849019264 learning.py:507] global step 20562: loss = 0.2808 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 20563: loss = 0.1062 (0.326 sec/step)\n",
            "I0923 10:13:57.727177 139631849019264 learning.py:507] global step 20563: loss = 0.1062 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20564: loss = 0.1124 (0.370 sec/step)\n",
            "I0923 10:13:58.102432 139631849019264 learning.py:507] global step 20564: loss = 0.1124 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 20565: loss = 0.1661 (0.307 sec/step)\n",
            "I0923 10:13:58.411469 139631849019264 learning.py:507] global step 20565: loss = 0.1661 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 20566: loss = 0.1700 (0.347 sec/step)\n",
            "I0923 10:13:58.760919 139631849019264 learning.py:507] global step 20566: loss = 0.1700 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 20567: loss = 0.0687 (0.327 sec/step)\n",
            "I0923 10:13:59.090158 139631849019264 learning.py:507] global step 20567: loss = 0.0687 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 20568: loss = 0.2208 (0.307 sec/step)\n",
            "I0923 10:13:59.399264 139631849019264 learning.py:507] global step 20568: loss = 0.2208 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 20569: loss = 0.0849 (0.335 sec/step)\n",
            "I0923 10:13:59.736105 139631849019264 learning.py:507] global step 20569: loss = 0.0849 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 20570: loss = 0.1023 (0.339 sec/step)\n",
            "I0923 10:14:00.077569 139631849019264 learning.py:507] global step 20570: loss = 0.1023 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 20571: loss = 0.0708 (0.292 sec/step)\n",
            "I0923 10:14:00.371708 139631849019264 learning.py:507] global step 20571: loss = 0.0708 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 20572: loss = 0.0920 (0.364 sec/step)\n",
            "I0923 10:14:00.737422 139631849019264 learning.py:507] global step 20572: loss = 0.0920 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 20573: loss = 0.0577 (0.338 sec/step)\n",
            "I0923 10:14:01.077730 139631849019264 learning.py:507] global step 20573: loss = 0.0577 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 20574: loss = 0.0330 (0.300 sec/step)\n",
            "I0923 10:14:01.379538 139631849019264 learning.py:507] global step 20574: loss = 0.0330 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 20575: loss = 0.1142 (0.280 sec/step)\n",
            "I0923 10:14:01.661821 139631849019264 learning.py:507] global step 20575: loss = 0.1142 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 20576: loss = 0.0578 (0.268 sec/step)\n",
            "I0923 10:14:01.931406 139631849019264 learning.py:507] global step 20576: loss = 0.0578 (0.268 sec/step)\n",
            "INFO:tensorflow:global step 20577: loss = 0.0687 (0.310 sec/step)\n",
            "I0923 10:14:02.243095 139631849019264 learning.py:507] global step 20577: loss = 0.0687 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 20578: loss = 0.0893 (0.281 sec/step)\n",
            "I0923 10:14:02.526248 139631849019264 learning.py:507] global step 20578: loss = 0.0893 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 20579: loss = 0.1585 (0.282 sec/step)\n",
            "I0923 10:14:02.809967 139631849019264 learning.py:507] global step 20579: loss = 0.1585 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 20580: loss = 0.0677 (0.344 sec/step)\n",
            "I0923 10:14:03.156271 139631849019264 learning.py:507] global step 20580: loss = 0.0677 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 20581: loss = 0.2069 (0.291 sec/step)\n",
            "I0923 10:14:03.448876 139631849019264 learning.py:507] global step 20581: loss = 0.2069 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 20582: loss = 0.2326 (0.359 sec/step)\n",
            "I0923 10:14:03.809184 139631849019264 learning.py:507] global step 20582: loss = 0.2326 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 20583: loss = 0.0313 (0.287 sec/step)\n",
            "I0923 10:14:04.098506 139631849019264 learning.py:507] global step 20583: loss = 0.0313 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 20584: loss = 0.0588 (0.307 sec/step)\n",
            "I0923 10:14:04.407138 139631849019264 learning.py:507] global step 20584: loss = 0.0588 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 20585: loss = 0.0388 (0.274 sec/step)\n",
            "I0923 10:14:04.683149 139631849019264 learning.py:507] global step 20585: loss = 0.0388 (0.274 sec/step)\n",
            "INFO:tensorflow:global step 20586: loss = 0.0740 (0.328 sec/step)\n",
            "I0923 10:14:05.013018 139631849019264 learning.py:507] global step 20586: loss = 0.0740 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 20587: loss = 0.0698 (0.306 sec/step)\n",
            "I0923 10:14:05.320780 139631849019264 learning.py:507] global step 20587: loss = 0.0698 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 20588: loss = 0.0578 (0.360 sec/step)\n",
            "I0923 10:14:05.682605 139631849019264 learning.py:507] global step 20588: loss = 0.0578 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 20589: loss = 0.0784 (0.290 sec/step)\n",
            "I0923 10:14:05.973970 139631849019264 learning.py:507] global step 20589: loss = 0.0784 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 20590: loss = 0.0746 (0.339 sec/step)\n",
            "I0923 10:14:06.316005 139631849019264 learning.py:507] global step 20590: loss = 0.0746 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 20591: loss = 0.0745 (0.364 sec/step)\n",
            "I0923 10:14:06.681516 139631849019264 learning.py:507] global step 20591: loss = 0.0745 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 20592: loss = 0.0577 (0.279 sec/step)\n",
            "I0923 10:14:06.962763 139631849019264 learning.py:507] global step 20592: loss = 0.0577 (0.279 sec/step)\n",
            "INFO:tensorflow:global step 20593: loss = 0.1663 (0.278 sec/step)\n",
            "I0923 10:14:07.242376 139631849019264 learning.py:507] global step 20593: loss = 0.1663 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 20594: loss = 0.0696 (0.295 sec/step)\n",
            "I0923 10:14:07.538800 139631849019264 learning.py:507] global step 20594: loss = 0.0696 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 20595: loss = 0.0482 (0.277 sec/step)\n",
            "I0923 10:14:07.817337 139631849019264 learning.py:507] global step 20595: loss = 0.0482 (0.277 sec/step)\n",
            "INFO:tensorflow:global step 20596: loss = 0.0692 (0.313 sec/step)\n",
            "I0923 10:14:08.132123 139631849019264 learning.py:507] global step 20596: loss = 0.0692 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 20597: loss = 0.0760 (0.316 sec/step)\n",
            "I0923 10:14:08.449498 139631849019264 learning.py:507] global step 20597: loss = 0.0760 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 20598: loss = 0.0600 (0.340 sec/step)\n",
            "I0923 10:14:08.791340 139631849019264 learning.py:507] global step 20598: loss = 0.0600 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 20599: loss = 0.1080 (0.328 sec/step)\n",
            "I0923 10:14:09.121124 139631849019264 learning.py:507] global step 20599: loss = 0.1080 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 20600: loss = 0.0955 (0.317 sec/step)\n",
            "I0923 10:14:09.440459 139631849019264 learning.py:507] global step 20600: loss = 0.0955 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 20601: loss = 0.0928 (0.322 sec/step)\n",
            "I0923 10:14:09.764171 139631849019264 learning.py:507] global step 20601: loss = 0.0928 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 20602: loss = 0.0575 (0.324 sec/step)\n",
            "I0923 10:14:10.089626 139631849019264 learning.py:507] global step 20602: loss = 0.0575 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 20603: loss = 0.0991 (0.306 sec/step)\n",
            "I0923 10:14:10.398275 139631849019264 learning.py:507] global step 20603: loss = 0.0991 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 20604: loss = 0.1602 (0.295 sec/step)\n",
            "I0923 10:14:10.694949 139631849019264 learning.py:507] global step 20604: loss = 0.1602 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 20605: loss = 0.0871 (0.327 sec/step)\n",
            "I0923 10:14:11.023690 139631849019264 learning.py:507] global step 20605: loss = 0.0871 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 20606: loss = 0.0397 (0.336 sec/step)\n",
            "I0923 10:14:11.361439 139631849019264 learning.py:507] global step 20606: loss = 0.0397 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 20607: loss = 0.0571 (0.329 sec/step)\n",
            "I0923 10:14:11.692514 139631849019264 learning.py:507] global step 20607: loss = 0.0571 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 20608: loss = 0.2770 (0.283 sec/step)\n",
            "I0923 10:14:11.977934 139631849019264 learning.py:507] global step 20608: loss = 0.2770 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 20609: loss = 0.0940 (0.321 sec/step)\n",
            "I0923 10:14:12.300373 139631849019264 learning.py:507] global step 20609: loss = 0.0940 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 20610: loss = 0.0518 (0.295 sec/step)\n",
            "I0923 10:14:12.596890 139631849019264 learning.py:507] global step 20610: loss = 0.0518 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 20611: loss = 0.0450 (0.285 sec/step)\n",
            "I0923 10:14:12.884101 139631849019264 learning.py:507] global step 20611: loss = 0.0450 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 20612: loss = 0.0634 (0.305 sec/step)\n",
            "I0923 10:14:13.190747 139631849019264 learning.py:507] global step 20612: loss = 0.0634 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 20613: loss = 0.3479 (0.312 sec/step)\n",
            "I0923 10:14:13.504427 139631849019264 learning.py:507] global step 20613: loss = 0.3479 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 20614: loss = 0.2230 (0.317 sec/step)\n",
            "I0923 10:14:13.823880 139631849019264 learning.py:507] global step 20614: loss = 0.2230 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 20615: loss = 0.1128 (0.343 sec/step)\n",
            "I0923 10:14:14.168925 139631849019264 learning.py:507] global step 20615: loss = 0.1128 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 20616: loss = 0.0895 (0.311 sec/step)\n",
            "I0923 10:14:14.481743 139631849019264 learning.py:507] global step 20616: loss = 0.0895 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 20617: loss = 0.1082 (0.346 sec/step)\n",
            "I0923 10:14:14.829589 139631849019264 learning.py:507] global step 20617: loss = 0.1082 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 20618: loss = 0.0289 (0.321 sec/step)\n",
            "I0923 10:14:15.153094 139631849019264 learning.py:507] global step 20618: loss = 0.0289 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 20619: loss = 0.0689 (0.333 sec/step)\n",
            "I0923 10:14:15.488120 139631849019264 learning.py:507] global step 20619: loss = 0.0689 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 20620: loss = 0.1470 (0.328 sec/step)\n",
            "I0923 10:14:15.818121 139631849019264 learning.py:507] global step 20620: loss = 0.1470 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 20621: loss = 0.0971 (0.321 sec/step)\n",
            "I0923 10:14:16.141038 139631849019264 learning.py:507] global step 20621: loss = 0.0971 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 20622: loss = 0.0733 (0.322 sec/step)\n",
            "I0923 10:14:16.464610 139631849019264 learning.py:507] global step 20622: loss = 0.0733 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 20623: loss = 0.0751 (0.340 sec/step)\n",
            "I0923 10:14:16.806195 139631849019264 learning.py:507] global step 20623: loss = 0.0751 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 20624: loss = 0.1024 (0.293 sec/step)\n",
            "I0923 10:14:17.101325 139631849019264 learning.py:507] global step 20624: loss = 0.1024 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 20625: loss = 0.0523 (0.361 sec/step)\n",
            "I0923 10:14:17.464357 139631849019264 learning.py:507] global step 20625: loss = 0.0523 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 20626: loss = 0.1013 (0.317 sec/step)\n",
            "I0923 10:14:17.783267 139631849019264 learning.py:507] global step 20626: loss = 0.1013 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 20627: loss = 0.1676 (0.294 sec/step)\n",
            "I0923 10:14:18.081395 139631849019264 learning.py:507] global step 20627: loss = 0.1676 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 20628: loss = 0.0712 (0.372 sec/step)\n",
            "I0923 10:14:18.466503 139631849019264 learning.py:507] global step 20628: loss = 0.0712 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 20629: loss = 0.0851 (0.377 sec/step)\n",
            "I0923 10:14:18.848402 139631849019264 learning.py:507] global step 20629: loss = 0.0851 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 20630: loss = 0.1926 (0.441 sec/step)\n",
            "I0923 10:14:19.295076 139631849019264 learning.py:507] global step 20630: loss = 0.1926 (0.441 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 20630.\n",
            "I0923 10:14:19.400205 139628630939392 supervisor.py:1050] Recording summary at step 20630.\n",
            "INFO:tensorflow:global step 20631: loss = 0.0265 (0.332 sec/step)\n",
            "I0923 10:14:19.629276 139631849019264 learning.py:507] global step 20631: loss = 0.0265 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20632: loss = 0.0566 (0.327 sec/step)\n",
            "I0923 10:14:19.958222 139631849019264 learning.py:507] global step 20632: loss = 0.0566 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 20633: loss = 0.0483 (0.360 sec/step)\n",
            "I0923 10:14:20.320119 139631849019264 learning.py:507] global step 20633: loss = 0.0483 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 20634: loss = 0.0555 (0.296 sec/step)\n",
            "I0923 10:14:20.617629 139631849019264 learning.py:507] global step 20634: loss = 0.0555 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 20635: loss = 0.1084 (0.313 sec/step)\n",
            "I0923 10:14:20.932552 139631849019264 learning.py:507] global step 20635: loss = 0.1084 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 20636: loss = 0.0784 (0.296 sec/step)\n",
            "I0923 10:14:21.230640 139631849019264 learning.py:507] global step 20636: loss = 0.0784 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 20637: loss = 0.2188 (0.289 sec/step)\n",
            "I0923 10:14:21.521307 139631849019264 learning.py:507] global step 20637: loss = 0.2188 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 20638: loss = 0.0583 (0.333 sec/step)\n",
            "I0923 10:14:21.856222 139631849019264 learning.py:507] global step 20638: loss = 0.0583 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 20639: loss = 0.1536 (0.341 sec/step)\n",
            "I0923 10:14:22.198969 139631849019264 learning.py:507] global step 20639: loss = 0.1536 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 20640: loss = 0.0627 (0.281 sec/step)\n",
            "I0923 10:14:22.481981 139631849019264 learning.py:507] global step 20640: loss = 0.0627 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 20641: loss = 0.0633 (0.334 sec/step)\n",
            "I0923 10:14:22.818320 139631849019264 learning.py:507] global step 20641: loss = 0.0633 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 20642: loss = 0.1325 (0.303 sec/step)\n",
            "I0923 10:14:23.123448 139631849019264 learning.py:507] global step 20642: loss = 0.1325 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 20643: loss = 0.0754 (0.330 sec/step)\n",
            "I0923 10:14:23.455519 139631849019264 learning.py:507] global step 20643: loss = 0.0754 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 20644: loss = 0.0422 (0.308 sec/step)\n",
            "I0923 10:14:23.765682 139631849019264 learning.py:507] global step 20644: loss = 0.0422 (0.308 sec/step)\n",
            "INFO:tensorflow:global step 20645: loss = 0.0679 (0.289 sec/step)\n",
            "I0923 10:14:24.056999 139631849019264 learning.py:507] global step 20645: loss = 0.0679 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 20646: loss = 0.2234 (0.323 sec/step)\n",
            "I0923 10:14:24.382050 139631849019264 learning.py:507] global step 20646: loss = 0.2234 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 20647: loss = 0.2077 (0.454 sec/step)\n",
            "I0923 10:14:24.837845 139631849019264 learning.py:507] global step 20647: loss = 0.2077 (0.454 sec/step)\n",
            "INFO:tensorflow:global step 20648: loss = 0.0461 (0.317 sec/step)\n",
            "I0923 10:14:25.156236 139631849019264 learning.py:507] global step 20648: loss = 0.0461 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 20649: loss = 0.0900 (0.340 sec/step)\n",
            "I0923 10:14:25.498471 139631849019264 learning.py:507] global step 20649: loss = 0.0900 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 20650: loss = 0.0715 (0.388 sec/step)\n",
            "I0923 10:14:25.888478 139631849019264 learning.py:507] global step 20650: loss = 0.0715 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 20651: loss = 0.0262 (0.313 sec/step)\n",
            "I0923 10:14:26.203577 139631849019264 learning.py:507] global step 20651: loss = 0.0262 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 20652: loss = 0.0757 (0.281 sec/step)\n",
            "I0923 10:14:26.487008 139631849019264 learning.py:507] global step 20652: loss = 0.0757 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 20653: loss = 0.1626 (0.355 sec/step)\n",
            "I0923 10:14:26.844517 139631849019264 learning.py:507] global step 20653: loss = 0.1626 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 20654: loss = 0.0562 (0.315 sec/step)\n",
            "I0923 10:14:27.162239 139631849019264 learning.py:507] global step 20654: loss = 0.0562 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 20655: loss = 0.1380 (0.304 sec/step)\n",
            "I0923 10:14:27.468266 139631849019264 learning.py:507] global step 20655: loss = 0.1380 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 20656: loss = 0.1171 (0.294 sec/step)\n",
            "I0923 10:14:27.764110 139631849019264 learning.py:507] global step 20656: loss = 0.1171 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 20657: loss = 0.0573 (0.334 sec/step)\n",
            "I0923 10:14:28.100127 139631849019264 learning.py:507] global step 20657: loss = 0.0573 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 20658: loss = 0.0781 (0.384 sec/step)\n",
            "I0923 10:14:28.485843 139631849019264 learning.py:507] global step 20658: loss = 0.0781 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 20659: loss = 0.1736 (0.279 sec/step)\n",
            "I0923 10:14:28.767348 139631849019264 learning.py:507] global step 20659: loss = 0.1736 (0.279 sec/step)\n",
            "INFO:tensorflow:global step 20660: loss = 0.0665 (0.344 sec/step)\n",
            "I0923 10:14:29.113118 139631849019264 learning.py:507] global step 20660: loss = 0.0665 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 20661: loss = 0.0616 (0.306 sec/step)\n",
            "I0923 10:14:29.420653 139631849019264 learning.py:507] global step 20661: loss = 0.0616 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 20662: loss = 0.0730 (0.298 sec/step)\n",
            "I0923 10:14:29.719938 139631849019264 learning.py:507] global step 20662: loss = 0.0730 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 20663: loss = 0.0569 (0.300 sec/step)\n",
            "I0923 10:14:30.022694 139631849019264 learning.py:507] global step 20663: loss = 0.0569 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 20664: loss = 0.1040 (0.357 sec/step)\n",
            "I0923 10:14:30.382024 139631849019264 learning.py:507] global step 20664: loss = 0.1040 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 20665: loss = 0.0848 (0.309 sec/step)\n",
            "I0923 10:14:30.693047 139631849019264 learning.py:507] global step 20665: loss = 0.0848 (0.309 sec/step)\n",
            "INFO:tensorflow:global step 20666: loss = 0.2248 (0.318 sec/step)\n",
            "I0923 10:14:31.013160 139631849019264 learning.py:507] global step 20666: loss = 0.2248 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 20667: loss = 0.0281 (0.301 sec/step)\n",
            "I0923 10:14:31.316420 139631849019264 learning.py:507] global step 20667: loss = 0.0281 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 20668: loss = 0.0657 (0.347 sec/step)\n",
            "I0923 10:14:31.665480 139631849019264 learning.py:507] global step 20668: loss = 0.0657 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 20669: loss = 0.1508 (0.318 sec/step)\n",
            "I0923 10:14:31.985502 139631849019264 learning.py:507] global step 20669: loss = 0.1508 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 20670: loss = 0.0692 (0.348 sec/step)\n",
            "I0923 10:14:32.335469 139631849019264 learning.py:507] global step 20670: loss = 0.0692 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 20671: loss = 0.1370 (0.325 sec/step)\n",
            "I0923 10:14:32.662306 139631849019264 learning.py:507] global step 20671: loss = 0.1370 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 20672: loss = 0.1011 (0.314 sec/step)\n",
            "I0923 10:14:32.977935 139631849019264 learning.py:507] global step 20672: loss = 0.1011 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 20673: loss = 0.0522 (0.310 sec/step)\n",
            "I0923 10:14:33.289717 139631849019264 learning.py:507] global step 20673: loss = 0.0522 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 20674: loss = 0.1726 (0.310 sec/step)\n",
            "I0923 10:14:33.600965 139631849019264 learning.py:507] global step 20674: loss = 0.1726 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 20675: loss = 0.0408 (0.303 sec/step)\n",
            "I0923 10:14:33.905456 139631849019264 learning.py:507] global step 20675: loss = 0.0408 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 20676: loss = 0.0998 (0.311 sec/step)\n",
            "I0923 10:14:34.218407 139631849019264 learning.py:507] global step 20676: loss = 0.0998 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 20677: loss = 0.1789 (0.305 sec/step)\n",
            "I0923 10:14:34.525276 139631849019264 learning.py:507] global step 20677: loss = 0.1789 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 20678: loss = 0.0229 (0.275 sec/step)\n",
            "I0923 10:14:34.801774 139631849019264 learning.py:507] global step 20678: loss = 0.0229 (0.275 sec/step)\n",
            "INFO:tensorflow:global step 20679: loss = 0.0254 (0.305 sec/step)\n",
            "I0923 10:14:35.108284 139631849019264 learning.py:507] global step 20679: loss = 0.0254 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 20680: loss = 0.0742 (0.300 sec/step)\n",
            "I0923 10:14:35.410301 139631849019264 learning.py:507] global step 20680: loss = 0.0742 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 20681: loss = 0.1960 (0.289 sec/step)\n",
            "I0923 10:14:35.701311 139631849019264 learning.py:507] global step 20681: loss = 0.1960 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 20682: loss = 0.0630 (0.313 sec/step)\n",
            "I0923 10:14:36.016209 139631849019264 learning.py:507] global step 20682: loss = 0.0630 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 20683: loss = 0.0849 (0.320 sec/step)\n",
            "I0923 10:14:36.338267 139631849019264 learning.py:507] global step 20683: loss = 0.0849 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 20684: loss = 0.0524 (0.284 sec/step)\n",
            "I0923 10:14:36.624854 139631849019264 learning.py:507] global step 20684: loss = 0.0524 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 20685: loss = 0.0602 (0.335 sec/step)\n",
            "I0923 10:14:36.961982 139631849019264 learning.py:507] global step 20685: loss = 0.0602 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 20686: loss = 0.0743 (0.284 sec/step)\n",
            "I0923 10:14:37.248452 139631849019264 learning.py:507] global step 20686: loss = 0.0743 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 20687: loss = 0.0409 (0.343 sec/step)\n",
            "I0923 10:14:37.593199 139631849019264 learning.py:507] global step 20687: loss = 0.0409 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 20688: loss = 0.1540 (0.336 sec/step)\n",
            "I0923 10:14:37.930830 139631849019264 learning.py:507] global step 20688: loss = 0.1540 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 20689: loss = 0.0731 (0.281 sec/step)\n",
            "I0923 10:14:38.214162 139631849019264 learning.py:507] global step 20689: loss = 0.0731 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 20690: loss = 0.1063 (0.296 sec/step)\n",
            "I0923 10:14:38.511985 139631849019264 learning.py:507] global step 20690: loss = 0.1063 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 20691: loss = 0.0695 (0.363 sec/step)\n",
            "I0923 10:14:38.876940 139631849019264 learning.py:507] global step 20691: loss = 0.0695 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 20692: loss = 0.0625 (0.292 sec/step)\n",
            "I0923 10:14:39.170109 139631849019264 learning.py:507] global step 20692: loss = 0.0625 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 20693: loss = 0.0413 (0.325 sec/step)\n",
            "I0923 10:14:39.496996 139631849019264 learning.py:507] global step 20693: loss = 0.0413 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 20694: loss = 0.1169 (0.330 sec/step)\n",
            "I0923 10:14:39.828693 139631849019264 learning.py:507] global step 20694: loss = 0.1169 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 20695: loss = 0.1090 (0.276 sec/step)\n",
            "I0923 10:14:40.106555 139631849019264 learning.py:507] global step 20695: loss = 0.1090 (0.276 sec/step)\n",
            "INFO:tensorflow:global step 20696: loss = 0.1134 (0.351 sec/step)\n",
            "I0923 10:14:40.459173 139631849019264 learning.py:507] global step 20696: loss = 0.1134 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 20697: loss = 0.0271 (0.331 sec/step)\n",
            "I0923 10:14:40.791708 139631849019264 learning.py:507] global step 20697: loss = 0.0271 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 20698: loss = 0.1059 (0.290 sec/step)\n",
            "I0923 10:14:41.083641 139631849019264 learning.py:507] global step 20698: loss = 0.1059 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 20699: loss = 0.0697 (0.337 sec/step)\n",
            "I0923 10:14:41.423541 139631849019264 learning.py:507] global step 20699: loss = 0.0697 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 20700: loss = 0.0443 (0.325 sec/step)\n",
            "I0923 10:14:41.751364 139631849019264 learning.py:507] global step 20700: loss = 0.0443 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 20701: loss = 0.0693 (0.311 sec/step)\n",
            "I0923 10:14:42.064398 139631849019264 learning.py:507] global step 20701: loss = 0.0693 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 20702: loss = 0.1352 (0.385 sec/step)\n",
            "I0923 10:14:42.451632 139631849019264 learning.py:507] global step 20702: loss = 0.1352 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 20703: loss = 0.0978 (0.321 sec/step)\n",
            "I0923 10:14:42.775735 139631849019264 learning.py:507] global step 20703: loss = 0.0978 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 20704: loss = 0.0768 (0.340 sec/step)\n",
            "I0923 10:14:43.117685 139631849019264 learning.py:507] global step 20704: loss = 0.0768 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 20705: loss = 0.0692 (0.305 sec/step)\n",
            "I0923 10:14:43.424984 139631849019264 learning.py:507] global step 20705: loss = 0.0692 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 20706: loss = 0.0942 (0.278 sec/step)\n",
            "I0923 10:14:43.704674 139631849019264 learning.py:507] global step 20706: loss = 0.0942 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 20707: loss = 0.2179 (0.321 sec/step)\n",
            "I0923 10:14:44.027500 139631849019264 learning.py:507] global step 20707: loss = 0.2179 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 20708: loss = 0.1477 (0.365 sec/step)\n",
            "I0923 10:14:44.394132 139631849019264 learning.py:507] global step 20708: loss = 0.1477 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 20709: loss = 0.1373 (0.330 sec/step)\n",
            "I0923 10:14:44.725793 139631849019264 learning.py:507] global step 20709: loss = 0.1373 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 20710: loss = 0.4157 (0.353 sec/step)\n",
            "I0923 10:14:45.081088 139631849019264 learning.py:507] global step 20710: loss = 0.4157 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 20711: loss = 0.0689 (0.332 sec/step)\n",
            "I0923 10:14:45.415101 139631849019264 learning.py:507] global step 20711: loss = 0.0689 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20712: loss = 0.0624 (0.289 sec/step)\n",
            "I0923 10:14:45.706159 139631849019264 learning.py:507] global step 20712: loss = 0.0624 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 20713: loss = 0.0564 (0.320 sec/step)\n",
            "I0923 10:14:46.028083 139631849019264 learning.py:507] global step 20713: loss = 0.0564 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 20714: loss = 0.1708 (0.326 sec/step)\n",
            "I0923 10:14:46.355312 139631849019264 learning.py:507] global step 20714: loss = 0.1708 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20715: loss = 0.0896 (0.293 sec/step)\n",
            "I0923 10:14:46.649996 139631849019264 learning.py:507] global step 20715: loss = 0.0896 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 20716: loss = 0.0729 (0.443 sec/step)\n",
            "I0923 10:14:47.095895 139631849019264 learning.py:507] global step 20716: loss = 0.0729 (0.443 sec/step)\n",
            "INFO:tensorflow:global step 20717: loss = 0.1600 (0.359 sec/step)\n",
            "I0923 10:14:47.457565 139631849019264 learning.py:507] global step 20717: loss = 0.1600 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 20718: loss = 0.0659 (0.328 sec/step)\n",
            "I0923 10:14:47.787447 139631849019264 learning.py:507] global step 20718: loss = 0.0659 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 20719: loss = 0.0919 (0.289 sec/step)\n",
            "I0923 10:14:48.078177 139631849019264 learning.py:507] global step 20719: loss = 0.0919 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 20720: loss = 0.0569 (0.352 sec/step)\n",
            "I0923 10:14:48.431809 139631849019264 learning.py:507] global step 20720: loss = 0.0569 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 20721: loss = 0.1023 (0.281 sec/step)\n",
            "I0923 10:14:48.714174 139631849019264 learning.py:507] global step 20721: loss = 0.1023 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 20722: loss = 0.0549 (0.307 sec/step)\n",
            "I0923 10:14:49.023224 139631849019264 learning.py:507] global step 20722: loss = 0.0549 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 20723: loss = 0.2410 (0.374 sec/step)\n",
            "I0923 10:14:49.398717 139631849019264 learning.py:507] global step 20723: loss = 0.2410 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 20724: loss = 0.1693 (0.319 sec/step)\n",
            "I0923 10:14:49.719476 139631849019264 learning.py:507] global step 20724: loss = 0.1693 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 20725: loss = 0.1206 (0.312 sec/step)\n",
            "I0923 10:14:50.033356 139631849019264 learning.py:507] global step 20725: loss = 0.1206 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 20726: loss = 0.1449 (0.326 sec/step)\n",
            "I0923 10:14:50.361758 139631849019264 learning.py:507] global step 20726: loss = 0.1449 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20727: loss = 0.1496 (0.318 sec/step)\n",
            "I0923 10:14:50.681475 139631849019264 learning.py:507] global step 20727: loss = 0.1496 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 20728: loss = 0.0829 (0.319 sec/step)\n",
            "I0923 10:14:51.001918 139631849019264 learning.py:507] global step 20728: loss = 0.0829 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 20729: loss = 0.0865 (0.300 sec/step)\n",
            "I0923 10:14:51.303604 139631849019264 learning.py:507] global step 20729: loss = 0.0865 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 20730: loss = 0.1853 (0.276 sec/step)\n",
            "I0923 10:14:51.581398 139631849019264 learning.py:507] global step 20730: loss = 0.1853 (0.276 sec/step)\n",
            "INFO:tensorflow:global step 20731: loss = 0.0963 (0.320 sec/step)\n",
            "I0923 10:14:51.903830 139631849019264 learning.py:507] global step 20731: loss = 0.0963 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 20732: loss = 0.0595 (0.349 sec/step)\n",
            "I0923 10:14:52.254768 139631849019264 learning.py:507] global step 20732: loss = 0.0595 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 20733: loss = 0.0459 (0.341 sec/step)\n",
            "I0923 10:14:52.597576 139631849019264 learning.py:507] global step 20733: loss = 0.0459 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 20734: loss = 0.1647 (0.332 sec/step)\n",
            "I0923 10:14:52.931614 139631849019264 learning.py:507] global step 20734: loss = 0.1647 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20735: loss = 0.0892 (0.344 sec/step)\n",
            "I0923 10:14:53.277922 139631849019264 learning.py:507] global step 20735: loss = 0.0892 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 20736: loss = 0.0529 (0.291 sec/step)\n",
            "I0923 10:14:53.571078 139631849019264 learning.py:507] global step 20736: loss = 0.0529 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 20737: loss = 0.0711 (0.282 sec/step)\n",
            "I0923 10:14:53.854323 139631849019264 learning.py:507] global step 20737: loss = 0.0711 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 20738: loss = 0.0532 (0.320 sec/step)\n",
            "I0923 10:14:54.176119 139631849019264 learning.py:507] global step 20738: loss = 0.0532 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 20739: loss = 0.0597 (0.301 sec/step)\n",
            "I0923 10:14:54.479246 139631849019264 learning.py:507] global step 20739: loss = 0.0597 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 20740: loss = 0.0593 (0.299 sec/step)\n",
            "I0923 10:14:54.779884 139631849019264 learning.py:507] global step 20740: loss = 0.0593 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 20741: loss = 0.0923 (0.286 sec/step)\n",
            "I0923 10:14:55.067023 139631849019264 learning.py:507] global step 20741: loss = 0.0923 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 20742: loss = 0.0842 (0.282 sec/step)\n",
            "I0923 10:14:55.351419 139631849019264 learning.py:507] global step 20742: loss = 0.0842 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 20743: loss = 0.0958 (0.333 sec/step)\n",
            "I0923 10:14:55.686517 139631849019264 learning.py:507] global step 20743: loss = 0.0958 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 20744: loss = 0.4132 (0.319 sec/step)\n",
            "I0923 10:14:56.007442 139631849019264 learning.py:507] global step 20744: loss = 0.4132 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 20745: loss = 0.0754 (0.402 sec/step)\n",
            "I0923 10:14:56.411346 139631849019264 learning.py:507] global step 20745: loss = 0.0754 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 20746: loss = 0.0480 (0.296 sec/step)\n",
            "I0923 10:14:56.709601 139631849019264 learning.py:507] global step 20746: loss = 0.0480 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 20747: loss = 0.0463 (0.304 sec/step)\n",
            "I0923 10:14:57.015395 139631849019264 learning.py:507] global step 20747: loss = 0.0463 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 20748: loss = 0.0727 (0.287 sec/step)\n",
            "I0923 10:14:57.304815 139631849019264 learning.py:507] global step 20748: loss = 0.0727 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 20749: loss = 0.1334 (0.318 sec/step)\n",
            "I0923 10:14:57.625457 139631849019264 learning.py:507] global step 20749: loss = 0.1334 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 20750: loss = 0.1322 (0.338 sec/step)\n",
            "I0923 10:14:57.965409 139631849019264 learning.py:507] global step 20750: loss = 0.1322 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 20751: loss = 0.1722 (0.373 sec/step)\n",
            "I0923 10:14:58.340823 139631849019264 learning.py:507] global step 20751: loss = 0.1722 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 20752: loss = 0.1622 (0.323 sec/step)\n",
            "I0923 10:14:58.666047 139631849019264 learning.py:507] global step 20752: loss = 0.1622 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 20753: loss = 0.1116 (0.278 sec/step)\n",
            "I0923 10:14:58.946120 139631849019264 learning.py:507] global step 20753: loss = 0.1116 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 20754: loss = 0.1368 (0.329 sec/step)\n",
            "I0923 10:14:59.277032 139631849019264 learning.py:507] global step 20754: loss = 0.1368 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 20755: loss = 0.0627 (0.329 sec/step)\n",
            "I0923 10:14:59.607559 139631849019264 learning.py:507] global step 20755: loss = 0.0627 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 20756: loss = 0.0988 (0.288 sec/step)\n",
            "I0923 10:14:59.898014 139631849019264 learning.py:507] global step 20756: loss = 0.0988 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 20757: loss = 0.1007 (0.382 sec/step)\n",
            "I0923 10:15:00.281755 139631849019264 learning.py:507] global step 20757: loss = 0.1007 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 20758: loss = 0.1075 (0.282 sec/step)\n",
            "I0923 10:15:00.566311 139631849019264 learning.py:507] global step 20758: loss = 0.1075 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 20759: loss = 0.0822 (0.286 sec/step)\n",
            "I0923 10:15:00.854223 139631849019264 learning.py:507] global step 20759: loss = 0.0822 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 20760: loss = 0.0416 (0.335 sec/step)\n",
            "I0923 10:15:01.191793 139631849019264 learning.py:507] global step 20760: loss = 0.0416 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 20761: loss = 0.0745 (0.289 sec/step)\n",
            "I0923 10:15:01.482831 139631849019264 learning.py:507] global step 20761: loss = 0.0745 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 20762: loss = 0.0525 (0.341 sec/step)\n",
            "I0923 10:15:01.825457 139631849019264 learning.py:507] global step 20762: loss = 0.0525 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 20763: loss = 0.0398 (0.295 sec/step)\n",
            "I0923 10:15:02.122378 139631849019264 learning.py:507] global step 20763: loss = 0.0398 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 20764: loss = 0.0653 (0.349 sec/step)\n",
            "I0923 10:15:02.473979 139631849019264 learning.py:507] global step 20764: loss = 0.0653 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 20765: loss = 0.2327 (0.281 sec/step)\n",
            "I0923 10:15:02.756574 139631849019264 learning.py:507] global step 20765: loss = 0.2327 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 20766: loss = 0.0489 (0.294 sec/step)\n",
            "I0923 10:15:03.052597 139631849019264 learning.py:507] global step 20766: loss = 0.0489 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 20767: loss = 0.1398 (0.343 sec/step)\n",
            "I0923 10:15:03.401834 139631849019264 learning.py:507] global step 20767: loss = 0.1398 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 20768: loss = 0.1052 (0.318 sec/step)\n",
            "I0923 10:15:03.722297 139631849019264 learning.py:507] global step 20768: loss = 0.1052 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 20769: loss = 0.0914 (0.326 sec/step)\n",
            "I0923 10:15:04.050762 139631849019264 learning.py:507] global step 20769: loss = 0.0914 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20770: loss = 0.0939 (0.324 sec/step)\n",
            "I0923 10:15:04.376769 139631849019264 learning.py:507] global step 20770: loss = 0.0939 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 20771: loss = 0.1029 (0.316 sec/step)\n",
            "I0923 10:15:04.695145 139631849019264 learning.py:507] global step 20771: loss = 0.1029 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 20772: loss = 0.2031 (0.314 sec/step)\n",
            "I0923 10:15:05.011242 139631849019264 learning.py:507] global step 20772: loss = 0.2031 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 20773: loss = 0.1040 (0.340 sec/step)\n",
            "I0923 10:15:05.353629 139631849019264 learning.py:507] global step 20773: loss = 0.1040 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 20774: loss = 0.1104 (0.302 sec/step)\n",
            "I0923 10:15:05.657277 139631849019264 learning.py:507] global step 20774: loss = 0.1104 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 20775: loss = 0.0586 (0.338 sec/step)\n",
            "I0923 10:15:05.997550 139631849019264 learning.py:507] global step 20775: loss = 0.0586 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 20776: loss = 0.1070 (0.390 sec/step)\n",
            "I0923 10:15:06.389153 139631849019264 learning.py:507] global step 20776: loss = 0.1070 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 20777: loss = 0.0662 (0.277 sec/step)\n",
            "I0923 10:15:06.668226 139631849019264 learning.py:507] global step 20777: loss = 0.0662 (0.277 sec/step)\n",
            "INFO:tensorflow:global step 20778: loss = 0.0557 (0.325 sec/step)\n",
            "I0923 10:15:06.994835 139631849019264 learning.py:507] global step 20778: loss = 0.0557 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 20779: loss = 0.0665 (0.286 sec/step)\n",
            "I0923 10:15:07.283024 139631849019264 learning.py:507] global step 20779: loss = 0.0665 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 20780: loss = 0.1025 (0.328 sec/step)\n",
            "I0923 10:15:07.613338 139631849019264 learning.py:507] global step 20780: loss = 0.1025 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 20781: loss = 0.1186 (0.307 sec/step)\n",
            "I0923 10:15:07.922693 139631849019264 learning.py:507] global step 20781: loss = 0.1186 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 20782: loss = 0.0866 (0.321 sec/step)\n",
            "I0923 10:15:08.246102 139631849019264 learning.py:507] global step 20782: loss = 0.0866 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 20783: loss = 0.1498 (0.356 sec/step)\n",
            "I0923 10:15:08.604223 139631849019264 learning.py:507] global step 20783: loss = 0.1498 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 20784: loss = 0.1198 (0.289 sec/step)\n",
            "I0923 10:15:08.895437 139631849019264 learning.py:507] global step 20784: loss = 0.1198 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 20785: loss = 0.0714 (0.300 sec/step)\n",
            "I0923 10:15:09.199583 139631849019264 learning.py:507] global step 20785: loss = 0.0714 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 20786: loss = 0.0738 (0.308 sec/step)\n",
            "I0923 10:15:09.509911 139631849019264 learning.py:507] global step 20786: loss = 0.0738 (0.308 sec/step)\n",
            "INFO:tensorflow:global step 20787: loss = 0.0477 (0.310 sec/step)\n",
            "I0923 10:15:09.821990 139631849019264 learning.py:507] global step 20787: loss = 0.0477 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 20788: loss = 0.0644 (0.320 sec/step)\n",
            "I0923 10:15:10.143553 139631849019264 learning.py:507] global step 20788: loss = 0.0644 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 20789: loss = 0.0558 (0.295 sec/step)\n",
            "I0923 10:15:10.440635 139631849019264 learning.py:507] global step 20789: loss = 0.0558 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 20790: loss = 0.0627 (0.294 sec/step)\n",
            "I0923 10:15:10.736780 139631849019264 learning.py:507] global step 20790: loss = 0.0627 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 20791: loss = 0.0882 (0.320 sec/step)\n",
            "I0923 10:15:11.058253 139631849019264 learning.py:507] global step 20791: loss = 0.0882 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 20792: loss = 0.1582 (0.317 sec/step)\n",
            "I0923 10:15:11.379097 139631849019264 learning.py:507] global step 20792: loss = 0.1582 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 20793: loss = 0.0911 (0.322 sec/step)\n",
            "I0923 10:15:11.708102 139631849019264 learning.py:507] global step 20793: loss = 0.0911 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 20794: loss = 0.0497 (0.332 sec/step)\n",
            "I0923 10:15:12.041744 139631849019264 learning.py:507] global step 20794: loss = 0.0497 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20795: loss = 0.1013 (0.352 sec/step)\n",
            "I0923 10:15:12.395963 139631849019264 learning.py:507] global step 20795: loss = 0.1013 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 20796: loss = 0.0829 (0.342 sec/step)\n",
            "I0923 10:15:12.739990 139631849019264 learning.py:507] global step 20796: loss = 0.0829 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 20797: loss = 0.0998 (0.323 sec/step)\n",
            "I0923 10:15:13.065033 139631849019264 learning.py:507] global step 20797: loss = 0.0998 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 20798: loss = 0.1020 (0.303 sec/step)\n",
            "I0923 10:15:13.369969 139631849019264 learning.py:507] global step 20798: loss = 0.1020 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 20799: loss = 0.0321 (0.347 sec/step)\n",
            "I0923 10:15:13.718491 139631849019264 learning.py:507] global step 20799: loss = 0.0321 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 20800: loss = 0.2103 (0.276 sec/step)\n",
            "I0923 10:15:13.996471 139631849019264 learning.py:507] global step 20800: loss = 0.2103 (0.276 sec/step)\n",
            "INFO:tensorflow:global step 20801: loss = 0.0564 (0.332 sec/step)\n",
            "I0923 10:15:14.330033 139631849019264 learning.py:507] global step 20801: loss = 0.0564 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20802: loss = 0.1140 (0.335 sec/step)\n",
            "I0923 10:15:14.666849 139631849019264 learning.py:507] global step 20802: loss = 0.1140 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 20803: loss = 0.0744 (0.324 sec/step)\n",
            "I0923 10:15:14.993112 139631849019264 learning.py:507] global step 20803: loss = 0.0744 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 20804: loss = 0.0575 (0.315 sec/step)\n",
            "I0923 10:15:15.310145 139631849019264 learning.py:507] global step 20804: loss = 0.0575 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 20805: loss = 0.1372 (0.360 sec/step)\n",
            "I0923 10:15:15.672145 139631849019264 learning.py:507] global step 20805: loss = 0.1372 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 20806: loss = 0.1099 (0.283 sec/step)\n",
            "I0923 10:15:15.957371 139631849019264 learning.py:507] global step 20806: loss = 0.1099 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 20807: loss = 0.2515 (0.321 sec/step)\n",
            "I0923 10:15:16.280022 139631849019264 learning.py:507] global step 20807: loss = 0.2515 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 20808: loss = 0.0580 (0.281 sec/step)\n",
            "I0923 10:15:16.564582 139631849019264 learning.py:507] global step 20808: loss = 0.0580 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 20809: loss = 0.0698 (0.341 sec/step)\n",
            "I0923 10:15:16.910085 139631849019264 learning.py:507] global step 20809: loss = 0.0698 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 20810: loss = 0.0799 (0.294 sec/step)\n",
            "I0923 10:15:17.206415 139631849019264 learning.py:507] global step 20810: loss = 0.0799 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 20811: loss = 0.2577 (0.362 sec/step)\n",
            "I0923 10:15:17.569876 139631849019264 learning.py:507] global step 20811: loss = 0.2577 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 20812: loss = 0.2218 (0.329 sec/step)\n",
            "I0923 10:15:17.900649 139631849019264 learning.py:507] global step 20812: loss = 0.2218 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 20813: loss = 0.1706 (0.335 sec/step)\n",
            "I0923 10:15:18.237335 139631849019264 learning.py:507] global step 20813: loss = 0.1706 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 20814: loss = 0.0473 (0.285 sec/step)\n",
            "I0923 10:15:18.524593 139631849019264 learning.py:507] global step 20814: loss = 0.0473 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 20815: loss = 0.0895 (0.336 sec/step)\n",
            "I0923 10:15:18.862677 139631849019264 learning.py:507] global step 20815: loss = 0.0895 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 20816: loss = 0.0702 (0.309 sec/step)\n",
            "I0923 10:15:19.173914 139631849019264 learning.py:507] global step 20816: loss = 0.0702 (0.309 sec/step)\n",
            "INFO:tensorflow:global step 20817: loss = 0.0558 (0.290 sec/step)\n",
            "I0923 10:15:19.465743 139631849019264 learning.py:507] global step 20817: loss = 0.0558 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 20818: loss = 0.1588 (0.295 sec/step)\n",
            "I0923 10:15:19.762135 139631849019264 learning.py:507] global step 20818: loss = 0.1588 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 20819: loss = 0.0750 (0.339 sec/step)\n",
            "I0923 10:15:20.103340 139631849019264 learning.py:507] global step 20819: loss = 0.0750 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 20820: loss = 0.0732 (0.295 sec/step)\n",
            "I0923 10:15:20.400459 139631849019264 learning.py:507] global step 20820: loss = 0.0732 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 20821: loss = 0.0665 (0.334 sec/step)\n",
            "I0923 10:15:20.738693 139631849019264 learning.py:507] global step 20821: loss = 0.0665 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 20822: loss = 0.0692 (0.287 sec/step)\n",
            "I0923 10:15:21.027933 139631849019264 learning.py:507] global step 20822: loss = 0.0692 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 20823: loss = 0.2110 (0.307 sec/step)\n",
            "I0923 10:15:21.336334 139631849019264 learning.py:507] global step 20823: loss = 0.2110 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 20824: loss = 0.2918 (0.306 sec/step)\n",
            "I0923 10:15:21.644236 139631849019264 learning.py:507] global step 20824: loss = 0.2918 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 20825: loss = 0.0612 (0.339 sec/step)\n",
            "I0923 10:15:21.985191 139631849019264 learning.py:507] global step 20825: loss = 0.0612 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 20826: loss = 0.0936 (0.323 sec/step)\n",
            "I0923 10:15:22.309754 139631849019264 learning.py:507] global step 20826: loss = 0.0936 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 20827: loss = 0.1482 (0.320 sec/step)\n",
            "I0923 10:15:22.631961 139631849019264 learning.py:507] global step 20827: loss = 0.1482 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 20828: loss = 0.1154 (0.288 sec/step)\n",
            "I0923 10:15:22.921975 139631849019264 learning.py:507] global step 20828: loss = 0.1154 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 20829: loss = 0.0819 (0.279 sec/step)\n",
            "I0923 10:15:23.202591 139631849019264 learning.py:507] global step 20829: loss = 0.0819 (0.279 sec/step)\n",
            "INFO:tensorflow:global step 20830: loss = 0.1073 (0.335 sec/step)\n",
            "I0923 10:15:23.539358 139631849019264 learning.py:507] global step 20830: loss = 0.1073 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 20831: loss = 0.0352 (0.334 sec/step)\n",
            "I0923 10:15:23.875360 139631849019264 learning.py:507] global step 20831: loss = 0.0352 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 20832: loss = 0.1806 (0.302 sec/step)\n",
            "I0923 10:15:24.179841 139631849019264 learning.py:507] global step 20832: loss = 0.1806 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 20833: loss = 0.0436 (0.298 sec/step)\n",
            "I0923 10:15:24.479794 139631849019264 learning.py:507] global step 20833: loss = 0.0436 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 20834: loss = 0.0882 (0.297 sec/step)\n",
            "I0923 10:15:24.778822 139631849019264 learning.py:507] global step 20834: loss = 0.0882 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 20835: loss = 0.1711 (0.326 sec/step)\n",
            "I0923 10:15:25.106525 139631849019264 learning.py:507] global step 20835: loss = 0.1711 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20836: loss = 0.0582 (0.314 sec/step)\n",
            "I0923 10:15:25.421715 139631849019264 learning.py:507] global step 20836: loss = 0.0582 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 20837: loss = 0.0410 (0.330 sec/step)\n",
            "I0923 10:15:25.753517 139631849019264 learning.py:507] global step 20837: loss = 0.0410 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 20838: loss = 0.0865 (0.324 sec/step)\n",
            "I0923 10:15:26.079151 139631849019264 learning.py:507] global step 20838: loss = 0.0865 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 20839: loss = 0.1148 (0.279 sec/step)\n",
            "I0923 10:15:26.360709 139631849019264 learning.py:507] global step 20839: loss = 0.1148 (0.279 sec/step)\n",
            "INFO:tensorflow:global step 20840: loss = 0.2596 (0.284 sec/step)\n",
            "I0923 10:15:26.647040 139631849019264 learning.py:507] global step 20840: loss = 0.2596 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 20841: loss = 0.1771 (0.369 sec/step)\n",
            "I0923 10:15:27.018279 139631849019264 learning.py:507] global step 20841: loss = 0.1771 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 20842: loss = 0.0626 (0.330 sec/step)\n",
            "I0923 10:15:27.350674 139631849019264 learning.py:507] global step 20842: loss = 0.0626 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 20843: loss = 0.0324 (0.293 sec/step)\n",
            "I0923 10:15:27.645191 139631849019264 learning.py:507] global step 20843: loss = 0.0324 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 20844: loss = 0.0472 (0.356 sec/step)\n",
            "I0923 10:15:28.002897 139631849019264 learning.py:507] global step 20844: loss = 0.0472 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 20845: loss = 0.0757 (0.284 sec/step)\n",
            "I0923 10:15:28.288847 139631849019264 learning.py:507] global step 20845: loss = 0.0757 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 20846: loss = 0.0583 (0.280 sec/step)\n",
            "I0923 10:15:28.570760 139631849019264 learning.py:507] global step 20846: loss = 0.0583 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 20847: loss = 0.0989 (0.277 sec/step)\n",
            "I0923 10:15:28.849193 139631849019264 learning.py:507] global step 20847: loss = 0.0989 (0.277 sec/step)\n",
            "INFO:tensorflow:global step 20848: loss = 0.0472 (0.319 sec/step)\n",
            "I0923 10:15:29.169806 139631849019264 learning.py:507] global step 20848: loss = 0.0472 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 20849: loss = 0.0706 (0.364 sec/step)\n",
            "I0923 10:15:29.535753 139631849019264 learning.py:507] global step 20849: loss = 0.0706 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 20850: loss = 0.0913 (0.316 sec/step)\n",
            "I0923 10:15:29.853759 139631849019264 learning.py:507] global step 20850: loss = 0.0913 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 20851: loss = 0.1286 (0.330 sec/step)\n",
            "I0923 10:15:30.185527 139631849019264 learning.py:507] global step 20851: loss = 0.1286 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 20852: loss = 0.0677 (0.338 sec/step)\n",
            "I0923 10:15:30.525472 139631849019264 learning.py:507] global step 20852: loss = 0.0677 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 20853: loss = 0.0999 (0.274 sec/step)\n",
            "I0923 10:15:30.801472 139631849019264 learning.py:507] global step 20853: loss = 0.0999 (0.274 sec/step)\n",
            "INFO:tensorflow:global step 20854: loss = 0.0331 (0.299 sec/step)\n",
            "I0923 10:15:31.102144 139631849019264 learning.py:507] global step 20854: loss = 0.0331 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 20855: loss = 0.1078 (0.343 sec/step)\n",
            "I0923 10:15:31.446853 139631849019264 learning.py:507] global step 20855: loss = 0.1078 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 20856: loss = 0.0683 (0.281 sec/step)\n",
            "I0923 10:15:31.729434 139631849019264 learning.py:507] global step 20856: loss = 0.0683 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 20857: loss = 0.1676 (0.351 sec/step)\n",
            "I0923 10:15:32.082628 139631849019264 learning.py:507] global step 20857: loss = 0.1676 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 20858: loss = 0.0540 (0.302 sec/step)\n",
            "I0923 10:15:32.386367 139631849019264 learning.py:507] global step 20858: loss = 0.0540 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 20859: loss = 0.0846 (0.285 sec/step)\n",
            "I0923 10:15:32.673090 139631849019264 learning.py:507] global step 20859: loss = 0.0846 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 20860: loss = 0.0633 (0.317 sec/step)\n",
            "I0923 10:15:32.992873 139631849019264 learning.py:507] global step 20860: loss = 0.0633 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 20861: loss = 0.0483 (0.311 sec/step)\n",
            "I0923 10:15:33.305562 139631849019264 learning.py:507] global step 20861: loss = 0.0483 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 20862: loss = 0.0746 (0.334 sec/step)\n",
            "I0923 10:15:33.640997 139631849019264 learning.py:507] global step 20862: loss = 0.0746 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 20863: loss = 0.0676 (0.283 sec/step)\n",
            "I0923 10:15:33.925656 139631849019264 learning.py:507] global step 20863: loss = 0.0676 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 20864: loss = 0.0473 (0.296 sec/step)\n",
            "I0923 10:15:34.223274 139631849019264 learning.py:507] global step 20864: loss = 0.0473 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 20865: loss = 0.0972 (0.314 sec/step)\n",
            "I0923 10:15:34.539158 139631849019264 learning.py:507] global step 20865: loss = 0.0972 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 20866: loss = 0.0728 (0.297 sec/step)\n",
            "I0923 10:15:34.838151 139631849019264 learning.py:507] global step 20866: loss = 0.0728 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 20867: loss = 0.0956 (0.312 sec/step)\n",
            "I0923 10:15:35.152621 139631849019264 learning.py:507] global step 20867: loss = 0.0956 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 20868: loss = 0.0913 (0.325 sec/step)\n",
            "I0923 10:15:35.479607 139631849019264 learning.py:507] global step 20868: loss = 0.0913 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 20869: loss = 0.1403 (0.279 sec/step)\n",
            "I0923 10:15:35.760682 139631849019264 learning.py:507] global step 20869: loss = 0.1403 (0.279 sec/step)\n",
            "INFO:tensorflow:global step 20870: loss = 0.1313 (0.308 sec/step)\n",
            "I0923 10:15:36.070502 139631849019264 learning.py:507] global step 20870: loss = 0.1313 (0.308 sec/step)\n",
            "INFO:tensorflow:global step 20871: loss = 0.0825 (0.332 sec/step)\n",
            "I0923 10:15:36.406898 139631849019264 learning.py:507] global step 20871: loss = 0.0825 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20872: loss = 0.0802 (0.346 sec/step)\n",
            "I0923 10:15:36.754830 139631849019264 learning.py:507] global step 20872: loss = 0.0802 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 20873: loss = 0.0784 (0.334 sec/step)\n",
            "I0923 10:15:37.091486 139631849019264 learning.py:507] global step 20873: loss = 0.0784 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 20874: loss = 0.0856 (0.321 sec/step)\n",
            "I0923 10:15:37.414877 139631849019264 learning.py:507] global step 20874: loss = 0.0856 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 20875: loss = 0.1264 (0.322 sec/step)\n",
            "I0923 10:15:37.738330 139631849019264 learning.py:507] global step 20875: loss = 0.1264 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 20876: loss = 0.0633 (0.324 sec/step)\n",
            "I0923 10:15:38.064495 139631849019264 learning.py:507] global step 20876: loss = 0.0633 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 20877: loss = 0.2432 (0.292 sec/step)\n",
            "I0923 10:15:38.358884 139631849019264 learning.py:507] global step 20877: loss = 0.2432 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 20878: loss = 0.0382 (0.284 sec/step)\n",
            "I0923 10:15:38.645262 139631849019264 learning.py:507] global step 20878: loss = 0.0382 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 20879: loss = 0.0686 (0.291 sec/step)\n",
            "I0923 10:15:38.937898 139631849019264 learning.py:507] global step 20879: loss = 0.0686 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 20880: loss = 0.2620 (0.374 sec/step)\n",
            "I0923 10:15:39.313678 139631849019264 learning.py:507] global step 20880: loss = 0.2620 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 20881: loss = 0.1336 (0.302 sec/step)\n",
            "I0923 10:15:39.617492 139631849019264 learning.py:507] global step 20881: loss = 0.1336 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 20882: loss = 0.0724 (0.344 sec/step)\n",
            "I0923 10:15:39.963270 139631849019264 learning.py:507] global step 20882: loss = 0.0724 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 20883: loss = 0.2340 (0.485 sec/step)\n",
            "I0923 10:15:40.451340 139631849019264 learning.py:507] global step 20883: loss = 0.2340 (0.485 sec/step)\n",
            "INFO:tensorflow:global step 20884: loss = 0.1240 (0.617 sec/step)\n",
            "I0923 10:15:41.076611 139631849019264 learning.py:507] global step 20884: loss = 0.1240 (0.617 sec/step)\n",
            "INFO:tensorflow:global step 20885: loss = 0.0929 (0.438 sec/step)\n",
            "I0923 10:15:41.520670 139631849019264 learning.py:507] global step 20885: loss = 0.0929 (0.438 sec/step)\n",
            "INFO:tensorflow:global step 20886: loss = 0.1555 (0.623 sec/step)\n",
            "I0923 10:15:42.147247 139631849019264 learning.py:507] global step 20886: loss = 0.1555 (0.623 sec/step)\n",
            "INFO:tensorflow:global step 20887: loss = 0.4138 (0.470 sec/step)\n",
            "I0923 10:15:42.620872 139631849019264 learning.py:507] global step 20887: loss = 0.4138 (0.470 sec/step)\n",
            "INFO:tensorflow:global step 20888: loss = 0.1005 (0.626 sec/step)\n",
            "I0923 10:15:43.253307 139631849019264 learning.py:507] global step 20888: loss = 0.1005 (0.626 sec/step)\n",
            "INFO:tensorflow:global step 20889: loss = 0.0824 (0.602 sec/step)\n",
            "I0923 10:15:43.860722 139631849019264 learning.py:507] global step 20889: loss = 0.0824 (0.602 sec/step)\n",
            "INFO:tensorflow:global step 20890: loss = 0.1389 (0.547 sec/step)\n",
            "I0923 10:15:44.411640 139631849019264 learning.py:507] global step 20890: loss = 0.1389 (0.547 sec/step)\n",
            "INFO:tensorflow:global step 20891: loss = 0.0519 (0.657 sec/step)\n",
            "I0923 10:15:45.071720 139631849019264 learning.py:507] global step 20891: loss = 0.0519 (0.657 sec/step)\n",
            "INFO:tensorflow:global step 20892: loss = 0.2220 (0.558 sec/step)\n",
            "I0923 10:15:45.638782 139631849019264 learning.py:507] global step 20892: loss = 0.2220 (0.558 sec/step)\n",
            "INFO:tensorflow:global step 20893: loss = 0.0806 (0.516 sec/step)\n",
            "I0923 10:15:46.157435 139631849019264 learning.py:507] global step 20893: loss = 0.0806 (0.516 sec/step)\n",
            "INFO:tensorflow:global step 20894: loss = 0.0336 (0.621 sec/step)\n",
            "I0923 10:15:46.780814 139631849019264 learning.py:507] global step 20894: loss = 0.0336 (0.621 sec/step)\n",
            "INFO:tensorflow:global step 20895: loss = 0.0541 (0.502 sec/step)\n",
            "I0923 10:15:47.286370 139631849019264 learning.py:507] global step 20895: loss = 0.0541 (0.502 sec/step)\n",
            "INFO:tensorflow:global step 20896: loss = 0.0911 (0.588 sec/step)\n",
            "I0923 10:15:47.878586 139631849019264 learning.py:507] global step 20896: loss = 0.0911 (0.588 sec/step)\n",
            "INFO:tensorflow:global step 20897: loss = 0.1065 (0.449 sec/step)\n",
            "I0923 10:15:48.330554 139631849019264 learning.py:507] global step 20897: loss = 0.1065 (0.449 sec/step)\n",
            "INFO:tensorflow:global step 20898: loss = 0.0722 (0.482 sec/step)\n",
            "I0923 10:15:48.815351 139631849019264 learning.py:507] global step 20898: loss = 0.0722 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 20899: loss = 0.0829 (0.546 sec/step)\n",
            "I0923 10:15:49.363439 139631849019264 learning.py:507] global step 20899: loss = 0.0829 (0.546 sec/step)\n",
            "INFO:tensorflow:global step 20900: loss = 0.0620 (0.382 sec/step)\n",
            "I0923 10:15:49.747133 139631849019264 learning.py:507] global step 20900: loss = 0.0620 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 20901: loss = 0.0540 (0.337 sec/step)\n",
            "I0923 10:15:50.086413 139631849019264 learning.py:507] global step 20901: loss = 0.0540 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 20902: loss = 0.1281 (0.283 sec/step)\n",
            "I0923 10:15:50.370871 139631849019264 learning.py:507] global step 20902: loss = 0.1281 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 20903: loss = 0.0306 (0.316 sec/step)\n",
            "I0923 10:15:50.689181 139631849019264 learning.py:507] global step 20903: loss = 0.0306 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 20904: loss = 0.2163 (0.332 sec/step)\n",
            "I0923 10:15:51.022924 139631849019264 learning.py:507] global step 20904: loss = 0.2163 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20905: loss = 0.1054 (0.330 sec/step)\n",
            "I0923 10:15:51.355502 139631849019264 learning.py:507] global step 20905: loss = 0.1054 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 20906: loss = 0.2443 (0.291 sec/step)\n",
            "I0923 10:15:51.648045 139631849019264 learning.py:507] global step 20906: loss = 0.2443 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 20907: loss = 0.0789 (0.304 sec/step)\n",
            "I0923 10:15:51.954476 139631849019264 learning.py:507] global step 20907: loss = 0.0789 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 20908: loss = 0.0934 (0.321 sec/step)\n",
            "I0923 10:15:52.277932 139631849019264 learning.py:507] global step 20908: loss = 0.0934 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 20909: loss = 0.0902 (0.336 sec/step)\n",
            "I0923 10:15:52.616163 139631849019264 learning.py:507] global step 20909: loss = 0.0902 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 20910: loss = 0.0607 (0.279 sec/step)\n",
            "I0923 10:15:52.897244 139631849019264 learning.py:507] global step 20910: loss = 0.0607 (0.279 sec/step)\n",
            "INFO:tensorflow:global step 20911: loss = 0.1023 (0.289 sec/step)\n",
            "I0923 10:15:53.189096 139631849019264 learning.py:507] global step 20911: loss = 0.1023 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 20912: loss = 0.1364 (0.314 sec/step)\n",
            "I0923 10:15:53.505354 139631849019264 learning.py:507] global step 20912: loss = 0.1364 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 20913: loss = 0.0982 (0.338 sec/step)\n",
            "I0923 10:15:53.845817 139631849019264 learning.py:507] global step 20913: loss = 0.0982 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 20914: loss = 0.1038 (0.298 sec/step)\n",
            "I0923 10:15:54.145975 139631849019264 learning.py:507] global step 20914: loss = 0.1038 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 20915: loss = 0.0259 (0.356 sec/step)\n",
            "I0923 10:15:54.504164 139631849019264 learning.py:507] global step 20915: loss = 0.0259 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 20916: loss = 0.1075 (0.299 sec/step)\n",
            "I0923 10:15:54.805313 139631849019264 learning.py:507] global step 20916: loss = 0.1075 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 20917: loss = 0.1383 (0.335 sec/step)\n",
            "I0923 10:15:55.142160 139631849019264 learning.py:507] global step 20917: loss = 0.1383 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 20918: loss = 0.0303 (0.320 sec/step)\n",
            "I0923 10:15:55.464104 139631849019264 learning.py:507] global step 20918: loss = 0.0303 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 20919: loss = 0.0733 (0.292 sec/step)\n",
            "I0923 10:15:55.757985 139631849019264 learning.py:507] global step 20919: loss = 0.0733 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 20920: loss = 0.0384 (0.306 sec/step)\n",
            "I0923 10:15:56.066010 139631849019264 learning.py:507] global step 20920: loss = 0.0384 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 20921: loss = 0.3101 (0.364 sec/step)\n",
            "I0923 10:15:56.431470 139631849019264 learning.py:507] global step 20921: loss = 0.3101 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 20922: loss = 0.1780 (0.326 sec/step)\n",
            "I0923 10:15:56.759689 139631849019264 learning.py:507] global step 20922: loss = 0.1780 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20923: loss = 0.0535 (0.338 sec/step)\n",
            "I0923 10:15:57.100567 139631849019264 learning.py:507] global step 20923: loss = 0.0535 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 20924: loss = 0.0679 (0.363 sec/step)\n",
            "I0923 10:15:57.465552 139631849019264 learning.py:507] global step 20924: loss = 0.0679 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 20925: loss = 0.0479 (0.330 sec/step)\n",
            "I0923 10:15:57.797274 139631849019264 learning.py:507] global step 20925: loss = 0.0479 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 20926: loss = 0.0681 (0.338 sec/step)\n",
            "I0923 10:15:58.137494 139631849019264 learning.py:507] global step 20926: loss = 0.0681 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 20927: loss = 0.0575 (0.301 sec/step)\n",
            "I0923 10:15:58.440899 139631849019264 learning.py:507] global step 20927: loss = 0.0575 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 20928: loss = 0.0715 (0.350 sec/step)\n",
            "I0923 10:15:58.793667 139631849019264 learning.py:507] global step 20928: loss = 0.0715 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 20929: loss = 0.0938 (0.307 sec/step)\n",
            "I0923 10:15:59.102813 139631849019264 learning.py:507] global step 20929: loss = 0.0938 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 20930: loss = 0.3120 (0.297 sec/step)\n",
            "I0923 10:15:59.402549 139631849019264 learning.py:507] global step 20930: loss = 0.3120 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 20931: loss = 0.0916 (0.318 sec/step)\n",
            "I0923 10:15:59.722932 139631849019264 learning.py:507] global step 20931: loss = 0.0916 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 20932: loss = 0.1209 (0.307 sec/step)\n",
            "I0923 10:16:00.032113 139631849019264 learning.py:507] global step 20932: loss = 0.1209 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 20933: loss = 0.1448 (0.340 sec/step)\n",
            "I0923 10:16:00.374749 139631849019264 learning.py:507] global step 20933: loss = 0.1448 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 20934: loss = 0.1703 (0.330 sec/step)\n",
            "I0923 10:16:00.706294 139631849019264 learning.py:507] global step 20934: loss = 0.1703 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 20935: loss = 0.1220 (0.324 sec/step)\n",
            "I0923 10:16:01.032003 139631849019264 learning.py:507] global step 20935: loss = 0.1220 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 20936: loss = 0.2066 (0.409 sec/step)\n",
            "I0923 10:16:01.443017 139631849019264 learning.py:507] global step 20936: loss = 0.2066 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 20937: loss = 0.0444 (0.285 sec/step)\n",
            "I0923 10:16:01.729775 139631849019264 learning.py:507] global step 20937: loss = 0.0444 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 20938: loss = 0.1691 (0.309 sec/step)\n",
            "I0923 10:16:02.040417 139631849019264 learning.py:507] global step 20938: loss = 0.1691 (0.309 sec/step)\n",
            "INFO:tensorflow:global step 20939: loss = 0.0517 (0.304 sec/step)\n",
            "I0923 10:16:02.346483 139631849019264 learning.py:507] global step 20939: loss = 0.0517 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 20940: loss = 0.2021 (0.380 sec/step)\n",
            "I0923 10:16:02.728539 139631849019264 learning.py:507] global step 20940: loss = 0.2021 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 20941: loss = 0.2793 (0.293 sec/step)\n",
            "I0923 10:16:03.023119 139631849019264 learning.py:507] global step 20941: loss = 0.2793 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 20942: loss = 0.0972 (0.334 sec/step)\n",
            "I0923 10:16:03.359551 139631849019264 learning.py:507] global step 20942: loss = 0.0972 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 20943: loss = 0.0385 (0.284 sec/step)\n",
            "I0923 10:16:03.645455 139631849019264 learning.py:507] global step 20943: loss = 0.0385 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 20944: loss = 0.1589 (0.285 sec/step)\n",
            "I0923 10:16:03.932348 139631849019264 learning.py:507] global step 20944: loss = 0.1589 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 20945: loss = 0.0637 (0.334 sec/step)\n",
            "I0923 10:16:04.268552 139631849019264 learning.py:507] global step 20945: loss = 0.0637 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 20946: loss = 0.1246 (0.343 sec/step)\n",
            "I0923 10:16:04.613558 139631849019264 learning.py:507] global step 20946: loss = 0.1246 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 20947: loss = 0.0677 (0.348 sec/step)\n",
            "I0923 10:16:04.964150 139631849019264 learning.py:507] global step 20947: loss = 0.0677 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 20948: loss = 0.0417 (0.285 sec/step)\n",
            "I0923 10:16:05.250910 139631849019264 learning.py:507] global step 20948: loss = 0.0417 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 20949: loss = 0.0411 (0.351 sec/step)\n",
            "I0923 10:16:05.603540 139631849019264 learning.py:507] global step 20949: loss = 0.0411 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 20950: loss = 0.2908 (0.332 sec/step)\n",
            "I0923 10:16:05.937999 139631849019264 learning.py:507] global step 20950: loss = 0.2908 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20951: loss = 0.0300 (0.301 sec/step)\n",
            "I0923 10:16:06.241168 139631849019264 learning.py:507] global step 20951: loss = 0.0300 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 20952: loss = 0.0684 (0.323 sec/step)\n",
            "I0923 10:16:06.566166 139631849019264 learning.py:507] global step 20952: loss = 0.0684 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 20953: loss = 0.0343 (0.340 sec/step)\n",
            "I0923 10:16:06.908269 139631849019264 learning.py:507] global step 20953: loss = 0.0343 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 20954: loss = 0.4983 (0.316 sec/step)\n",
            "I0923 10:16:07.226147 139631849019264 learning.py:507] global step 20954: loss = 0.4983 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 20955: loss = 0.0882 (0.302 sec/step)\n",
            "I0923 10:16:07.529764 139631849019264 learning.py:507] global step 20955: loss = 0.0882 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 20956: loss = 0.2259 (0.336 sec/step)\n",
            "I0923 10:16:07.868380 139631849019264 learning.py:507] global step 20956: loss = 0.2259 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 20957: loss = 0.0447 (0.288 sec/step)\n",
            "I0923 10:16:08.158898 139631849019264 learning.py:507] global step 20957: loss = 0.0447 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 20958: loss = 0.2163 (0.313 sec/step)\n",
            "I0923 10:16:08.473272 139631849019264 learning.py:507] global step 20958: loss = 0.2163 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 20959: loss = 0.2652 (0.299 sec/step)\n",
            "I0923 10:16:08.773742 139631849019264 learning.py:507] global step 20959: loss = 0.2652 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 20960: loss = 0.0708 (0.337 sec/step)\n",
            "I0923 10:16:09.112094 139631849019264 learning.py:507] global step 20960: loss = 0.0708 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 20961: loss = 0.0747 (0.303 sec/step)\n",
            "I0923 10:16:09.418768 139631849019264 learning.py:507] global step 20961: loss = 0.0747 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 20962: loss = 0.1175 (0.326 sec/step)\n",
            "I0923 10:16:09.747018 139631849019264 learning.py:507] global step 20962: loss = 0.1175 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 20963: loss = 0.1460 (0.282 sec/step)\n",
            "I0923 10:16:10.030976 139631849019264 learning.py:507] global step 20963: loss = 0.1460 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 20964: loss = 0.0797 (0.284 sec/step)\n",
            "I0923 10:16:10.316718 139631849019264 learning.py:507] global step 20964: loss = 0.0797 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 20965: loss = 0.0599 (0.294 sec/step)\n",
            "I0923 10:16:10.612752 139631849019264 learning.py:507] global step 20965: loss = 0.0599 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 20966: loss = 0.4239 (0.319 sec/step)\n",
            "I0923 10:16:10.933537 139631849019264 learning.py:507] global step 20966: loss = 0.4239 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 20967: loss = 0.0695 (0.315 sec/step)\n",
            "I0923 10:16:11.250209 139631849019264 learning.py:507] global step 20967: loss = 0.0695 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 20968: loss = 0.1000 (0.319 sec/step)\n",
            "I0923 10:16:11.570897 139631849019264 learning.py:507] global step 20968: loss = 0.1000 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 20969: loss = 0.0982 (0.290 sec/step)\n",
            "I0923 10:16:11.862730 139631849019264 learning.py:507] global step 20969: loss = 0.0982 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 20970: loss = 0.2415 (0.294 sec/step)\n",
            "I0923 10:16:12.158477 139631849019264 learning.py:507] global step 20970: loss = 0.2415 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 20971: loss = 0.0789 (0.364 sec/step)\n",
            "I0923 10:16:12.523845 139631849019264 learning.py:507] global step 20971: loss = 0.0789 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 20972: loss = 0.1027 (0.302 sec/step)\n",
            "I0923 10:16:12.827563 139631849019264 learning.py:507] global step 20972: loss = 0.1027 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 20973: loss = 0.1256 (0.318 sec/step)\n",
            "I0923 10:16:13.147461 139631849019264 learning.py:507] global step 20973: loss = 0.1256 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 20974: loss = 0.0836 (0.300 sec/step)\n",
            "I0923 10:16:13.449930 139631849019264 learning.py:507] global step 20974: loss = 0.0836 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 20975: loss = 0.1098 (0.311 sec/step)\n",
            "I0923 10:16:13.763138 139631849019264 learning.py:507] global step 20975: loss = 0.1098 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 20976: loss = 0.2020 (0.314 sec/step)\n",
            "I0923 10:16:14.078825 139631849019264 learning.py:507] global step 20976: loss = 0.2020 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 20977: loss = 0.0833 (0.327 sec/step)\n",
            "I0923 10:16:14.407954 139631849019264 learning.py:507] global step 20977: loss = 0.0833 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 20978: loss = 0.0349 (0.296 sec/step)\n",
            "I0923 10:16:14.705436 139631849019264 learning.py:507] global step 20978: loss = 0.0349 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 20979: loss = 0.1520 (0.292 sec/step)\n",
            "I0923 10:16:14.998614 139631849019264 learning.py:507] global step 20979: loss = 0.1520 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 20980: loss = 0.1903 (0.331 sec/step)\n",
            "I0923 10:16:15.331360 139631849019264 learning.py:507] global step 20980: loss = 0.1903 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 20981: loss = 0.0911 (0.316 sec/step)\n",
            "I0923 10:16:15.649113 139631849019264 learning.py:507] global step 20981: loss = 0.0911 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 20982: loss = 0.1058 (0.327 sec/step)\n",
            "I0923 10:16:15.978773 139631849019264 learning.py:507] global step 20982: loss = 0.1058 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 20983: loss = 0.1244 (0.300 sec/step)\n",
            "I0923 10:16:16.280220 139631849019264 learning.py:507] global step 20983: loss = 0.1244 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 20984: loss = 0.1439 (0.332 sec/step)\n",
            "I0923 10:16:16.614478 139631849019264 learning.py:507] global step 20984: loss = 0.1439 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20985: loss = 0.0303 (0.285 sec/step)\n",
            "I0923 10:16:16.900828 139631849019264 learning.py:507] global step 20985: loss = 0.0303 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 20986: loss = 0.0536 (0.340 sec/step)\n",
            "I0923 10:16:17.243424 139631849019264 learning.py:507] global step 20986: loss = 0.0536 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 20987: loss = 0.0730 (0.280 sec/step)\n",
            "I0923 10:16:17.525580 139631849019264 learning.py:507] global step 20987: loss = 0.0730 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 20988: loss = 0.0647 (0.295 sec/step)\n",
            "I0923 10:16:17.822345 139631849019264 learning.py:507] global step 20988: loss = 0.0647 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 20989: loss = 0.1126 (0.365 sec/step)\n",
            "I0923 10:16:18.368578 139631849019264 learning.py:507] global step 20989: loss = 0.1126 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 20990: loss = 0.0767 (0.438 sec/step)\n",
            "I0923 10:16:18.812849 139631849019264 learning.py:507] global step 20990: loss = 0.0767 (0.438 sec/step)\n",
            "INFO:tensorflow:global step 20991: loss = 0.0903 (0.435 sec/step)\n",
            "I0923 10:16:19.254657 139631849019264 learning.py:507] global step 20991: loss = 0.0903 (0.435 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 20991.\n",
            "I0923 10:16:19.333027 139628630939392 supervisor.py:1050] Recording summary at step 20991.\n",
            "INFO:tensorflow:global step 20992: loss = 0.0454 (0.381 sec/step)\n",
            "I0923 10:16:19.646421 139631849019264 learning.py:507] global step 20992: loss = 0.0454 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 20993: loss = 0.0905 (0.332 sec/step)\n",
            "I0923 10:16:19.979997 139631849019264 learning.py:507] global step 20993: loss = 0.0905 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 20994: loss = 0.0754 (0.385 sec/step)\n",
            "I0923 10:16:20.367180 139631849019264 learning.py:507] global step 20994: loss = 0.0754 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 20995: loss = 0.3111 (0.317 sec/step)\n",
            "I0923 10:16:20.685509 139631849019264 learning.py:507] global step 20995: loss = 0.3111 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 20996: loss = 0.0541 (0.298 sec/step)\n",
            "I0923 10:16:20.985253 139631849019264 learning.py:507] global step 20996: loss = 0.0541 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 20997: loss = 0.0877 (0.335 sec/step)\n",
            "I0923 10:16:21.322150 139631849019264 learning.py:507] global step 20997: loss = 0.0877 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 20998: loss = 0.1300 (0.290 sec/step)\n",
            "I0923 10:16:21.614325 139631849019264 learning.py:507] global step 20998: loss = 0.1300 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 20999: loss = 0.2085 (0.318 sec/step)\n",
            "I0923 10:16:21.934054 139631849019264 learning.py:507] global step 20999: loss = 0.2085 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 21000: loss = 0.0641 (0.276 sec/step)\n",
            "I0923 10:16:22.212371 139631849019264 learning.py:507] global step 21000: loss = 0.0641 (0.276 sec/step)\n",
            "INFO:tensorflow:global step 21001: loss = 0.0657 (0.381 sec/step)\n",
            "I0923 10:16:22.595590 139631849019264 learning.py:507] global step 21001: loss = 0.0657 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 21002: loss = 0.0576 (0.296 sec/step)\n",
            "I0923 10:16:22.893414 139631849019264 learning.py:507] global step 21002: loss = 0.0576 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 21003: loss = 0.0676 (0.359 sec/step)\n",
            "I0923 10:16:23.254517 139631849019264 learning.py:507] global step 21003: loss = 0.0676 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 21004: loss = 0.1423 (0.360 sec/step)\n",
            "I0923 10:16:23.616364 139631849019264 learning.py:507] global step 21004: loss = 0.1423 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 21005: loss = 0.0560 (0.295 sec/step)\n",
            "I0923 10:16:23.913146 139631849019264 learning.py:507] global step 21005: loss = 0.0560 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 21006: loss = 0.1228 (0.355 sec/step)\n",
            "I0923 10:16:24.270004 139631849019264 learning.py:507] global step 21006: loss = 0.1228 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 21007: loss = 0.1344 (0.334 sec/step)\n",
            "I0923 10:16:24.605378 139631849019264 learning.py:507] global step 21007: loss = 0.1344 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 21008: loss = 0.0759 (0.320 sec/step)\n",
            "I0923 10:16:24.927094 139631849019264 learning.py:507] global step 21008: loss = 0.0759 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 21009: loss = 0.1749 (0.297 sec/step)\n",
            "I0923 10:16:25.226777 139631849019264 learning.py:507] global step 21009: loss = 0.1749 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 21010: loss = 0.2128 (0.306 sec/step)\n",
            "I0923 10:16:25.535148 139631849019264 learning.py:507] global step 21010: loss = 0.2128 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 21011: loss = 0.0366 (0.303 sec/step)\n",
            "I0923 10:16:25.840151 139631849019264 learning.py:507] global step 21011: loss = 0.0366 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 21012: loss = 0.1873 (0.355 sec/step)\n",
            "I0923 10:16:26.197512 139631849019264 learning.py:507] global step 21012: loss = 0.1873 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 21013: loss = 0.0914 (0.327 sec/step)\n",
            "I0923 10:16:26.527393 139631849019264 learning.py:507] global step 21013: loss = 0.0914 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 21014: loss = 0.0716 (0.271 sec/step)\n",
            "I0923 10:16:26.800544 139631849019264 learning.py:507] global step 21014: loss = 0.0716 (0.271 sec/step)\n",
            "INFO:tensorflow:global step 21015: loss = 0.0646 (0.293 sec/step)\n",
            "I0923 10:16:27.094860 139631849019264 learning.py:507] global step 21015: loss = 0.0646 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 21016: loss = 0.0660 (0.332 sec/step)\n",
            "I0923 10:16:27.428437 139631849019264 learning.py:507] global step 21016: loss = 0.0660 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 21017: loss = 0.1851 (0.293 sec/step)\n",
            "I0923 10:16:27.723126 139631849019264 learning.py:507] global step 21017: loss = 0.1851 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 21018: loss = 0.0639 (0.349 sec/step)\n",
            "I0923 10:16:28.074233 139631849019264 learning.py:507] global step 21018: loss = 0.0639 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 21019: loss = 0.1053 (0.339 sec/step)\n",
            "I0923 10:16:28.415004 139631849019264 learning.py:507] global step 21019: loss = 0.1053 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 21020: loss = 0.2325 (0.307 sec/step)\n",
            "I0923 10:16:28.724125 139631849019264 learning.py:507] global step 21020: loss = 0.2325 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 21021: loss = 0.1141 (0.320 sec/step)\n",
            "I0923 10:16:29.047974 139631849019264 learning.py:507] global step 21021: loss = 0.1141 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 21022: loss = 0.0585 (0.320 sec/step)\n",
            "I0923 10:16:29.370136 139631849019264 learning.py:507] global step 21022: loss = 0.0585 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 21023: loss = 0.0445 (0.303 sec/step)\n",
            "I0923 10:16:29.675329 139631849019264 learning.py:507] global step 21023: loss = 0.0445 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 21024: loss = 0.1538 (0.332 sec/step)\n",
            "I0923 10:16:30.009521 139631849019264 learning.py:507] global step 21024: loss = 0.1538 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 21025: loss = 0.2236 (0.298 sec/step)\n",
            "I0923 10:16:30.309280 139631849019264 learning.py:507] global step 21025: loss = 0.2236 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 21026: loss = 0.0763 (0.301 sec/step)\n",
            "I0923 10:16:30.612801 139631849019264 learning.py:507] global step 21026: loss = 0.0763 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 21027: loss = 0.0361 (0.358 sec/step)\n",
            "I0923 10:16:30.973325 139631849019264 learning.py:507] global step 21027: loss = 0.0361 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 21028: loss = 0.0577 (0.327 sec/step)\n",
            "I0923 10:16:31.301869 139631849019264 learning.py:507] global step 21028: loss = 0.0577 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 21029: loss = 0.0630 (0.339 sec/step)\n",
            "I0923 10:16:31.642696 139631849019264 learning.py:507] global step 21029: loss = 0.0630 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 21030: loss = 0.0792 (0.319 sec/step)\n",
            "I0923 10:16:31.963354 139631849019264 learning.py:507] global step 21030: loss = 0.0792 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 21031: loss = 0.0469 (0.306 sec/step)\n",
            "I0923 10:16:32.270931 139631849019264 learning.py:507] global step 21031: loss = 0.0469 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 21032: loss = 0.0667 (0.318 sec/step)\n",
            "I0923 10:16:32.590718 139631849019264 learning.py:507] global step 21032: loss = 0.0667 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 21033: loss = 0.0682 (0.339 sec/step)\n",
            "I0923 10:16:32.931662 139631849019264 learning.py:507] global step 21033: loss = 0.0682 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 21034: loss = 0.0819 (0.309 sec/step)\n",
            "I0923 10:16:33.242189 139631849019264 learning.py:507] global step 21034: loss = 0.0819 (0.309 sec/step)\n",
            "INFO:tensorflow:global step 21035: loss = 0.0299 (0.344 sec/step)\n",
            "I0923 10:16:33.588142 139631849019264 learning.py:507] global step 21035: loss = 0.0299 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 21036: loss = 0.1277 (0.321 sec/step)\n",
            "I0923 10:16:33.910561 139631849019264 learning.py:507] global step 21036: loss = 0.1277 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 21037: loss = 0.0847 (0.275 sec/step)\n",
            "I0923 10:16:34.187082 139631849019264 learning.py:507] global step 21037: loss = 0.0847 (0.275 sec/step)\n",
            "INFO:tensorflow:global step 21038: loss = 0.0668 (0.300 sec/step)\n",
            "I0923 10:16:34.488796 139631849019264 learning.py:507] global step 21038: loss = 0.0668 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 21039: loss = 0.0904 (0.310 sec/step)\n",
            "I0923 10:16:34.800835 139631849019264 learning.py:507] global step 21039: loss = 0.0904 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 21040: loss = 0.0462 (0.320 sec/step)\n",
            "I0923 10:16:35.122382 139631849019264 learning.py:507] global step 21040: loss = 0.0462 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 21041: loss = 0.1047 (0.292 sec/step)\n",
            "I0923 10:16:35.416046 139631849019264 learning.py:507] global step 21041: loss = 0.1047 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 21042: loss = 0.0348 (0.316 sec/step)\n",
            "I0923 10:16:35.733530 139631849019264 learning.py:507] global step 21042: loss = 0.0348 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 21043: loss = 0.1418 (0.302 sec/step)\n",
            "I0923 10:16:36.037106 139631849019264 learning.py:507] global step 21043: loss = 0.1418 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 21044: loss = 0.0631 (0.318 sec/step)\n",
            "I0923 10:16:36.357227 139631849019264 learning.py:507] global step 21044: loss = 0.0631 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 21045: loss = 0.0761 (0.326 sec/step)\n",
            "I0923 10:16:36.685606 139631849019264 learning.py:507] global step 21045: loss = 0.0761 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 21046: loss = 0.1742 (0.304 sec/step)\n",
            "I0923 10:16:36.991600 139631849019264 learning.py:507] global step 21046: loss = 0.1742 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 21047: loss = 0.1902 (0.303 sec/step)\n",
            "I0923 10:16:37.296139 139631849019264 learning.py:507] global step 21047: loss = 0.1902 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 21048: loss = 0.1358 (0.324 sec/step)\n",
            "I0923 10:16:37.621887 139631849019264 learning.py:507] global step 21048: loss = 0.1358 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 21049: loss = 0.0305 (0.322 sec/step)\n",
            "I0923 10:16:37.945733 139631849019264 learning.py:507] global step 21049: loss = 0.0305 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 21050: loss = 0.0820 (0.272 sec/step)\n",
            "I0923 10:16:38.219554 139631849019264 learning.py:507] global step 21050: loss = 0.0820 (0.272 sec/step)\n",
            "INFO:tensorflow:global step 21051: loss = 0.0348 (0.299 sec/step)\n",
            "I0923 10:16:38.520478 139631849019264 learning.py:507] global step 21051: loss = 0.0348 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 21052: loss = 0.1276 (0.314 sec/step)\n",
            "I0923 10:16:38.836704 139631849019264 learning.py:507] global step 21052: loss = 0.1276 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 21053: loss = 0.0244 (0.290 sec/step)\n",
            "I0923 10:16:39.128567 139631849019264 learning.py:507] global step 21053: loss = 0.0244 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 21054: loss = 0.2390 (0.315 sec/step)\n",
            "I0923 10:16:39.445441 139631849019264 learning.py:507] global step 21054: loss = 0.2390 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 21055: loss = 0.1480 (0.324 sec/step)\n",
            "I0923 10:16:39.770949 139631849019264 learning.py:507] global step 21055: loss = 0.1480 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 21056: loss = 0.0488 (0.278 sec/step)\n",
            "I0923 10:16:40.051757 139631849019264 learning.py:507] global step 21056: loss = 0.0488 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 21057: loss = 0.0420 (0.285 sec/step)\n",
            "I0923 10:16:40.342091 139631849019264 learning.py:507] global step 21057: loss = 0.0420 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 21058: loss = 0.1293 (0.336 sec/step)\n",
            "I0923 10:16:40.679999 139631849019264 learning.py:507] global step 21058: loss = 0.1293 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 21059: loss = 0.0401 (0.284 sec/step)\n",
            "I0923 10:16:40.966259 139631849019264 learning.py:507] global step 21059: loss = 0.0401 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 21060: loss = 0.1219 (0.300 sec/step)\n",
            "I0923 10:16:41.268631 139631849019264 learning.py:507] global step 21060: loss = 0.1219 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 21061: loss = 0.0512 (0.303 sec/step)\n",
            "I0923 10:16:41.573027 139631849019264 learning.py:507] global step 21061: loss = 0.0512 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 21062: loss = 0.0896 (0.285 sec/step)\n",
            "I0923 10:16:41.859497 139631849019264 learning.py:507] global step 21062: loss = 0.0896 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 21063: loss = 0.0924 (0.285 sec/step)\n",
            "I0923 10:16:42.146032 139631849019264 learning.py:507] global step 21063: loss = 0.0924 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 21064: loss = 0.0756 (0.325 sec/step)\n",
            "I0923 10:16:42.472911 139631849019264 learning.py:507] global step 21064: loss = 0.0756 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 21065: loss = 0.1228 (0.338 sec/step)\n",
            "I0923 10:16:42.812564 139631849019264 learning.py:507] global step 21065: loss = 0.1228 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 21066: loss = 0.0545 (0.303 sec/step)\n",
            "I0923 10:16:43.117401 139631849019264 learning.py:507] global step 21066: loss = 0.0545 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 21067: loss = 0.0869 (0.279 sec/step)\n",
            "I0923 10:16:43.398519 139631849019264 learning.py:507] global step 21067: loss = 0.0869 (0.279 sec/step)\n",
            "INFO:tensorflow:global step 21068: loss = 0.0342 (0.293 sec/step)\n",
            "I0923 10:16:43.693351 139631849019264 learning.py:507] global step 21068: loss = 0.0342 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 21069: loss = 0.0914 (0.311 sec/step)\n",
            "I0923 10:16:44.006525 139631849019264 learning.py:507] global step 21069: loss = 0.0914 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 21070: loss = 0.1170 (0.290 sec/step)\n",
            "I0923 10:16:44.298281 139631849019264 learning.py:507] global step 21070: loss = 0.1170 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 21071: loss = 0.0282 (0.299 sec/step)\n",
            "I0923 10:16:44.600040 139631849019264 learning.py:507] global step 21071: loss = 0.0282 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 21072: loss = 0.0551 (0.292 sec/step)\n",
            "I0923 10:16:44.893557 139631849019264 learning.py:507] global step 21072: loss = 0.0551 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 21073: loss = 0.0556 (0.282 sec/step)\n",
            "I0923 10:16:45.177343 139631849019264 learning.py:507] global step 21073: loss = 0.0556 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 21074: loss = 0.1166 (0.290 sec/step)\n",
            "I0923 10:16:45.469126 139631849019264 learning.py:507] global step 21074: loss = 0.1166 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 21075: loss = 0.0960 (0.312 sec/step)\n",
            "I0923 10:16:45.782938 139631849019264 learning.py:507] global step 21075: loss = 0.0960 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 21076: loss = 0.0462 (0.276 sec/step)\n",
            "I0923 10:16:46.061001 139631849019264 learning.py:507] global step 21076: loss = 0.0462 (0.276 sec/step)\n",
            "INFO:tensorflow:global step 21077: loss = 0.1807 (0.323 sec/step)\n",
            "I0923 10:16:46.385518 139631849019264 learning.py:507] global step 21077: loss = 0.1807 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 21078: loss = 0.1001 (0.317 sec/step)\n",
            "I0923 10:16:46.704875 139631849019264 learning.py:507] global step 21078: loss = 0.1001 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 21079: loss = 0.0537 (0.298 sec/step)\n",
            "I0923 10:16:47.004458 139631849019264 learning.py:507] global step 21079: loss = 0.0537 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 21080: loss = 0.0482 (0.321 sec/step)\n",
            "I0923 10:16:47.327836 139631849019264 learning.py:507] global step 21080: loss = 0.0482 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 21081: loss = 0.0943 (0.320 sec/step)\n",
            "I0923 10:16:47.650129 139631849019264 learning.py:507] global step 21081: loss = 0.0943 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 21082: loss = 0.1099 (0.317 sec/step)\n",
            "I0923 10:16:47.968825 139631849019264 learning.py:507] global step 21082: loss = 0.1099 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 21083: loss = 0.0539 (0.287 sec/step)\n",
            "I0923 10:16:48.256917 139631849019264 learning.py:507] global step 21083: loss = 0.0539 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 21084: loss = 0.0807 (0.348 sec/step)\n",
            "I0923 10:16:48.607003 139631849019264 learning.py:507] global step 21084: loss = 0.0807 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 21085: loss = 0.0983 (0.327 sec/step)\n",
            "I0923 10:16:48.936261 139631849019264 learning.py:507] global step 21085: loss = 0.0983 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 21086: loss = 0.0777 (0.321 sec/step)\n",
            "I0923 10:16:49.259704 139631849019264 learning.py:507] global step 21086: loss = 0.0777 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 21087: loss = 0.0904 (0.325 sec/step)\n",
            "I0923 10:16:49.587569 139631849019264 learning.py:507] global step 21087: loss = 0.0904 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 21088: loss = 0.0577 (0.315 sec/step)\n",
            "I0923 10:16:49.904084 139631849019264 learning.py:507] global step 21088: loss = 0.0577 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 21089: loss = 0.0722 (0.292 sec/step)\n",
            "I0923 10:16:50.198110 139631849019264 learning.py:507] global step 21089: loss = 0.0722 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 21090: loss = 0.0465 (0.292 sec/step)\n",
            "I0923 10:16:50.492369 139631849019264 learning.py:507] global step 21090: loss = 0.0465 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 21091: loss = 0.0638 (0.306 sec/step)\n",
            "I0923 10:16:50.801015 139631849019264 learning.py:507] global step 21091: loss = 0.0638 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 21092: loss = 0.0654 (0.282 sec/step)\n",
            "I0923 10:16:51.084743 139631849019264 learning.py:507] global step 21092: loss = 0.0654 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 21093: loss = 0.0662 (0.289 sec/step)\n",
            "I0923 10:16:51.375558 139631849019264 learning.py:507] global step 21093: loss = 0.0662 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 21094: loss = 0.0549 (0.321 sec/step)\n",
            "I0923 10:16:51.701336 139631849019264 learning.py:507] global step 21094: loss = 0.0549 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 21095: loss = 0.0637 (0.290 sec/step)\n",
            "I0923 10:16:51.994556 139631849019264 learning.py:507] global step 21095: loss = 0.0637 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 21096: loss = 0.0525 (0.343 sec/step)\n",
            "I0923 10:16:52.339280 139631849019264 learning.py:507] global step 21096: loss = 0.0525 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 21097: loss = 0.0659 (0.321 sec/step)\n",
            "I0923 10:16:52.662094 139631849019264 learning.py:507] global step 21097: loss = 0.0659 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 21098: loss = 0.3429 (0.323 sec/step)\n",
            "I0923 10:16:52.987124 139631849019264 learning.py:507] global step 21098: loss = 0.3429 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 21099: loss = 0.0866 (0.386 sec/step)\n",
            "I0923 10:16:53.374475 139631849019264 learning.py:507] global step 21099: loss = 0.0866 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 21100: loss = 0.0345 (0.337 sec/step)\n",
            "I0923 10:16:53.713054 139631849019264 learning.py:507] global step 21100: loss = 0.0345 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 21101: loss = 0.0846 (0.307 sec/step)\n",
            "I0923 10:16:54.022214 139631849019264 learning.py:507] global step 21101: loss = 0.0846 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 21102: loss = 0.1720 (0.329 sec/step)\n",
            "I0923 10:16:54.353044 139631849019264 learning.py:507] global step 21102: loss = 0.1720 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 21103: loss = 0.0825 (0.328 sec/step)\n",
            "I0923 10:16:54.682469 139631849019264 learning.py:507] global step 21103: loss = 0.0825 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 21104: loss = 0.0642 (0.334 sec/step)\n",
            "I0923 10:16:55.018117 139631849019264 learning.py:507] global step 21104: loss = 0.0642 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 21105: loss = 0.0955 (0.310 sec/step)\n",
            "I0923 10:16:55.330491 139631849019264 learning.py:507] global step 21105: loss = 0.0955 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 21106: loss = 0.0891 (0.343 sec/step)\n",
            "I0923 10:16:55.675465 139631849019264 learning.py:507] global step 21106: loss = 0.0891 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 21107: loss = 0.0669 (0.286 sec/step)\n",
            "I0923 10:16:55.963494 139631849019264 learning.py:507] global step 21107: loss = 0.0669 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 21108: loss = 0.1050 (0.283 sec/step)\n",
            "I0923 10:16:56.250447 139631849019264 learning.py:507] global step 21108: loss = 0.1050 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 21109: loss = 0.1542 (0.297 sec/step)\n",
            "I0923 10:16:56.549497 139631849019264 learning.py:507] global step 21109: loss = 0.1542 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 21110: loss = 0.7545 (0.311 sec/step)\n",
            "I0923 10:16:56.861959 139631849019264 learning.py:507] global step 21110: loss = 0.7545 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 21111: loss = 0.0725 (0.295 sec/step)\n",
            "I0923 10:16:57.158497 139631849019264 learning.py:507] global step 21111: loss = 0.0725 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 21112: loss = 0.0994 (0.275 sec/step)\n",
            "I0923 10:16:57.435368 139631849019264 learning.py:507] global step 21112: loss = 0.0994 (0.275 sec/step)\n",
            "INFO:tensorflow:global step 21113: loss = 0.0218 (0.292 sec/step)\n",
            "I0923 10:16:57.729587 139631849019264 learning.py:507] global step 21113: loss = 0.0218 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 21114: loss = 0.1185 (0.332 sec/step)\n",
            "I0923 10:16:58.063020 139631849019264 learning.py:507] global step 21114: loss = 0.1185 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 21115: loss = 0.1152 (0.284 sec/step)\n",
            "I0923 10:16:58.348637 139631849019264 learning.py:507] global step 21115: loss = 0.1152 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 21116: loss = 0.0645 (0.329 sec/step)\n",
            "I0923 10:16:58.679562 139631849019264 learning.py:507] global step 21116: loss = 0.0645 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 21117: loss = 0.2295 (0.326 sec/step)\n",
            "I0923 10:16:59.007737 139631849019264 learning.py:507] global step 21117: loss = 0.2295 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 21118: loss = 0.0658 (0.335 sec/step)\n",
            "I0923 10:16:59.344263 139631849019264 learning.py:507] global step 21118: loss = 0.0658 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 21119: loss = 0.1001 (0.319 sec/step)\n",
            "I0923 10:16:59.664753 139631849019264 learning.py:507] global step 21119: loss = 0.1001 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 21120: loss = 0.0568 (0.300 sec/step)\n",
            "I0923 10:16:59.966510 139631849019264 learning.py:507] global step 21120: loss = 0.0568 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 21121: loss = 0.3637 (0.333 sec/step)\n",
            "I0923 10:17:00.301074 139631849019264 learning.py:507] global step 21121: loss = 0.3637 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 21122: loss = 0.1396 (0.336 sec/step)\n",
            "I0923 10:17:00.638383 139631849019264 learning.py:507] global step 21122: loss = 0.1396 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 21123: loss = 0.0821 (0.325 sec/step)\n",
            "I0923 10:17:00.965411 139631849019264 learning.py:507] global step 21123: loss = 0.0821 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 21124: loss = 0.0420 (0.353 sec/step)\n",
            "I0923 10:17:01.320831 139631849019264 learning.py:507] global step 21124: loss = 0.0420 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 21125: loss = 0.0458 (0.290 sec/step)\n",
            "I0923 10:17:01.612375 139631849019264 learning.py:507] global step 21125: loss = 0.0458 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 21126: loss = 0.0686 (0.339 sec/step)\n",
            "I0923 10:17:01.953342 139631849019264 learning.py:507] global step 21126: loss = 0.0686 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 21127: loss = 0.1612 (0.301 sec/step)\n",
            "I0923 10:17:02.256080 139631849019264 learning.py:507] global step 21127: loss = 0.1612 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 21128: loss = 0.1280 (0.295 sec/step)\n",
            "I0923 10:17:02.552996 139631849019264 learning.py:507] global step 21128: loss = 0.1280 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 21129: loss = 0.2525 (0.313 sec/step)\n",
            "I0923 10:17:02.867837 139631849019264 learning.py:507] global step 21129: loss = 0.2525 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 21130: loss = 0.0835 (0.316 sec/step)\n",
            "I0923 10:17:03.189003 139631849019264 learning.py:507] global step 21130: loss = 0.0835 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 21131: loss = 0.0838 (0.343 sec/step)\n",
            "I0923 10:17:03.534506 139631849019264 learning.py:507] global step 21131: loss = 0.0838 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 21132: loss = 0.0606 (0.346 sec/step)\n",
            "I0923 10:17:03.882736 139631849019264 learning.py:507] global step 21132: loss = 0.0606 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 21133: loss = 0.0282 (0.317 sec/step)\n",
            "I0923 10:17:04.201637 139631849019264 learning.py:507] global step 21133: loss = 0.0282 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 21134: loss = 0.1248 (0.336 sec/step)\n",
            "I0923 10:17:04.539982 139631849019264 learning.py:507] global step 21134: loss = 0.1248 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 21135: loss = 0.1601 (0.291 sec/step)\n",
            "I0923 10:17:04.833680 139631849019264 learning.py:507] global step 21135: loss = 0.1601 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 21136: loss = 0.0640 (0.314 sec/step)\n",
            "I0923 10:17:05.149023 139631849019264 learning.py:507] global step 21136: loss = 0.0640 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 21137: loss = 0.1659 (0.320 sec/step)\n",
            "I0923 10:17:05.471151 139631849019264 learning.py:507] global step 21137: loss = 0.1659 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 21138: loss = 0.0624 (0.325 sec/step)\n",
            "I0923 10:17:05.798580 139631849019264 learning.py:507] global step 21138: loss = 0.0624 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 21139: loss = 0.1584 (0.289 sec/step)\n",
            "I0923 10:17:06.089259 139631849019264 learning.py:507] global step 21139: loss = 0.1584 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 21140: loss = 0.1289 (0.303 sec/step)\n",
            "I0923 10:17:06.393854 139631849019264 learning.py:507] global step 21140: loss = 0.1289 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 21141: loss = 0.0318 (0.300 sec/step)\n",
            "I0923 10:17:06.695595 139631849019264 learning.py:507] global step 21141: loss = 0.0318 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 21142: loss = 0.0423 (0.292 sec/step)\n",
            "I0923 10:17:06.989390 139631849019264 learning.py:507] global step 21142: loss = 0.0423 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 21143: loss = 0.0469 (0.305 sec/step)\n",
            "I0923 10:17:07.296508 139631849019264 learning.py:507] global step 21143: loss = 0.0469 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 21144: loss = 0.1219 (0.316 sec/step)\n",
            "I0923 10:17:07.614937 139631849019264 learning.py:507] global step 21144: loss = 0.1219 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 21145: loss = 0.0548 (0.270 sec/step)\n",
            "I0923 10:17:07.887415 139631849019264 learning.py:507] global step 21145: loss = 0.0548 (0.270 sec/step)\n",
            "INFO:tensorflow:global step 21146: loss = 0.1063 (0.328 sec/step)\n",
            "I0923 10:17:08.217866 139631849019264 learning.py:507] global step 21146: loss = 0.1063 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 21147: loss = 0.0487 (0.322 sec/step)\n",
            "I0923 10:17:08.542124 139631849019264 learning.py:507] global step 21147: loss = 0.0487 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 21148: loss = 0.1544 (0.308 sec/step)\n",
            "I0923 10:17:08.852308 139631849019264 learning.py:507] global step 21148: loss = 0.1544 (0.308 sec/step)\n",
            "INFO:tensorflow:global step 21149: loss = 0.0544 (0.337 sec/step)\n",
            "I0923 10:17:09.191299 139631849019264 learning.py:507] global step 21149: loss = 0.0544 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 21150: loss = 0.0670 (0.347 sec/step)\n",
            "I0923 10:17:09.540455 139631849019264 learning.py:507] global step 21150: loss = 0.0670 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 21151: loss = 0.0539 (0.300 sec/step)\n",
            "I0923 10:17:09.842210 139631849019264 learning.py:507] global step 21151: loss = 0.0539 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 21152: loss = 0.0785 (0.297 sec/step)\n",
            "I0923 10:17:10.140543 139631849019264 learning.py:507] global step 21152: loss = 0.0785 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 21153: loss = 0.1103 (0.372 sec/step)\n",
            "I0923 10:17:10.514632 139631849019264 learning.py:507] global step 21153: loss = 0.1103 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 21154: loss = 0.1288 (0.297 sec/step)\n",
            "I0923 10:17:10.813608 139631849019264 learning.py:507] global step 21154: loss = 0.1288 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 21155: loss = 0.1053 (0.271 sec/step)\n",
            "I0923 10:17:11.086046 139631849019264 learning.py:507] global step 21155: loss = 0.1053 (0.271 sec/step)\n",
            "INFO:tensorflow:global step 21156: loss = 0.0980 (0.286 sec/step)\n",
            "I0923 10:17:11.374465 139631849019264 learning.py:507] global step 21156: loss = 0.0980 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 21157: loss = 0.0500 (0.339 sec/step)\n",
            "I0923 10:17:11.715104 139631849019264 learning.py:507] global step 21157: loss = 0.0500 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 21158: loss = 0.0666 (0.312 sec/step)\n",
            "I0923 10:17:12.028478 139631849019264 learning.py:507] global step 21158: loss = 0.0666 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 21159: loss = 0.0586 (0.315 sec/step)\n",
            "I0923 10:17:12.345647 139631849019264 learning.py:507] global step 21159: loss = 0.0586 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 21160: loss = 0.0397 (0.340 sec/step)\n",
            "I0923 10:17:12.687574 139631849019264 learning.py:507] global step 21160: loss = 0.0397 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 21161: loss = 0.0619 (0.311 sec/step)\n",
            "I0923 10:17:13.000292 139631849019264 learning.py:507] global step 21161: loss = 0.0619 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 21162: loss = 0.0548 (0.342 sec/step)\n",
            "I0923 10:17:13.343927 139631849019264 learning.py:507] global step 21162: loss = 0.0548 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 21163: loss = 0.0747 (0.296 sec/step)\n",
            "I0923 10:17:13.641788 139631849019264 learning.py:507] global step 21163: loss = 0.0747 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 21164: loss = 0.1608 (0.282 sec/step)\n",
            "I0923 10:17:13.924923 139631849019264 learning.py:507] global step 21164: loss = 0.1608 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 21165: loss = 0.1253 (0.392 sec/step)\n",
            "I0923 10:17:14.318984 139631849019264 learning.py:507] global step 21165: loss = 0.1253 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 21166: loss = 0.0469 (0.295 sec/step)\n",
            "I0923 10:17:14.616353 139631849019264 learning.py:507] global step 21166: loss = 0.0469 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 21167: loss = 0.0868 (0.290 sec/step)\n",
            "I0923 10:17:14.907701 139631849019264 learning.py:507] global step 21167: loss = 0.0868 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 21168: loss = 0.1045 (0.316 sec/step)\n",
            "I0923 10:17:15.225109 139631849019264 learning.py:507] global step 21168: loss = 0.1045 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 21169: loss = 0.1018 (0.287 sec/step)\n",
            "I0923 10:17:15.514286 139631849019264 learning.py:507] global step 21169: loss = 0.1018 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 21170: loss = 0.1333 (0.298 sec/step)\n",
            "I0923 10:17:15.814041 139631849019264 learning.py:507] global step 21170: loss = 0.1333 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 21171: loss = 0.0479 (0.285 sec/step)\n",
            "I0923 10:17:16.101311 139631849019264 learning.py:507] global step 21171: loss = 0.0479 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 21172: loss = 0.0474 (0.306 sec/step)\n",
            "I0923 10:17:16.412737 139631849019264 learning.py:507] global step 21172: loss = 0.0474 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 21173: loss = 0.0518 (0.295 sec/step)\n",
            "I0923 10:17:16.710704 139631849019264 learning.py:507] global step 21173: loss = 0.0518 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 21174: loss = 0.0720 (0.318 sec/step)\n",
            "I0923 10:17:17.031125 139631849019264 learning.py:507] global step 21174: loss = 0.0720 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 21175: loss = 0.0429 (0.292 sec/step)\n",
            "I0923 10:17:17.324627 139631849019264 learning.py:507] global step 21175: loss = 0.0429 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 21176: loss = 0.0667 (0.346 sec/step)\n",
            "I0923 10:17:17.675286 139631849019264 learning.py:507] global step 21176: loss = 0.0667 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 21177: loss = 0.0431 (0.322 sec/step)\n",
            "I0923 10:17:17.999220 139631849019264 learning.py:507] global step 21177: loss = 0.0431 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 21178: loss = 0.0547 (0.309 sec/step)\n",
            "I0923 10:17:18.310947 139631849019264 learning.py:507] global step 21178: loss = 0.0547 (0.309 sec/step)\n",
            "INFO:tensorflow:global step 21179: loss = 0.0744 (0.331 sec/step)\n",
            "I0923 10:17:18.643835 139631849019264 learning.py:507] global step 21179: loss = 0.0744 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 21180: loss = 0.1671 (0.308 sec/step)\n",
            "I0923 10:17:18.954027 139631849019264 learning.py:507] global step 21180: loss = 0.1671 (0.308 sec/step)\n",
            "INFO:tensorflow:global step 21181: loss = 0.0574 (0.292 sec/step)\n",
            "I0923 10:17:19.250272 139631849019264 learning.py:507] global step 21181: loss = 0.0574 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 21182: loss = 0.1305 (0.335 sec/step)\n",
            "I0923 10:17:19.587417 139631849019264 learning.py:507] global step 21182: loss = 0.1305 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 21183: loss = 0.0771 (0.341 sec/step)\n",
            "I0923 10:17:19.930634 139631849019264 learning.py:507] global step 21183: loss = 0.0771 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 21184: loss = 0.0571 (0.309 sec/step)\n",
            "I0923 10:17:20.241812 139631849019264 learning.py:507] global step 21184: loss = 0.0571 (0.309 sec/step)\n",
            "INFO:tensorflow:global step 21185: loss = 0.1757 (0.317 sec/step)\n",
            "I0923 10:17:20.560899 139631849019264 learning.py:507] global step 21185: loss = 0.1757 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 21186: loss = 0.1000 (0.330 sec/step)\n",
            "I0923 10:17:20.893351 139631849019264 learning.py:507] global step 21186: loss = 0.1000 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 21187: loss = 0.0456 (0.302 sec/step)\n",
            "I0923 10:17:21.197038 139631849019264 learning.py:507] global step 21187: loss = 0.0456 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 21188: loss = 0.0801 (0.353 sec/step)\n",
            "I0923 10:17:21.551699 139631849019264 learning.py:507] global step 21188: loss = 0.0801 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 21189: loss = 0.0493 (0.354 sec/step)\n",
            "I0923 10:17:21.907950 139631849019264 learning.py:507] global step 21189: loss = 0.0493 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 21190: loss = 0.0964 (0.310 sec/step)\n",
            "I0923 10:17:22.220772 139631849019264 learning.py:507] global step 21190: loss = 0.0964 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 21191: loss = 0.0787 (0.330 sec/step)\n",
            "I0923 10:17:22.552442 139631849019264 learning.py:507] global step 21191: loss = 0.0787 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 21192: loss = 0.0884 (0.295 sec/step)\n",
            "I0923 10:17:22.849771 139631849019264 learning.py:507] global step 21192: loss = 0.0884 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 21193: loss = 0.1170 (0.344 sec/step)\n",
            "I0923 10:17:23.196324 139631849019264 learning.py:507] global step 21193: loss = 0.1170 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 21194: loss = 0.0550 (0.362 sec/step)\n",
            "I0923 10:17:23.560116 139631849019264 learning.py:507] global step 21194: loss = 0.0550 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 21195: loss = 0.1068 (0.330 sec/step)\n",
            "I0923 10:17:23.892409 139631849019264 learning.py:507] global step 21195: loss = 0.1068 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 21196: loss = 0.0549 (0.320 sec/step)\n",
            "I0923 10:17:24.214331 139631849019264 learning.py:507] global step 21196: loss = 0.0549 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 21197: loss = 0.0754 (0.310 sec/step)\n",
            "I0923 10:17:24.526315 139631849019264 learning.py:507] global step 21197: loss = 0.0754 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 21198: loss = 0.0874 (0.393 sec/step)\n",
            "I0923 10:17:24.921709 139631849019264 learning.py:507] global step 21198: loss = 0.0874 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 21199: loss = 0.1265 (0.280 sec/step)\n",
            "I0923 10:17:25.204552 139631849019264 learning.py:507] global step 21199: loss = 0.1265 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 21200: loss = 0.0523 (0.328 sec/step)\n",
            "I0923 10:17:25.534809 139631849019264 learning.py:507] global step 21200: loss = 0.0523 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 21201: loss = 0.0739 (0.320 sec/step)\n",
            "I0923 10:17:25.856441 139631849019264 learning.py:507] global step 21201: loss = 0.0739 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 21202: loss = 0.1348 (0.338 sec/step)\n",
            "I0923 10:17:26.196183 139631849019264 learning.py:507] global step 21202: loss = 0.1348 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 21203: loss = 0.1730 (0.331 sec/step)\n",
            "I0923 10:17:26.528536 139631849019264 learning.py:507] global step 21203: loss = 0.1730 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 21204: loss = 0.0283 (0.337 sec/step)\n",
            "I0923 10:17:26.867250 139631849019264 learning.py:507] global step 21204: loss = 0.0283 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 21205: loss = 0.2502 (0.321 sec/step)\n",
            "I0923 10:17:27.190277 139631849019264 learning.py:507] global step 21205: loss = 0.2502 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 21206: loss = 0.0997 (0.295 sec/step)\n",
            "I0923 10:17:27.486746 139631849019264 learning.py:507] global step 21206: loss = 0.0997 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 21207: loss = 0.0956 (0.339 sec/step)\n",
            "I0923 10:17:27.827916 139631849019264 learning.py:507] global step 21207: loss = 0.0956 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 21208: loss = 0.0591 (0.351 sec/step)\n",
            "I0923 10:17:28.181373 139631849019264 learning.py:507] global step 21208: loss = 0.0591 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 21209: loss = 0.1754 (0.306 sec/step)\n",
            "I0923 10:17:28.490034 139631849019264 learning.py:507] global step 21209: loss = 0.1754 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 21210: loss = 0.0798 (0.305 sec/step)\n",
            "I0923 10:17:28.796928 139631849019264 learning.py:507] global step 21210: loss = 0.0798 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 21211: loss = 0.0655 (0.357 sec/step)\n",
            "I0923 10:17:29.155664 139631849019264 learning.py:507] global step 21211: loss = 0.0655 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 21212: loss = 0.1294 (0.340 sec/step)\n",
            "I0923 10:17:29.498154 139631849019264 learning.py:507] global step 21212: loss = 0.1294 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 21213: loss = 0.0939 (0.302 sec/step)\n",
            "I0923 10:17:29.801455 139631849019264 learning.py:507] global step 21213: loss = 0.0939 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 21214: loss = 0.1794 (0.279 sec/step)\n",
            "I0923 10:17:30.082301 139631849019264 learning.py:507] global step 21214: loss = 0.1794 (0.279 sec/step)\n",
            "INFO:tensorflow:global step 21215: loss = 0.0376 (0.354 sec/step)\n",
            "I0923 10:17:30.440436 139631849019264 learning.py:507] global step 21215: loss = 0.0376 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 21216: loss = 0.0949 (0.388 sec/step)\n",
            "I0923 10:17:30.830600 139631849019264 learning.py:507] global step 21216: loss = 0.0949 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 21217: loss = 0.0617 (0.319 sec/step)\n",
            "I0923 10:17:31.151513 139631849019264 learning.py:507] global step 21217: loss = 0.0617 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 21218: loss = 0.0700 (0.302 sec/step)\n",
            "I0923 10:17:31.456238 139631849019264 learning.py:507] global step 21218: loss = 0.0700 (0.302 sec/step)\n",
            "INFO:tensorflow:global step 21219: loss = 0.1372 (0.327 sec/step)\n",
            "I0923 10:17:31.785377 139631849019264 learning.py:507] global step 21219: loss = 0.1372 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 21220: loss = 0.0559 (0.335 sec/step)\n",
            "I0923 10:17:32.122338 139631849019264 learning.py:507] global step 21220: loss = 0.0559 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 21221: loss = 0.0920 (0.322 sec/step)\n",
            "I0923 10:17:32.446915 139631849019264 learning.py:507] global step 21221: loss = 0.0920 (0.322 sec/step)\n",
            "INFO:tensorflow:global step 21222: loss = 0.0459 (0.304 sec/step)\n",
            "I0923 10:17:32.752467 139631849019264 learning.py:507] global step 21222: loss = 0.0459 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 21223: loss = 0.0964 (0.313 sec/step)\n",
            "I0923 10:17:33.068048 139631849019264 learning.py:507] global step 21223: loss = 0.0964 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 21224: loss = 0.1834 (0.347 sec/step)\n",
            "I0923 10:17:33.417228 139631849019264 learning.py:507] global step 21224: loss = 0.1834 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 21225: loss = 0.1400 (0.314 sec/step)\n",
            "I0923 10:17:33.732998 139631849019264 learning.py:507] global step 21225: loss = 0.1400 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 21226: loss = 0.0999 (0.287 sec/step)\n",
            "I0923 10:17:34.021532 139631849019264 learning.py:507] global step 21226: loss = 0.0999 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 21227: loss = 0.1260 (0.345 sec/step)\n",
            "I0923 10:17:34.368187 139631849019264 learning.py:507] global step 21227: loss = 0.1260 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 21228: loss = 0.0916 (0.331 sec/step)\n",
            "I0923 10:17:34.700979 139631849019264 learning.py:507] global step 21228: loss = 0.0916 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 21229: loss = 0.0679 (0.344 sec/step)\n",
            "I0923 10:17:35.046970 139631849019264 learning.py:507] global step 21229: loss = 0.0679 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 21230: loss = 0.1115 (0.307 sec/step)\n",
            "I0923 10:17:35.355681 139631849019264 learning.py:507] global step 21230: loss = 0.1115 (0.307 sec/step)\n",
            "INFO:tensorflow:global step 21231: loss = 0.1012 (0.347 sec/step)\n",
            "I0923 10:17:35.704090 139631849019264 learning.py:507] global step 21231: loss = 0.1012 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 21232: loss = 0.0413 (0.289 sec/step)\n",
            "I0923 10:17:35.994987 139631849019264 learning.py:507] global step 21232: loss = 0.0413 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 21233: loss = 0.1243 (0.338 sec/step)\n",
            "I0923 10:17:36.335319 139631849019264 learning.py:507] global step 21233: loss = 0.1243 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 21234: loss = 0.0724 (0.291 sec/step)\n",
            "I0923 10:17:36.628386 139631849019264 learning.py:507] global step 21234: loss = 0.0724 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 21235: loss = 0.0543 (0.347 sec/step)\n",
            "I0923 10:17:36.977518 139631849019264 learning.py:507] global step 21235: loss = 0.0543 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 21236: loss = 0.0426 (0.335 sec/step)\n",
            "I0923 10:17:37.314832 139631849019264 learning.py:507] global step 21236: loss = 0.0426 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 21237: loss = 0.0504 (0.290 sec/step)\n",
            "I0923 10:17:37.606804 139631849019264 learning.py:507] global step 21237: loss = 0.0504 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 21238: loss = 0.0456 (0.290 sec/step)\n",
            "I0923 10:17:37.898873 139631849019264 learning.py:507] global step 21238: loss = 0.0456 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 21239: loss = 0.1365 (0.341 sec/step)\n",
            "I0923 10:17:38.241933 139631849019264 learning.py:507] global step 21239: loss = 0.1365 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 21240: loss = 0.0931 (0.315 sec/step)\n",
            "I0923 10:17:38.559103 139631849019264 learning.py:507] global step 21240: loss = 0.0931 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 21241: loss = 0.1668 (0.296 sec/step)\n",
            "I0923 10:17:38.856763 139631849019264 learning.py:507] global step 21241: loss = 0.1668 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 21242: loss = 0.0674 (0.337 sec/step)\n",
            "I0923 10:17:39.195847 139631849019264 learning.py:507] global step 21242: loss = 0.0674 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 21243: loss = 0.0604 (0.341 sec/step)\n",
            "I0923 10:17:39.538936 139631849019264 learning.py:507] global step 21243: loss = 0.0604 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 21244: loss = 0.0743 (0.295 sec/step)\n",
            "I0923 10:17:39.836210 139631849019264 learning.py:507] global step 21244: loss = 0.0743 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 21245: loss = 0.1004 (0.336 sec/step)\n",
            "I0923 10:17:40.174791 139631849019264 learning.py:507] global step 21245: loss = 0.1004 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 21246: loss = 0.0463 (0.301 sec/step)\n",
            "I0923 10:17:40.477554 139631849019264 learning.py:507] global step 21246: loss = 0.0463 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 21247: loss = 0.0802 (0.297 sec/step)\n",
            "I0923 10:17:40.775983 139631849019264 learning.py:507] global step 21247: loss = 0.0802 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 21248: loss = 0.0969 (0.369 sec/step)\n",
            "I0923 10:17:41.147004 139631849019264 learning.py:507] global step 21248: loss = 0.0969 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 21249: loss = 0.2918 (0.313 sec/step)\n",
            "I0923 10:17:41.462178 139631849019264 learning.py:507] global step 21249: loss = 0.2918 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 21250: loss = 0.2087 (0.297 sec/step)\n",
            "I0923 10:17:41.760487 139631849019264 learning.py:507] global step 21250: loss = 0.2087 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 21251: loss = 0.1216 (0.344 sec/step)\n",
            "I0923 10:17:42.106253 139631849019264 learning.py:507] global step 21251: loss = 0.1216 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 21252: loss = 0.0724 (0.339 sec/step)\n",
            "I0923 10:17:42.446980 139631849019264 learning.py:507] global step 21252: loss = 0.0724 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 21253: loss = 0.0270 (0.280 sec/step)\n",
            "I0923 10:17:42.729206 139631849019264 learning.py:507] global step 21253: loss = 0.0270 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 21254: loss = 0.0573 (0.338 sec/step)\n",
            "I0923 10:17:43.068729 139631849019264 learning.py:507] global step 21254: loss = 0.0573 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 21255: loss = 0.1025 (0.339 sec/step)\n",
            "I0923 10:17:43.409871 139631849019264 learning.py:507] global step 21255: loss = 0.1025 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 21256: loss = 0.2014 (0.334 sec/step)\n",
            "I0923 10:17:43.745829 139631849019264 learning.py:507] global step 21256: loss = 0.2014 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 21257: loss = 0.0545 (0.288 sec/step)\n",
            "I0923 10:17:44.035924 139631849019264 learning.py:507] global step 21257: loss = 0.0545 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 21258: loss = 0.0407 (0.355 sec/step)\n",
            "I0923 10:17:44.393036 139631849019264 learning.py:507] global step 21258: loss = 0.0407 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 21259: loss = 0.0392 (0.284 sec/step)\n",
            "I0923 10:17:44.679184 139631849019264 learning.py:507] global step 21259: loss = 0.0392 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 21260: loss = 0.1877 (0.371 sec/step)\n",
            "I0923 10:17:45.052687 139631849019264 learning.py:507] global step 21260: loss = 0.1877 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 21261: loss = 0.0774 (0.348 sec/step)\n",
            "I0923 10:17:45.402389 139631849019264 learning.py:507] global step 21261: loss = 0.0774 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 21262: loss = 0.0882 (0.318 sec/step)\n",
            "I0923 10:17:45.722277 139631849019264 learning.py:507] global step 21262: loss = 0.0882 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 21263: loss = 0.0555 (0.286 sec/step)\n",
            "I0923 10:17:46.009764 139631849019264 learning.py:507] global step 21263: loss = 0.0555 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 21264: loss = 0.0884 (0.287 sec/step)\n",
            "I0923 10:17:46.298581 139631849019264 learning.py:507] global step 21264: loss = 0.0884 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 21265: loss = 0.1114 (0.343 sec/step)\n",
            "I0923 10:17:46.644037 139631849019264 learning.py:507] global step 21265: loss = 0.1114 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 21266: loss = 0.0816 (0.289 sec/step)\n",
            "I0923 10:17:46.935247 139631849019264 learning.py:507] global step 21266: loss = 0.0816 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 21267: loss = 0.0412 (0.334 sec/step)\n",
            "I0923 10:17:47.270823 139631849019264 learning.py:507] global step 21267: loss = 0.0412 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 21268: loss = 0.2724 (0.315 sec/step)\n",
            "I0923 10:17:47.587330 139631849019264 learning.py:507] global step 21268: loss = 0.2724 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 21269: loss = 0.0428 (0.356 sec/step)\n",
            "I0923 10:17:47.949450 139631849019264 learning.py:507] global step 21269: loss = 0.0428 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 21270: loss = 0.0620 (0.324 sec/step)\n",
            "I0923 10:17:48.275815 139631849019264 learning.py:507] global step 21270: loss = 0.0620 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 21271: loss = 0.0527 (0.343 sec/step)\n",
            "I0923 10:17:48.620152 139631849019264 learning.py:507] global step 21271: loss = 0.0527 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 21272: loss = 0.0294 (0.312 sec/step)\n",
            "I0923 10:17:48.933938 139631849019264 learning.py:507] global step 21272: loss = 0.0294 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 21273: loss = 0.0518 (0.337 sec/step)\n",
            "I0923 10:17:49.273216 139631849019264 learning.py:507] global step 21273: loss = 0.0518 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 21274: loss = 0.1223 (0.299 sec/step)\n",
            "I0923 10:17:49.574077 139631849019264 learning.py:507] global step 21274: loss = 0.1223 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 21275: loss = 0.1077 (0.295 sec/step)\n",
            "I0923 10:17:49.871258 139631849019264 learning.py:507] global step 21275: loss = 0.1077 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 21276: loss = 0.1852 (0.328 sec/step)\n",
            "I0923 10:17:50.201744 139631849019264 learning.py:507] global step 21276: loss = 0.1852 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 21277: loss = 0.0875 (0.340 sec/step)\n",
            "I0923 10:17:50.543204 139631849019264 learning.py:507] global step 21277: loss = 0.0875 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 21278: loss = 0.2716 (0.324 sec/step)\n",
            "I0923 10:17:50.868815 139631849019264 learning.py:507] global step 21278: loss = 0.2716 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 21279: loss = 0.2707 (0.288 sec/step)\n",
            "I0923 10:17:51.158548 139631849019264 learning.py:507] global step 21279: loss = 0.2707 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 21280: loss = 0.0910 (0.285 sec/step)\n",
            "I0923 10:17:51.445522 139631849019264 learning.py:507] global step 21280: loss = 0.0910 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 21281: loss = 0.3199 (0.313 sec/step)\n",
            "I0923 10:17:51.760321 139631849019264 learning.py:507] global step 21281: loss = 0.3199 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 21282: loss = 0.2626 (0.339 sec/step)\n",
            "I0923 10:17:52.101480 139631849019264 learning.py:507] global step 21282: loss = 0.2626 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 21283: loss = 0.1950 (0.295 sec/step)\n",
            "I0923 10:17:52.398583 139631849019264 learning.py:507] global step 21283: loss = 0.1950 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 21284: loss = 0.0575 (0.279 sec/step)\n",
            "I0923 10:17:52.679765 139631849019264 learning.py:507] global step 21284: loss = 0.0575 (0.279 sec/step)\n",
            "INFO:tensorflow:global step 21285: loss = 0.0983 (0.305 sec/step)\n",
            "I0923 10:17:52.986746 139631849019264 learning.py:507] global step 21285: loss = 0.0983 (0.305 sec/step)\n",
            "INFO:tensorflow:global step 21286: loss = 0.0673 (0.289 sec/step)\n",
            "I0923 10:17:53.277982 139631849019264 learning.py:507] global step 21286: loss = 0.0673 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 21287: loss = 0.0282 (0.324 sec/step)\n",
            "I0923 10:17:53.603854 139631849019264 learning.py:507] global step 21287: loss = 0.0282 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 21288: loss = 0.0516 (0.353 sec/step)\n",
            "I0923 10:17:53.958782 139631849019264 learning.py:507] global step 21288: loss = 0.0516 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 21289: loss = 0.1166 (0.285 sec/step)\n",
            "I0923 10:17:54.245254 139631849019264 learning.py:507] global step 21289: loss = 0.1166 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 21290: loss = 0.0453 (0.271 sec/step)\n",
            "I0923 10:17:54.518173 139631849019264 learning.py:507] global step 21290: loss = 0.0453 (0.271 sec/step)\n",
            "INFO:tensorflow:global step 21291: loss = 0.1705 (0.319 sec/step)\n",
            "I0923 10:17:54.839169 139631849019264 learning.py:507] global step 21291: loss = 0.1705 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 21292: loss = 0.0809 (0.298 sec/step)\n",
            "I0923 10:17:55.138936 139631849019264 learning.py:507] global step 21292: loss = 0.0809 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 21293: loss = 0.0397 (0.285 sec/step)\n",
            "I0923 10:17:55.425493 139631849019264 learning.py:507] global step 21293: loss = 0.0397 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 21294: loss = 0.1250 (0.331 sec/step)\n",
            "I0923 10:17:55.757636 139631849019264 learning.py:507] global step 21294: loss = 0.1250 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 21295: loss = 0.0599 (0.283 sec/step)\n",
            "I0923 10:17:56.042606 139631849019264 learning.py:507] global step 21295: loss = 0.0599 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 21296: loss = 0.0626 (0.297 sec/step)\n",
            "I0923 10:17:56.341835 139631849019264 learning.py:507] global step 21296: loss = 0.0626 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 21297: loss = 0.1433 (0.295 sec/step)\n",
            "I0923 10:17:56.638289 139631849019264 learning.py:507] global step 21297: loss = 0.1433 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 21298: loss = 0.0644 (0.315 sec/step)\n",
            "I0923 10:17:56.955461 139631849019264 learning.py:507] global step 21298: loss = 0.0644 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 21299: loss = 0.0811 (0.353 sec/step)\n",
            "I0923 10:17:57.310865 139631849019264 learning.py:507] global step 21299: loss = 0.0811 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 21300: loss = 0.0846 (0.277 sec/step)\n",
            "I0923 10:17:57.589788 139631849019264 learning.py:507] global step 21300: loss = 0.0846 (0.277 sec/step)\n",
            "INFO:tensorflow:global step 21301: loss = 0.0646 (0.281 sec/step)\n",
            "I0923 10:17:57.875584 139631849019264 learning.py:507] global step 21301: loss = 0.0646 (0.281 sec/step)\n",
            "INFO:tensorflow:global step 21302: loss = 0.0848 (0.341 sec/step)\n",
            "I0923 10:17:58.218646 139631849019264 learning.py:507] global step 21302: loss = 0.0848 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 21303: loss = 0.0881 (0.298 sec/step)\n",
            "I0923 10:17:58.518554 139631849019264 learning.py:507] global step 21303: loss = 0.0881 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 21304: loss = 0.1581 (0.283 sec/step)\n",
            "I0923 10:17:58.803878 139631849019264 learning.py:507] global step 21304: loss = 0.1581 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 21305: loss = 0.0810 (0.320 sec/step)\n",
            "I0923 10:17:59.125276 139631849019264 learning.py:507] global step 21305: loss = 0.0810 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 21306: loss = 0.1153 (0.289 sec/step)\n",
            "I0923 10:17:59.416287 139631849019264 learning.py:507] global step 21306: loss = 0.1153 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 21307: loss = 0.0869 (0.290 sec/step)\n",
            "I0923 10:17:59.708007 139631849019264 learning.py:507] global step 21307: loss = 0.0869 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 21308: loss = 0.0912 (0.379 sec/step)\n",
            "I0923 10:18:00.089303 139631849019264 learning.py:507] global step 21308: loss = 0.0912 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 21309: loss = 0.0328 (0.269 sec/step)\n",
            "I0923 10:18:00.359983 139631849019264 learning.py:507] global step 21309: loss = 0.0328 (0.269 sec/step)\n",
            "INFO:tensorflow:global step 21310: loss = 0.0616 (0.270 sec/step)\n",
            "I0923 10:18:00.632295 139631849019264 learning.py:507] global step 21310: loss = 0.0616 (0.270 sec/step)\n",
            "INFO:tensorflow:global step 21311: loss = 0.0597 (0.288 sec/step)\n",
            "I0923 10:18:00.922429 139631849019264 learning.py:507] global step 21311: loss = 0.0597 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 21312: loss = 0.0405 (0.364 sec/step)\n",
            "I0923 10:18:01.288028 139631849019264 learning.py:507] global step 21312: loss = 0.0405 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 21313: loss = 0.4291 (0.303 sec/step)\n",
            "I0923 10:18:01.592516 139631849019264 learning.py:507] global step 21313: loss = 0.4291 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 21314: loss = 0.1453 (0.334 sec/step)\n",
            "I0923 10:18:01.928855 139631849019264 learning.py:507] global step 21314: loss = 0.1453 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 21315: loss = 0.1393 (0.330 sec/step)\n",
            "I0923 10:18:02.260190 139631849019264 learning.py:507] global step 21315: loss = 0.1393 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 21316: loss = 0.1283 (0.286 sec/step)\n",
            "I0923 10:18:02.548040 139631849019264 learning.py:507] global step 21316: loss = 0.1283 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 21317: loss = 0.0485 (0.325 sec/step)\n",
            "I0923 10:18:02.874941 139631849019264 learning.py:507] global step 21317: loss = 0.0485 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 21318: loss = 0.0608 (0.341 sec/step)\n",
            "I0923 10:18:03.218130 139631849019264 learning.py:507] global step 21318: loss = 0.0608 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 21319: loss = 0.0472 (0.304 sec/step)\n",
            "I0923 10:18:03.524181 139631849019264 learning.py:507] global step 21319: loss = 0.0472 (0.304 sec/step)\n",
            "INFO:tensorflow:global step 21320: loss = 0.0736 (0.329 sec/step)\n",
            "I0923 10:18:03.854764 139631849019264 learning.py:507] global step 21320: loss = 0.0736 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 21321: loss = 0.0669 (0.300 sec/step)\n",
            "I0923 10:18:04.156883 139631849019264 learning.py:507] global step 21321: loss = 0.0669 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 21322: loss = 0.0892 (0.329 sec/step)\n",
            "I0923 10:18:04.487352 139631849019264 learning.py:507] global step 21322: loss = 0.0892 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 21323: loss = 0.0734 (0.355 sec/step)\n",
            "I0923 10:18:04.844708 139631849019264 learning.py:507] global step 21323: loss = 0.0734 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 21324: loss = 0.1444 (0.287 sec/step)\n",
            "I0923 10:18:05.133460 139631849019264 learning.py:507] global step 21324: loss = 0.1444 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 21325: loss = 0.0503 (0.318 sec/step)\n",
            "I0923 10:18:05.452998 139631849019264 learning.py:507] global step 21325: loss = 0.0503 (0.318 sec/step)\n",
            "INFO:tensorflow:global step 21326: loss = 0.0437 (0.328 sec/step)\n",
            "I0923 10:18:05.783271 139631849019264 learning.py:507] global step 21326: loss = 0.0437 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 21327: loss = 0.0451 (0.317 sec/step)\n",
            "I0923 10:18:06.102048 139631849019264 learning.py:507] global step 21327: loss = 0.0451 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 21328: loss = 0.1820 (0.294 sec/step)\n",
            "I0923 10:18:06.397570 139631849019264 learning.py:507] global step 21328: loss = 0.1820 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 21329: loss = 0.1804 (0.372 sec/step)\n",
            "I0923 10:18:06.771202 139631849019264 learning.py:507] global step 21329: loss = 0.1804 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 21330: loss = 0.0739 (0.300 sec/step)\n",
            "I0923 10:18:07.073756 139631849019264 learning.py:507] global step 21330: loss = 0.0739 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 21331: loss = 0.0321 (0.329 sec/step)\n",
            "I0923 10:18:07.404859 139631849019264 learning.py:507] global step 21331: loss = 0.0321 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 21332: loss = 0.0817 (0.286 sec/step)\n",
            "I0923 10:18:07.692888 139631849019264 learning.py:507] global step 21332: loss = 0.0817 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 21333: loss = 0.0472 (0.315 sec/step)\n",
            "I0923 10:18:08.009738 139631849019264 learning.py:507] global step 21333: loss = 0.0472 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 21334: loss = 0.1972 (0.294 sec/step)\n",
            "I0923 10:18:08.305685 139631849019264 learning.py:507] global step 21334: loss = 0.1972 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 21335: loss = 0.0540 (0.329 sec/step)\n",
            "I0923 10:18:08.636989 139631849019264 learning.py:507] global step 21335: loss = 0.0540 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 21336: loss = 0.0776 (0.361 sec/step)\n",
            "I0923 10:18:08.999763 139631849019264 learning.py:507] global step 21336: loss = 0.0776 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 21337: loss = 0.0445 (0.335 sec/step)\n",
            "I0923 10:18:09.336822 139631849019264 learning.py:507] global step 21337: loss = 0.0445 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 21338: loss = 0.0659 (0.291 sec/step)\n",
            "I0923 10:18:09.629555 139631849019264 learning.py:507] global step 21338: loss = 0.0659 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 21339: loss = 0.0712 (0.326 sec/step)\n",
            "I0923 10:18:09.957537 139631849019264 learning.py:507] global step 21339: loss = 0.0712 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 21340: loss = 0.0591 (0.292 sec/step)\n",
            "I0923 10:18:10.250851 139631849019264 learning.py:507] global step 21340: loss = 0.0591 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 21341: loss = 0.0896 (0.312 sec/step)\n",
            "I0923 10:18:10.564591 139631849019264 learning.py:507] global step 21341: loss = 0.0896 (0.312 sec/step)\n",
            "INFO:tensorflow:global step 21342: loss = 0.3646 (0.311 sec/step)\n",
            "I0923 10:18:10.877307 139631849019264 learning.py:507] global step 21342: loss = 0.3646 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 21343: loss = 0.0594 (0.327 sec/step)\n",
            "I0923 10:18:11.206443 139631849019264 learning.py:507] global step 21343: loss = 0.0594 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 21344: loss = 0.0675 (0.347 sec/step)\n",
            "I0923 10:18:11.555194 139631849019264 learning.py:507] global step 21344: loss = 0.0675 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 21345: loss = 0.1313 (0.299 sec/step)\n",
            "I0923 10:18:11.855873 139631849019264 learning.py:507] global step 21345: loss = 0.1313 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 21346: loss = 0.0337 (0.313 sec/step)\n",
            "I0923 10:18:12.170509 139631849019264 learning.py:507] global step 21346: loss = 0.0337 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 21347: loss = 0.0573 (0.362 sec/step)\n",
            "I0923 10:18:12.534538 139631849019264 learning.py:507] global step 21347: loss = 0.0573 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 21348: loss = 0.0787 (0.342 sec/step)\n",
            "I0923 10:18:12.878248 139631849019264 learning.py:507] global step 21348: loss = 0.0787 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 21349: loss = 0.0418 (0.293 sec/step)\n",
            "I0923 10:18:13.172989 139631849019264 learning.py:507] global step 21349: loss = 0.0418 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 21350: loss = 0.0234 (0.311 sec/step)\n",
            "I0923 10:18:13.486124 139631849019264 learning.py:507] global step 21350: loss = 0.0234 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 21351: loss = 0.2412 (0.335 sec/step)\n",
            "I0923 10:18:13.823346 139631849019264 learning.py:507] global step 21351: loss = 0.2412 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 21352: loss = 0.0867 (0.341 sec/step)\n",
            "I0923 10:18:14.166136 139631849019264 learning.py:507] global step 21352: loss = 0.0867 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 21353: loss = 0.1622 (0.286 sec/step)\n",
            "I0923 10:18:14.453240 139631849019264 learning.py:507] global step 21353: loss = 0.1622 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 21354: loss = 0.1195 (0.344 sec/step)\n",
            "I0923 10:18:14.798799 139631849019264 learning.py:507] global step 21354: loss = 0.1195 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 21355: loss = 0.0623 (0.303 sec/step)\n",
            "I0923 10:18:15.103333 139631849019264 learning.py:507] global step 21355: loss = 0.0623 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 21356: loss = 0.0910 (0.355 sec/step)\n",
            "I0923 10:18:15.460652 139631849019264 learning.py:507] global step 21356: loss = 0.0910 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 21357: loss = 0.0688 (0.329 sec/step)\n",
            "I0923 10:18:15.791717 139631849019264 learning.py:507] global step 21357: loss = 0.0688 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 21358: loss = 0.1145 (0.288 sec/step)\n",
            "I0923 10:18:16.082130 139631849019264 learning.py:507] global step 21358: loss = 0.1145 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 21359: loss = 0.0396 (0.334 sec/step)\n",
            "I0923 10:18:16.419633 139631849019264 learning.py:507] global step 21359: loss = 0.0396 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 21360: loss = 0.0424 (0.395 sec/step)\n",
            "I0923 10:18:16.817088 139631849019264 learning.py:507] global step 21360: loss = 0.0424 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 21361: loss = 0.0423 (0.293 sec/step)\n",
            "I0923 10:18:17.112365 139631849019264 learning.py:507] global step 21361: loss = 0.0423 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 21362: loss = 0.1261 (0.337 sec/step)\n",
            "I0923 10:18:17.451112 139631849019264 learning.py:507] global step 21362: loss = 0.1261 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 21363: loss = 0.0323 (0.291 sec/step)\n",
            "I0923 10:18:17.743506 139631849019264 learning.py:507] global step 21363: loss = 0.0323 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 21364: loss = 0.0977 (0.276 sec/step)\n",
            "I0923 10:18:18.026115 139631849019264 learning.py:507] global step 21364: loss = 0.0977 (0.276 sec/step)\n",
            "INFO:tensorflow:global step 21365: loss = 0.0932 (0.395 sec/step)\n",
            "I0923 10:18:18.438398 139631849019264 learning.py:507] global step 21365: loss = 0.0932 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 21366: loss = 0.0820 (0.434 sec/step)\n",
            "I0923 10:18:18.882442 139631849019264 learning.py:507] global step 21366: loss = 0.0820 (0.434 sec/step)\n",
            "INFO:tensorflow:global step 21367: loss = 0.0562 (0.448 sec/step)\n",
            "I0923 10:18:19.333190 139631849019264 learning.py:507] global step 21367: loss = 0.0562 (0.448 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 21367.\n",
            "I0923 10:18:19.386006 139628630939392 supervisor.py:1050] Recording summary at step 21367.\n",
            "INFO:tensorflow:global step 21368: loss = 0.0916 (0.360 sec/step)\n",
            "I0923 10:18:19.698467 139631849019264 learning.py:507] global step 21368: loss = 0.0916 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 21369: loss = 0.0501 (0.316 sec/step)\n",
            "I0923 10:18:20.015996 139631849019264 learning.py:507] global step 21369: loss = 0.0501 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 21370: loss = 0.0984 (0.328 sec/step)\n",
            "I0923 10:18:20.345903 139631849019264 learning.py:507] global step 21370: loss = 0.0984 (0.328 sec/step)\n",
            "INFO:tensorflow:global step 21371: loss = 0.1054 (0.313 sec/step)\n",
            "I0923 10:18:20.661626 139631849019264 learning.py:507] global step 21371: loss = 0.1054 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 21372: loss = 0.0461 (0.341 sec/step)\n",
            "I0923 10:18:21.004228 139631849019264 learning.py:507] global step 21372: loss = 0.0461 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 21373: loss = 0.1030 (0.325 sec/step)\n",
            "I0923 10:18:21.331499 139631849019264 learning.py:507] global step 21373: loss = 0.1030 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 21374: loss = 0.1201 (0.321 sec/step)\n",
            "I0923 10:18:21.654579 139631849019264 learning.py:507] global step 21374: loss = 0.1201 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 21375: loss = 0.1241 (0.340 sec/step)\n",
            "I0923 10:18:21.996749 139631849019264 learning.py:507] global step 21375: loss = 0.1241 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 21376: loss = 0.0798 (0.333 sec/step)\n",
            "I0923 10:18:22.331803 139631849019264 learning.py:507] global step 21376: loss = 0.0798 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 21377: loss = 0.2529 (0.300 sec/step)\n",
            "I0923 10:18:22.633856 139631849019264 learning.py:507] global step 21377: loss = 0.2529 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 21378: loss = 0.0918 (0.291 sec/step)\n",
            "I0923 10:18:22.927134 139631849019264 learning.py:507] global step 21378: loss = 0.0918 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 21379: loss = 0.0877 (0.288 sec/step)\n",
            "I0923 10:18:23.217043 139631849019264 learning.py:507] global step 21379: loss = 0.0877 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 21380: loss = 0.0906 (0.277 sec/step)\n",
            "I0923 10:18:23.495775 139631849019264 learning.py:507] global step 21380: loss = 0.0906 (0.277 sec/step)\n",
            "INFO:tensorflow:global step 21381: loss = 0.0385 (0.341 sec/step)\n",
            "I0923 10:18:23.838423 139631849019264 learning.py:507] global step 21381: loss = 0.0385 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 21382: loss = 0.0582 (0.325 sec/step)\n",
            "I0923 10:18:24.164780 139631849019264 learning.py:507] global step 21382: loss = 0.0582 (0.325 sec/step)\n",
            "INFO:tensorflow:global step 21383: loss = 0.1095 (0.291 sec/step)\n",
            "I0923 10:18:24.458034 139631849019264 learning.py:507] global step 21383: loss = 0.1095 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 21384: loss = 0.1211 (0.297 sec/step)\n",
            "I0923 10:18:24.756607 139631849019264 learning.py:507] global step 21384: loss = 0.1211 (0.297 sec/step)\n",
            "INFO:tensorflow:global step 21385: loss = 0.1746 (0.298 sec/step)\n",
            "I0923 10:18:25.056787 139631849019264 learning.py:507] global step 21385: loss = 0.1746 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 21386: loss = 0.0581 (0.299 sec/step)\n",
            "I0923 10:18:25.357408 139631849019264 learning.py:507] global step 21386: loss = 0.0581 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 21387: loss = 0.0681 (0.311 sec/step)\n",
            "I0923 10:18:25.670033 139631849019264 learning.py:507] global step 21387: loss = 0.0681 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 21388: loss = 0.1102 (0.294 sec/step)\n",
            "I0923 10:18:25.966305 139631849019264 learning.py:507] global step 21388: loss = 0.1102 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 21389: loss = 0.0698 (0.289 sec/step)\n",
            "I0923 10:18:26.257142 139631849019264 learning.py:507] global step 21389: loss = 0.0698 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 21390: loss = 0.0988 (0.338 sec/step)\n",
            "I0923 10:18:26.596689 139631849019264 learning.py:507] global step 21390: loss = 0.0988 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 21391: loss = 0.0863 (0.282 sec/step)\n",
            "I0923 10:18:26.883153 139631849019264 learning.py:507] global step 21391: loss = 0.0863 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 21392: loss = 0.1615 (0.317 sec/step)\n",
            "I0923 10:18:27.202685 139631849019264 learning.py:507] global step 21392: loss = 0.1615 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 21393: loss = 0.1474 (0.311 sec/step)\n",
            "I0923 10:18:27.515489 139631849019264 learning.py:507] global step 21393: loss = 0.1474 (0.311 sec/step)\n",
            "INFO:tensorflow:global step 21394: loss = 0.0523 (0.337 sec/step)\n",
            "I0923 10:18:27.854484 139631849019264 learning.py:507] global step 21394: loss = 0.0523 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 21395: loss = 0.0766 (0.321 sec/step)\n",
            "I0923 10:18:28.177567 139631849019264 learning.py:507] global step 21395: loss = 0.0766 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 21396: loss = 0.1498 (0.329 sec/step)\n",
            "I0923 10:18:28.508688 139631849019264 learning.py:507] global step 21396: loss = 0.1498 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 21397: loss = 0.0666 (0.357 sec/step)\n",
            "I0923 10:18:28.868683 139631849019264 learning.py:507] global step 21397: loss = 0.0666 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 21398: loss = 0.0349 (0.310 sec/step)\n",
            "I0923 10:18:29.180588 139631849019264 learning.py:507] global step 21398: loss = 0.0349 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 21399: loss = 0.0396 (0.300 sec/step)\n",
            "I0923 10:18:29.482276 139631849019264 learning.py:507] global step 21399: loss = 0.0396 (0.300 sec/step)\n",
            "INFO:tensorflow:global step 21400: loss = 0.0889 (0.282 sec/step)\n",
            "I0923 10:18:29.765928 139631849019264 learning.py:507] global step 21400: loss = 0.0889 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 21401: loss = 0.0753 (0.303 sec/step)\n",
            "I0923 10:18:30.071856 139631849019264 learning.py:507] global step 21401: loss = 0.0753 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 21402: loss = 0.0388 (0.292 sec/step)\n",
            "I0923 10:18:30.368419 139631849019264 learning.py:507] global step 21402: loss = 0.0388 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 21403: loss = 0.1041 (0.279 sec/step)\n",
            "I0923 10:18:30.649098 139631849019264 learning.py:507] global step 21403: loss = 0.1041 (0.279 sec/step)\n",
            "INFO:tensorflow:global step 21404: loss = 0.1141 (0.292 sec/step)\n",
            "I0923 10:18:30.943433 139631849019264 learning.py:507] global step 21404: loss = 0.1141 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 21405: loss = 0.1796 (0.349 sec/step)\n",
            "I0923 10:18:31.294405 139631849019264 learning.py:507] global step 21405: loss = 0.1796 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 21406: loss = 0.0583 (0.303 sec/step)\n",
            "I0923 10:18:31.599849 139631849019264 learning.py:507] global step 21406: loss = 0.0583 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 21407: loss = 0.0497 (0.342 sec/step)\n",
            "I0923 10:18:31.944138 139631849019264 learning.py:507] global step 21407: loss = 0.0497 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 21408: loss = 0.1185 (0.331 sec/step)\n",
            "I0923 10:18:32.277493 139631849019264 learning.py:507] global step 21408: loss = 0.1185 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 21409: loss = 0.2468 (0.287 sec/step)\n",
            "I0923 10:18:32.566920 139631849019264 learning.py:507] global step 21409: loss = 0.2468 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 21410: loss = 0.1339 (0.314 sec/step)\n",
            "I0923 10:18:32.883114 139631849019264 learning.py:507] global step 21410: loss = 0.1339 (0.314 sec/step)\n",
            "INFO:tensorflow:global step 21411: loss = 0.1951 (0.339 sec/step)\n",
            "I0923 10:18:33.224089 139631849019264 learning.py:507] global step 21411: loss = 0.1951 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 21412: loss = 0.0918 (0.346 sec/step)\n",
            "I0923 10:18:33.572217 139631849019264 learning.py:507] global step 21412: loss = 0.0918 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 21413: loss = 0.0919 (0.316 sec/step)\n",
            "I0923 10:18:33.889767 139631849019264 learning.py:507] global step 21413: loss = 0.0919 (0.316 sec/step)\n",
            "INFO:tensorflow:global step 21414: loss = 0.0494 (0.332 sec/step)\n",
            "I0923 10:18:34.223845 139631849019264 learning.py:507] global step 21414: loss = 0.0494 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 21415: loss = 0.1371 (0.345 sec/step)\n",
            "I0923 10:18:34.571249 139631849019264 learning.py:507] global step 21415: loss = 0.1371 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 21416: loss = 0.0378 (0.299 sec/step)\n",
            "I0923 10:18:34.872389 139631849019264 learning.py:507] global step 21416: loss = 0.0378 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 21417: loss = 0.1530 (0.330 sec/step)\n",
            "I0923 10:18:35.204053 139631849019264 learning.py:507] global step 21417: loss = 0.1530 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 21418: loss = 0.1217 (0.298 sec/step)\n",
            "I0923 10:18:35.503457 139631849019264 learning.py:507] global step 21418: loss = 0.1217 (0.298 sec/step)\n",
            "INFO:tensorflow:global step 21419: loss = 0.0622 (0.329 sec/step)\n",
            "I0923 10:18:35.834493 139631849019264 learning.py:507] global step 21419: loss = 0.0622 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 21420: loss = 0.1495 (0.319 sec/step)\n",
            "I0923 10:18:36.155738 139631849019264 learning.py:507] global step 21420: loss = 0.1495 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 21421: loss = 0.1224 (0.292 sec/step)\n",
            "I0923 10:18:36.449604 139631849019264 learning.py:507] global step 21421: loss = 0.1224 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 21422: loss = 0.0359 (0.301 sec/step)\n",
            "I0923 10:18:36.751908 139631849019264 learning.py:507] global step 21422: loss = 0.0359 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 21423: loss = 0.1224 (0.383 sec/step)\n",
            "I0923 10:18:37.136346 139631849019264 learning.py:507] global step 21423: loss = 0.1224 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 21424: loss = 0.0431 (0.309 sec/step)\n",
            "I0923 10:18:37.447300 139631849019264 learning.py:507] global step 21424: loss = 0.0431 (0.309 sec/step)\n",
            "INFO:tensorflow:global step 21425: loss = 0.0781 (0.357 sec/step)\n",
            "I0923 10:18:37.806109 139631849019264 learning.py:507] global step 21425: loss = 0.0781 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 21426: loss = 0.0713 (0.333 sec/step)\n",
            "I0923 10:18:38.141206 139631849019264 learning.py:507] global step 21426: loss = 0.0713 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 21427: loss = 0.1402 (0.337 sec/step)\n",
            "I0923 10:18:38.480517 139631849019264 learning.py:507] global step 21427: loss = 0.1402 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 21428: loss = 0.0615 (0.329 sec/step)\n",
            "I0923 10:18:38.810717 139631849019264 learning.py:507] global step 21428: loss = 0.0615 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 21429: loss = 0.1433 (0.323 sec/step)\n",
            "I0923 10:18:39.136307 139631849019264 learning.py:507] global step 21429: loss = 0.1433 (0.323 sec/step)\n",
            "INFO:tensorflow:global step 21430: loss = 0.0716 (0.344 sec/step)\n",
            "I0923 10:18:39.482400 139631849019264 learning.py:507] global step 21430: loss = 0.0716 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 21431: loss = 0.0767 (0.345 sec/step)\n",
            "I0923 10:18:39.829968 139631849019264 learning.py:507] global step 21431: loss = 0.0767 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 21432: loss = 0.1197 (0.310 sec/step)\n",
            "I0923 10:18:40.141495 139631849019264 learning.py:507] global step 21432: loss = 0.1197 (0.310 sec/step)\n",
            "INFO:tensorflow:global step 21433: loss = 0.0793 (0.338 sec/step)\n",
            "I0923 10:18:40.481220 139631849019264 learning.py:507] global step 21433: loss = 0.0793 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 21434: loss = 0.0370 (0.294 sec/step)\n",
            "I0923 10:18:40.776735 139631849019264 learning.py:507] global step 21434: loss = 0.0370 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 21435: loss = 0.0934 (0.286 sec/step)\n",
            "I0923 10:18:41.064180 139631849019264 learning.py:507] global step 21435: loss = 0.0934 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 21436: loss = 0.1208 (0.283 sec/step)\n",
            "I0923 10:18:41.349314 139631849019264 learning.py:507] global step 21436: loss = 0.1208 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 21437: loss = 0.1137 (0.280 sec/step)\n",
            "I0923 10:18:41.630674 139631849019264 learning.py:507] global step 21437: loss = 0.1137 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 21438: loss = 0.0908 (0.286 sec/step)\n",
            "I0923 10:18:41.919122 139631849019264 learning.py:507] global step 21438: loss = 0.0908 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 21439: loss = 0.0576 (0.326 sec/step)\n",
            "I0923 10:18:42.246462 139631849019264 learning.py:507] global step 21439: loss = 0.0576 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 21440: loss = 0.1410 (0.340 sec/step)\n",
            "I0923 10:18:42.588438 139631849019264 learning.py:507] global step 21440: loss = 0.1410 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 21441: loss = 0.2473 (0.327 sec/step)\n",
            "I0923 10:18:42.917190 139631849019264 learning.py:507] global step 21441: loss = 0.2473 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 21442: loss = 0.0955 (0.291 sec/step)\n",
            "I0923 10:18:43.210224 139631849019264 learning.py:507] global step 21442: loss = 0.0955 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 21443: loss = 0.0637 (0.296 sec/step)\n",
            "I0923 10:18:43.508865 139631849019264 learning.py:507] global step 21443: loss = 0.0637 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 21444: loss = 0.1280 (0.320 sec/step)\n",
            "I0923 10:18:43.832191 139631849019264 learning.py:507] global step 21444: loss = 0.1280 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 21445: loss = 0.1259 (0.377 sec/step)\n",
            "I0923 10:18:44.211548 139631849019264 learning.py:507] global step 21445: loss = 0.1259 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 21446: loss = 0.0302 (0.290 sec/step)\n",
            "I0923 10:18:44.503799 139631849019264 learning.py:507] global step 21446: loss = 0.0302 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 21447: loss = 0.0614 (0.296 sec/step)\n",
            "I0923 10:18:44.801241 139631849019264 learning.py:507] global step 21447: loss = 0.0614 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 21448: loss = 0.0380 (0.345 sec/step)\n",
            "I0923 10:18:45.148364 139631849019264 learning.py:507] global step 21448: loss = 0.0380 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 21449: loss = 0.0731 (0.285 sec/step)\n",
            "I0923 10:18:45.435147 139631849019264 learning.py:507] global step 21449: loss = 0.0731 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 21450: loss = 0.4073 (0.321 sec/step)\n",
            "I0923 10:18:45.758127 139631849019264 learning.py:507] global step 21450: loss = 0.4073 (0.321 sec/step)\n",
            "INFO:tensorflow:global step 21451: loss = 0.0772 (0.330 sec/step)\n",
            "I0923 10:18:46.090203 139631849019264 learning.py:507] global step 21451: loss = 0.0772 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 21452: loss = 0.0692 (0.331 sec/step)\n",
            "I0923 10:18:46.422976 139631849019264 learning.py:507] global step 21452: loss = 0.0692 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 21453: loss = 0.0800 (0.295 sec/step)\n",
            "I0923 10:18:46.719982 139631849019264 learning.py:507] global step 21453: loss = 0.0800 (0.295 sec/step)\n",
            "INFO:tensorflow:global step 21454: loss = 0.0820 (0.324 sec/step)\n",
            "I0923 10:18:47.045692 139631849019264 learning.py:507] global step 21454: loss = 0.0820 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 21455: loss = 0.0658 (0.280 sec/step)\n",
            "I0923 10:18:47.328176 139631849019264 learning.py:507] global step 21455: loss = 0.0658 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 21456: loss = 0.0716 (0.279 sec/step)\n",
            "I0923 10:18:47.609248 139631849019264 learning.py:507] global step 21456: loss = 0.0716 (0.279 sec/step)\n",
            "INFO:tensorflow:global step 21457: loss = 0.0642 (0.341 sec/step)\n",
            "I0923 10:18:47.952176 139631849019264 learning.py:507] global step 21457: loss = 0.0642 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 21458: loss = 0.1030 (0.289 sec/step)\n",
            "I0923 10:18:48.243647 139631849019264 learning.py:507] global step 21458: loss = 0.1030 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 21459: loss = 0.1138 (0.333 sec/step)\n",
            "I0923 10:18:48.578288 139631849019264 learning.py:507] global step 21459: loss = 0.1138 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 21460: loss = 0.0541 (0.335 sec/step)\n",
            "I0923 10:18:48.914966 139631849019264 learning.py:507] global step 21460: loss = 0.0541 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 21461: loss = 0.0770 (0.296 sec/step)\n",
            "I0923 10:18:49.212165 139631849019264 learning.py:507] global step 21461: loss = 0.0770 (0.296 sec/step)\n",
            "INFO:tensorflow:global step 21462: loss = 0.0440 (0.284 sec/step)\n",
            "I0923 10:18:49.497636 139631849019264 learning.py:507] global step 21462: loss = 0.0440 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 21463: loss = 0.0577 (0.309 sec/step)\n",
            "I0923 10:18:49.808931 139631849019264 learning.py:507] global step 21463: loss = 0.0577 (0.309 sec/step)\n",
            "INFO:tensorflow:global step 21464: loss = 0.0358 (0.278 sec/step)\n",
            "I0923 10:18:50.089484 139631849019264 learning.py:507] global step 21464: loss = 0.0358 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 21465: loss = 0.1054 (0.333 sec/step)\n",
            "I0923 10:18:50.424179 139631849019264 learning.py:507] global step 21465: loss = 0.1054 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 21466: loss = 0.0791 (0.350 sec/step)\n",
            "I0923 10:18:50.775990 139631849019264 learning.py:507] global step 21466: loss = 0.0791 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 21467: loss = 0.2038 (0.308 sec/step)\n",
            "I0923 10:18:51.087908 139631849019264 learning.py:507] global step 21467: loss = 0.2038 (0.308 sec/step)\n",
            "INFO:tensorflow:global step 21468: loss = 0.0416 (0.337 sec/step)\n",
            "I0923 10:18:51.427980 139631849019264 learning.py:507] global step 21468: loss = 0.0416 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 21469: loss = 0.0861 (0.346 sec/step)\n",
            "I0923 10:18:51.775906 139631849019264 learning.py:507] global step 21469: loss = 0.0861 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 21470: loss = 0.1788 (0.326 sec/step)\n",
            "I0923 10:18:52.105173 139631849019264 learning.py:507] global step 21470: loss = 0.1788 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 21471: loss = 0.0652 (0.273 sec/step)\n",
            "I0923 10:18:52.381084 139631849019264 learning.py:507] global step 21471: loss = 0.0652 (0.273 sec/step)\n",
            "INFO:tensorflow:global step 21472: loss = 0.0954 (0.303 sec/step)\n",
            "I0923 10:18:52.686169 139631849019264 learning.py:507] global step 21472: loss = 0.0954 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 21473: loss = 0.1757 (0.306 sec/step)\n",
            "I0923 10:18:52.993746 139631849019264 learning.py:507] global step 21473: loss = 0.1757 (0.306 sec/step)\n",
            "INFO:tensorflow:global step 21474: loss = 0.0889 (0.282 sec/step)\n",
            "I0923 10:18:53.277585 139631849019264 learning.py:507] global step 21474: loss = 0.0889 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 21475: loss = 0.0710 (0.336 sec/step)\n",
            "I0923 10:18:53.615486 139631849019264 learning.py:507] global step 21475: loss = 0.0710 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 21476: loss = 0.0862 (0.345 sec/step)\n",
            "I0923 10:18:53.962411 139631849019264 learning.py:507] global step 21476: loss = 0.0862 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 21477: loss = 0.0537 (0.415 sec/step)\n",
            "I0923 10:18:54.379578 139631849019264 learning.py:507] global step 21477: loss = 0.0537 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 21478: loss = 0.2776 (0.303 sec/step)\n",
            "I0923 10:18:54.684733 139631849019264 learning.py:507] global step 21478: loss = 0.2776 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 21479: loss = 0.0521 (0.324 sec/step)\n",
            "I0923 10:18:55.010666 139631849019264 learning.py:507] global step 21479: loss = 0.0521 (0.324 sec/step)\n",
            "INFO:tensorflow:global step 21480: loss = 0.0772 (0.329 sec/step)\n",
            "I0923 10:18:55.341817 139631849019264 learning.py:507] global step 21480: loss = 0.0772 (0.329 sec/step)\n",
            "INFO:tensorflow:global step 21481: loss = 0.1301 (0.303 sec/step)\n",
            "I0923 10:18:55.646980 139631849019264 learning.py:507] global step 21481: loss = 0.1301 (0.303 sec/step)\n",
            "INFO:tensorflow:global step 21482: loss = 0.1331 (0.333 sec/step)\n",
            "I0923 10:18:55.981592 139631849019264 learning.py:507] global step 21482: loss = 0.1331 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 21483: loss = 0.1420 (0.366 sec/step)\n",
            "I0923 10:18:56.349385 139631849019264 learning.py:507] global step 21483: loss = 0.1420 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 21484: loss = 0.0941 (0.319 sec/step)\n",
            "I0923 10:18:56.670939 139631849019264 learning.py:507] global step 21484: loss = 0.0941 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 21485: loss = 0.0832 (0.346 sec/step)\n",
            "I0923 10:18:57.019092 139631849019264 learning.py:507] global step 21485: loss = 0.0832 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 21486: loss = 0.0305 (0.288 sec/step)\n",
            "I0923 10:18:57.309285 139631849019264 learning.py:507] global step 21486: loss = 0.0305 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 21487: loss = 0.1102 (0.279 sec/step)\n",
            "I0923 10:18:57.589740 139631849019264 learning.py:507] global step 21487: loss = 0.1102 (0.279 sec/step)\n",
            "INFO:tensorflow:global step 21488: loss = 0.1698 (0.293 sec/step)\n",
            "I0923 10:18:57.884876 139631849019264 learning.py:507] global step 21488: loss = 0.1698 (0.293 sec/step)\n",
            "INFO:tensorflow:global step 21489: loss = 0.0688 (0.289 sec/step)\n",
            "I0923 10:18:58.175834 139631849019264 learning.py:507] global step 21489: loss = 0.0688 (0.289 sec/step)\n",
            "INFO:tensorflow:global step 21490: loss = 0.1096 (0.341 sec/step)\n",
            "I0923 10:18:58.518907 139631849019264 learning.py:507] global step 21490: loss = 0.1096 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 21491: loss = 0.0810 (0.292 sec/step)\n",
            "I0923 10:18:58.812747 139631849019264 learning.py:507] global step 21491: loss = 0.0810 (0.292 sec/step)\n",
            "INFO:tensorflow:global step 21492: loss = 0.0351 (0.319 sec/step)\n",
            "I0923 10:18:59.133908 139631849019264 learning.py:507] global step 21492: loss = 0.0351 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 21493: loss = 0.0773 (0.299 sec/step)\n",
            "I0923 10:18:59.434881 139631849019264 learning.py:507] global step 21493: loss = 0.0773 (0.299 sec/step)\n",
            "INFO:tensorflow:global step 21494: loss = 0.3123 (0.315 sec/step)\n",
            "I0923 10:18:59.751964 139631849019264 learning.py:507] global step 21494: loss = 0.3123 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 21495: loss = 0.2051 (0.327 sec/step)\n",
            "I0923 10:19:00.080641 139631849019264 learning.py:507] global step 21495: loss = 0.2051 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 21496: loss = 0.1058 (0.338 sec/step)\n",
            "I0923 10:19:00.421288 139631849019264 learning.py:507] global step 21496: loss = 0.1058 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 21497: loss = 0.0908 (0.283 sec/step)\n",
            "I0923 10:19:00.706334 139631849019264 learning.py:507] global step 21497: loss = 0.0908 (0.283 sec/step)\n",
            "INFO:tensorflow:global step 21498: loss = 0.1689 (0.309 sec/step)\n",
            "I0923 10:19:01.017027 139631849019264 learning.py:507] global step 21498: loss = 0.1689 (0.309 sec/step)\n",
            "INFO:tensorflow:global step 21499: loss = 0.0348 (0.326 sec/step)\n",
            "I0923 10:19:01.344607 139631849019264 learning.py:507] global step 21499: loss = 0.0348 (0.326 sec/step)\n",
            "INFO:tensorflow:global step 21500: loss = 0.0538 (0.343 sec/step)\n",
            "I0923 10:19:01.689973 139631849019264 learning.py:507] global step 21500: loss = 0.0538 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 21501: loss = 0.0598 (0.342 sec/step)\n",
            "I0923 10:19:02.033569 139631849019264 learning.py:507] global step 21501: loss = 0.0598 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 21502: loss = 0.1501 (0.319 sec/step)\n",
            "I0923 10:19:02.354453 139631849019264 learning.py:507] global step 21502: loss = 0.1501 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 21503: loss = 0.0626 (0.331 sec/step)\n",
            "I0923 10:19:02.686898 139631849019264 learning.py:507] global step 21503: loss = 0.0626 (0.331 sec/step)\n",
            "INFO:tensorflow:global step 21504: loss = 0.0908 (0.301 sec/step)\n",
            "I0923 10:19:02.990143 139631849019264 learning.py:507] global step 21504: loss = 0.0908 (0.301 sec/step)\n",
            "INFO:tensorflow:global step 21505: loss = 0.0700 (0.294 sec/step)\n",
            "I0923 10:19:03.286142 139631849019264 learning.py:507] global step 21505: loss = 0.0700 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 21506: loss = 0.2052 (0.290 sec/step)\n",
            "I0923 10:19:03.578049 139631849019264 learning.py:507] global step 21506: loss = 0.2052 (0.290 sec/step)\n",
            "INFO:tensorflow:global step 21507: loss = 0.0577 (0.272 sec/step)\n",
            "I0923 10:19:03.851915 139631849019264 learning.py:507] global step 21507: loss = 0.0577 (0.272 sec/step)\n",
            "INFO:tensorflow:global step 21508: loss = 0.0827 (0.294 sec/step)\n",
            "I0923 10:19:04.147541 139631849019264 learning.py:507] global step 21508: loss = 0.0827 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 21509: loss = 0.0821 (0.335 sec/step)\n",
            "I0923 10:19:04.484780 139631849019264 learning.py:507] global step 21509: loss = 0.0821 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 21510: loss = 0.0436 (0.291 sec/step)\n",
            "I0923 10:19:04.777726 139631849019264 learning.py:507] global step 21510: loss = 0.0436 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 21511: loss = 0.0984 (0.313 sec/step)\n",
            "I0923 10:19:05.092552 139631849019264 learning.py:507] global step 21511: loss = 0.0984 (0.313 sec/step)\n",
            "INFO:tensorflow:global step 21512: loss = 0.1663 (0.288 sec/step)\n",
            "I0923 10:19:05.382577 139631849019264 learning.py:507] global step 21512: loss = 0.1663 (0.288 sec/step)\n",
            "INFO:tensorflow:global step 21513: loss = 0.1088 (0.327 sec/step)\n",
            "I0923 10:19:05.711774 139631849019264 learning.py:507] global step 21513: loss = 0.1088 (0.327 sec/step)\n",
            "INFO:tensorflow:global step 21514: loss = 0.0706 (0.291 sec/step)\n",
            "I0923 10:19:06.004629 139631849019264 learning.py:507] global step 21514: loss = 0.0706 (0.291 sec/step)\n",
            "INFO:tensorflow:global step 21515: loss = 0.0435 (0.278 sec/step)\n",
            "I0923 10:19:06.284984 139631849019264 learning.py:507] global step 21515: loss = 0.0435 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 21516: loss = 0.2081 (0.349 sec/step)\n",
            "I0923 10:19:06.636270 139631849019264 learning.py:507] global step 21516: loss = 0.2081 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 21517: loss = 0.0492 (0.332 sec/step)\n",
            "I0923 10:19:06.969719 139631849019264 learning.py:507] global step 21517: loss = 0.0492 (0.332 sec/step)\n",
            "INFO:tensorflow:global step 21518: loss = 0.0649 (0.294 sec/step)\n",
            "I0923 10:19:07.267364 139631849019264 learning.py:507] global step 21518: loss = 0.0649 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 21519: loss = 0.2255 (0.285 sec/step)\n",
            "I0923 10:19:07.554423 139631849019264 learning.py:507] global step 21519: loss = 0.2255 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 21520: loss = 0.0409 (0.280 sec/step)\n",
            "I0923 10:19:07.836023 139631849019264 learning.py:507] global step 21520: loss = 0.0409 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 21521: loss = 0.2139 (0.319 sec/step)\n",
            "I0923 10:19:08.156729 139631849019264 learning.py:507] global step 21521: loss = 0.2139 (0.319 sec/step)\n",
            "INFO:tensorflow:global step 21522: loss = 0.0910 (0.315 sec/step)\n",
            "I0923 10:19:08.473805 139631849019264 learning.py:507] global step 21522: loss = 0.0910 (0.315 sec/step)\n",
            "INFO:tensorflow:global step 21523: loss = 0.1309 (0.286 sec/step)\n",
            "I0923 10:19:08.762163 139631849019264 learning.py:507] global step 21523: loss = 0.1309 (0.286 sec/step)\n",
            "INFO:tensorflow:global step 21524: loss = 0.1335 (0.458 sec/step)\n",
            "I0923 10:19:09.221947 139631849019264 learning.py:507] global step 21524: loss = 0.1335 (0.458 sec/step)\n",
            "INFO:tensorflow:global step 21525: loss = 0.0780 (0.644 sec/step)\n",
            "I0923 10:19:09.875652 139631849019264 learning.py:507] global step 21525: loss = 0.0780 (0.644 sec/step)\n",
            "INFO:tensorflow:global step 21526: loss = 0.0439 (0.862 sec/step)\n",
            "I0923 10:19:10.740929 139631849019264 learning.py:507] global step 21526: loss = 0.0439 (0.862 sec/step)\n",
            "INFO:tensorflow:global step 21527: loss = 0.0435 (0.614 sec/step)\n",
            "I0923 10:19:11.357273 139631849019264 learning.py:507] global step 21527: loss = 0.0435 (0.614 sec/step)\n",
            "INFO:tensorflow:global step 21528: loss = 0.0339 (0.490 sec/step)\n",
            "I0923 10:19:11.849854 139631849019264 learning.py:507] global step 21528: loss = 0.0339 (0.490 sec/step)\n",
            "INFO:tensorflow:global step 21529: loss = 0.1008 (0.557 sec/step)\n",
            "I0923 10:19:12.413420 139631849019264 learning.py:507] global step 21529: loss = 0.1008 (0.557 sec/step)\n",
            "INFO:tensorflow:global step 21530: loss = 0.2395 (0.420 sec/step)\n",
            "I0923 10:19:12.835538 139631849019264 learning.py:507] global step 21530: loss = 0.2395 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 21531: loss = 0.0584 (0.493 sec/step)\n",
            "I0923 10:19:13.330152 139631849019264 learning.py:507] global step 21531: loss = 0.0584 (0.493 sec/step)\n",
            "INFO:tensorflow:global step 21532: loss = 0.1654 (0.432 sec/step)\n",
            "I0923 10:19:13.764377 139631849019264 learning.py:507] global step 21532: loss = 0.1654 (0.432 sec/step)\n",
            "INFO:tensorflow:global step 21533: loss = 0.0807 (0.441 sec/step)\n",
            "I0923 10:19:14.209862 139631849019264 learning.py:507] global step 21533: loss = 0.0807 (0.441 sec/step)\n",
            "INFO:tensorflow:global step 21534: loss = 0.0792 (0.446 sec/step)\n",
            "I0923 10:19:14.659464 139631849019264 learning.py:507] global step 21534: loss = 0.0792 (0.446 sec/step)\n",
            "INFO:tensorflow:global step 21535: loss = 0.0388 (0.486 sec/step)\n",
            "I0923 10:19:15.149346 139631849019264 learning.py:507] global step 21535: loss = 0.0388 (0.486 sec/step)\n",
            "INFO:tensorflow:global step 21536: loss = 0.1211 (0.669 sec/step)\n",
            "I0923 10:19:15.820281 139631849019264 learning.py:507] global step 21536: loss = 0.1211 (0.669 sec/step)\n",
            "INFO:tensorflow:global step 21537: loss = 0.0895 (0.364 sec/step)\n",
            "I0923 10:19:16.188765 139631849019264 learning.py:507] global step 21537: loss = 0.0895 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 21538: loss = 0.0644 (0.332 sec/step)\n",
            "I0923 10:19:16.523142 139631849019264 learning.py:507] global step 21538: loss = 0.0644 (0.332 sec/step)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS86hCQWZJMj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ae6e94a-321e-4d92-c3b0-0b4aa8f50b73"
      },
      "source": [
        "!python export_inference_graph.py --input_type image_tensor --pipeline_config_path training/faster_rcnn_inception_v2_coco.config --trained_checkpoint_prefix training/model.ckpt-22099 --output_directory warehouse_model \n",
        "#!python export_inference_graph.py --input_type image_tensor --pipeline_config_path training/ssd_mobilenet_v1_coco.config --trained_checkpoint_prefix training/model.ckpt-19202 --output_directory SSD_mask_nomask_model "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/nets/mobilenet/mobilenet.py:389: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From export_inference_graph.py:150: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From export_inference_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0924 17:39:20.646022 140085409609600 deprecation_wrapper.py:119] From export_inference_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/object_detection/anchor_generators/grid_anchor_generator.py:59: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0924 17:39:47.556068 140085409609600 deprecation.py:323] From /content/drive/My Drive/TFOD/models/research/object_detection/anchor_generators/grid_anchor_generator.py:59: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/object_detection/exporter.py:348: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0924 17:39:47.559364 140085409609600 deprecation_wrapper.py:119] From /content/drive/My Drive/TFOD/models/research/object_detection/exporter.py:348: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/object_detection/exporter.py:113: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0924 17:39:47.562752 140085409609600 deprecation_wrapper.py:119] From /content/drive/My Drive/TFOD/models/research/object_detection/exporter.py:113: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/object_detection/core/preprocessor.py:2154: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0924 17:39:47.603404 140085409609600 deprecation.py:323] From /content/drive/My Drive/TFOD/models/research/object_detection/core/preprocessor.py:2154: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/object_detection/core/preprocessor.py:2236: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0924 17:39:47.619693 140085409609600 deprecation_wrapper.py:119] From /content/drive/My Drive/TFOD/models/research/object_detection/core/preprocessor.py:2236: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:162: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0924 17:39:47.641904 140085409609600 deprecation_wrapper.py:119] From /content/drive/My Drive/TFOD/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:162: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0924 17:39:47.651215 140085409609600 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f67c28d3fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f67c28d3fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:47.713187 140085409609600 ag_logging.py:145] Entity <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f67c28d3fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SeparableConv2D.call of <tensorflow.python.layers.convolutional.SeparableConv2D object at 0x7f67c28d3fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28ec7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28ec7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:47.745005 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28ec7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28ec7f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c28ec240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c28ec240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:47.781826 140085409609600 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c28ec240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c28ec240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ec1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ec1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:47.837575 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ec1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ec1d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2873f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2873f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:47.862295 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2873f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2873f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ec240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ec240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:47.915877 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ec240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ec240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28eca90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28eca90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:47.940404 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28eca90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28eca90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c2822c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c2822c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:47.975725 140085409609600 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c2822c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c2822c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2818128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2818128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.033681 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2818128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2818128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2773e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2773e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.060475 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2773e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2773e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28180b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28180b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.112460 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28180b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28180b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c279ba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c279ba90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.140675 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c279ba90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c279ba90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.195404 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28ecc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28ecc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.221915 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28ecc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28ecc50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.273928 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28ec160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28ec160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.297842 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28ec160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28ec160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.351600 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773d68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c26917f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c26917f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.376456 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c26917f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c26917f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.431718 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2691e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2691e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.457609 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2691e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2691e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c25ba898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c25ba898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.493052 140085409609600 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c25ba898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c25ba898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2671f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2671f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.544394 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2671f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2671f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c259fba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c259fba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.568620 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c259fba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c259fba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.624411 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2773470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c25439b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c25439b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.648291 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c25439b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c25439b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ec908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ec908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.700597 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ec908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ec908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2753ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2753ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.724979 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2753ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2753ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ec198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ec198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.779275 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ec198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ec198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2543400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2543400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.803686 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2543400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2543400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c25eecf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c25eecf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.861961 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c25eecf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c25eecf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2543d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2543d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.887389 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2543d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2543d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c24c39e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c24c39e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.941569 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c24c39e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c24c39e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c23ff4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c23ff4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:48.966711 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c23ff4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c23ff4e0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2511ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2511ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.020901 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2511ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2511ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2543b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2543b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.051609 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2543b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2543b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c28ec908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c28ec908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.089567 140085409609600 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c28ec908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c28ec908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c24e1908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c24e1908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.141756 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c24e1908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c24e1908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c23b6470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c23b6470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.171607 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c23b6470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c23b6470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2543da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2543da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.226360 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2543da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2543da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2424a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2424a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.252417 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2424a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2424a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2361860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2361860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.305094 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2361860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2361860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c24e1fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c24e1fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.329631 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c24e1fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c24e1fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2361160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2361160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.383446 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2361160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2361160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c24e1b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c24e1b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.408344 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c24e1b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c24e1b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c233ef60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c233ef60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.466708 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c233ef60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c233ef60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c232fe80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c232fe80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.491677 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c232fe80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c232fe80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c244c3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c244c3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.545007 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c244c3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c244c3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c252fc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c252fc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.570036 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c252fc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c252fc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c232f3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c232f3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.605339 140085409609600 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c232f3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c232f3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2393f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2393f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.661294 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2393f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2393f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c21aef60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c21aef60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.685877 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c21aef60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c21aef60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2393e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2393e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.738991 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2393e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2393e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c21ae400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c21ae400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.764276 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c21ae400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c21ae400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c22b3e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c22b3e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.911785 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c22b3e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c22b3e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c22d30f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c22d30f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.937938 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c22d30f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c22d30f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2205c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2205c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:49.993062 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2205c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2205c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f682492c2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f682492c2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.018648 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f682492c2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f682492c2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c21c4470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c21c4470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.085369 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c21c4470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c21c4470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c21ae390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c21ae390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.112535 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c21ae390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c21ae390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ecb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ecb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.176683 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ecb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ecb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c21aea58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c21aea58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.202174 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c21aea58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c21aea58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c2873fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c2873fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.241013 140085409609600 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c2873fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c2873fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c265fb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c265fb38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.294954 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c265fb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c265fb38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28708d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28708d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.319338 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28708d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c28708d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c21aebe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c21aebe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.373837 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c21aebe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c21aebe0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f9eba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f9eba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.398553 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f9eba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f9eba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c265fb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c265fb38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.453989 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c265fb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c265fb38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1fe0908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1fe0908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.479105 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1fe0908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1fe0908>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2090710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2090710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.532381 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2090710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2090710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2101cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2101cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.559584 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2101cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2101cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1f9efd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1f9efd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.612934 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1f9efd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1f9efd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2083f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2083f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.637385 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2083f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c2083f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1f330b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1f330b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.693417 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1f330b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1f330b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1e3be10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1e3be10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.717875 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1e3be10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1e3be10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1f33080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1f33080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.771817 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1f33080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1f33080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1e29668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1e29668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.796871 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1e29668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1e29668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c1f33080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c1f33080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.832533 140085409609600 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c1f33080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c1f33080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1df8f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1df8f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.884712 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1df8f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1df8f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1d852e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1d852e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.909308 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1d852e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1d852e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1f9efd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1f9efd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.966573 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1f9efd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1f9efd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f6b8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f6b8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:50.991523 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f6b8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f6b8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1e3be10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1e3be10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.044534 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1e3be10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1e3be10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1d71ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1d71ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.069222 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1d71ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1d71ef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1da1400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1da1400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.129121 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1da1400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1da1400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f6ba58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f6ba58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.154256 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f6ba58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f6ba58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1d85320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1d85320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.212565 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1d85320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1d85320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f1ea20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f1ea20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.237820 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f1ea20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f1ea20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1d10da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1d10da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.294276 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1d10da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1d10da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1e4f0f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1e4f0f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.319277 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1e4f0f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1e4f0f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ecb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ecb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.373263 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ecb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c28ecb00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1ca74a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1ca74a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.398142 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1ca74a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1ca74a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c1bd5630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c1bd5630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.433488 140085409609600 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c1bd5630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c1bd5630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1ca2f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1ca2f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.488339 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1ca2f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1ca2f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1ba7a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1ba7a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.513360 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1ba7a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1ba7a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1ca7eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1ca7eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.567739 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1ca7eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1ca7eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1e155f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1e155f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.592033 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1e155f8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1e155f8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1df8f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1df8f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.644804 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1df8f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1df8f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1d71f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1d71f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.671404 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1d71f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1d71f28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1b42048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1b42048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.724040 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1b42048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1b42048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1b0fe10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1b0fe10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.748678 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1b0fe10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1b0fe10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1b42da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1b42da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.801353 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1b42da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1b42da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1b424a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1b424a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.825700 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1b424a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1b424a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1ca2eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1ca2eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.882371 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1ca2eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1ca2eb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1b2d4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1b2d4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.907431 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1b2d4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1b2d4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1b0feb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1b0feb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.961938 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1b0feb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1b0feb8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1b42630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1b42630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:51.986746 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1b42630>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1b42630>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c1b28780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c1b28780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:52.022357 140085409609600 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c1b28780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c1b28780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1ae0828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1ae0828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:52.078318 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1ae0828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1ae0828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c19f1198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c19f1198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:52.104863 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c19f1198>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c19f1198>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/object_detection/core/anchor_generator.py:149: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0924 17:39:52.249491 140085409609600 deprecation_wrapper.py:119] From /content/drive/My Drive/TFOD/models/research/object_detection/core/anchor_generator.py:149: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0924 17:39:52.257587 140085409609600 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:986: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W0924 17:39:52.257919 140085409609600 deprecation_wrapper.py:119] From /content/drive/My Drive/TFOD/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:986: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2977470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2977470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:52.314330 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2977470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c2977470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0924 17:39:52.316606 140085409609600 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/object_detection/predictors/convolutional_box_predictor.py:147: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0924 17:39:52.316954 140085409609600 deprecation_wrapper.py:119] From /content/drive/My Drive/TFOD/models/research/object_detection/predictors/convolutional_box_predictor.py:147: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0924 17:39:52.317071 140085409609600 convolutional_box_predictor.py:148] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c17c6668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c17c6668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:52.378421 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c17c6668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c17c6668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c17c6ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c17c6ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:52.439897 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c17c6ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c17c6ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/object_detection/core/box_list_ops.py:136: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0924 17:39:52.465234 140085409609600 deprecation.py:323] From /content/drive/My Drive/TFOD/models/research/object_detection/core/box_list_ops.py:136: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/object_detection/utils/ops.py:1085: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0924 17:39:53.035199 140085409609600 deprecation.py:506] From /content/drive/My Drive/TFOD/models/research/object_detection/utils/ops.py:1085: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c12184a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c12184a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.087899 140085409609600 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c12184a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c12184a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c11be978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c11be978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.148646 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c11be978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c11be978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c11be0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c11be0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.175379 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c11be0b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c11be0b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c11be2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c11be2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.235355 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c11be2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c11be2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c11e2278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c11e2278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.261885 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c11e2278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c11e2278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1a417f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1a417f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.316658 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1a417f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1a417f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c11decc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c11decc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.341752 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c11decc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c11decc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c11be2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c11be2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.395601 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c11be2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c11be2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1960470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1960470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.420113 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1960470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1960470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c11befd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c11befd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.473890 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c11befd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c11befd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c110def0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c110def0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.499603 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c110def0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c110def0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c19dc470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c19dc470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.535016 140085409609600 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c19dc470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c19dc470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c10faa20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c10faa20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.590943 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c10faa20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c10faa20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c17d27f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c17d27f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.615534 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c17d27f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c17d27f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1088fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1088fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.672688 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1088fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1088fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c10c6dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c10c6dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.697518 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c10c6dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c10c6dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c19dc470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c19dc470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.750385 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c19dc470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c19dc470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c11c21d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c11c21d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.777208 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c11c21d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c11c21d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c10a2e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c10a2e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.830080 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c10a2e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c10a2e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1189080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1189080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.855481 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1189080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1189080>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c10582e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c10582e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.909029 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c10582e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c10582e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1163a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1163a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.933472 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1163a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1163a90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c110d9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c110d9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:53.988704 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c110d9e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c110d9e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0f6f940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0f6f940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.013324 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0f6f940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0f6f940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c10afe80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c10afe80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.048818 140085409609600 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c10afe80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c10afe80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1163b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1163b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.100615 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1163b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c1163b00>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0f7a6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0f7a6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.124844 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0f7a6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0f7a6d8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0f2f8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0f2f8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.187927 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0f2f8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0f2f8d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0e55da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0e55da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.217109 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0e55da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0e55da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c122aef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c122aef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.270430 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c122aef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c122aef0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0f993c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0f993c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.294906 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0f993c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0f993c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0f7ae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0f7ae10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.348413 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0f7ae10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0f7ae10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0debe10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0debe10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.373018 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0debe10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0debe10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c10afe80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c10afe80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.426676 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c10afe80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c10afe80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0f6fe80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0f6fe80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.451613 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0f6fe80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0f6fe80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c122af28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c122af28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.504354 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c122af28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c122af28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0de9c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0de9c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.528599 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0de9c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0de9c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c122ae80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c122ae80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.581574 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c122ae80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c122ae80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0eebc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0eebc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.605814 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0eebc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0eebc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c122af28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c122af28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.640869 140085409609600 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c122af28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c122af28>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0ead860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0ead860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.695137 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0ead860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0ead860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f1ef60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f1ef60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.719973 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f1ef60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c1f1ef60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0924 17:39:54.724313 140085409609600 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f67c0dfd710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f67c0dfd710>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "W0924 17:39:54.732239 140085409609600 ag_logging.py:145] Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f67c0dfd710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f67c0dfd710>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0924 17:39:54.737472 140085409609600 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f67c0fa1c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f67c0fa1c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.809600 140085409609600 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f67c0fa1c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f67c0fa1c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f67c0d07780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f67c0d07780>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "W0924 17:39:54.821358 140085409609600 ag_logging.py:145] Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f67c0d07780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f67c0d07780>>: AttributeError: module 'gast' has no attribute 'Num'\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0924 17:39:54.826146 140085409609600 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f67c0d076a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f67c0d076a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:54.900923 140085409609600 ag_logging.py:145] Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f67c0d076a0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f67c0d076a0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c0596f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c0596f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:55.626039 140085409609600 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c0596f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c0596f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c053d0f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c053d0f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:55.674328 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c053d0f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c053d0f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0560c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0560c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:55.689182 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0560c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0560c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c054f400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c054f400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:55.735896 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c054f400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c054f400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c054b390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c054b390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:55.749923 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c054b390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c054b390>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0c9c208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0c9c208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:55.797420 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0c9c208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0c9c208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c05b6ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c05b6ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:55.811282 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c05b6ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c05b6ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c054f400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c054f400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:55.859401 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c054f400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c054f400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0d07668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0d07668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:55.873649 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0d07668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0d07668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0ead4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0ead4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:55.924616 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0ead4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c0ead4a8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0556860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0556860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:55.940173 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0556860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0556860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c05a6d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c05a6d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:55.977709 140085409609600 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c05a6d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c05a6d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c053d3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c053d3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.025409 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c053d3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c053d3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0556da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0556da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.039491 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0556da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0556da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.086999 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6c50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c05b60b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c05b60b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.102646 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c05b60b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c05b60b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c053d3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c053d3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.148892 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c053d3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c053d3c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0560dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0560dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.162369 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0560dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0560dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.216075 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04f9d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04f9d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.232770 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04f9d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04f9d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6b70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.280842 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6b70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0560278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0560278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.296745 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0560278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c0560278>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05b6e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05b6e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.343299 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05b6e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05b6e48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04f9320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04f9320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.356737 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04f9320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04f9320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c05a6c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c05a6c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.391970 140085409609600 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c05a6c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.AveragePooling2D object at 0x7f67c05a6c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.437651 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6f98>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c052c240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c052c240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.451169 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c052c240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c052c240>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c04f8978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c04f8978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.501371 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c04f8978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c04f8978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04b8b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04b8b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.515324 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04b8b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04b8b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.561897 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6cf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04d00b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04d00b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.575361 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04d00b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04d00b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c04f88d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c04f88d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.622151 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c04f88d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c04f88d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c056d5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c056d5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.635496 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c056d5c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c056d5c0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.681618 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c05a6d30>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c05600b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c05600b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.697368 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c05600b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c05600b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c050d898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c050d898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.743901 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c050d898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c050d898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c052b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c052b160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.757604 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c052b160>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c052b160>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c056de48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c056de48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.804854 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c056de48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c056de48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04dd978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04dd978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.818520 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04dd978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c04dd978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c056d7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c056d7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.854079 140085409609600 ag_logging.py:145] Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c056d7b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f67c056d7b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c04f8f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c04f8f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.902764 140085409609600 ag_logging.py:145] Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c04f8f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f67c04f8f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c050d898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c050d898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "W0924 17:39:56.916948 140085409609600 ag_logging.py:145] Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c050d898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x7f67c050d898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/object_detection/exporter.py:330: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0924 17:39:56.932834 140085409609600 deprecation.py:323] From /content/drive/My Drive/TFOD/models/research/object_detection/exporter.py:330: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/object_detection/exporter.py:484: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0924 17:39:56.935854 140085409609600 deprecation.py:323] From /content/drive/My Drive/TFOD/models/research/object_detection/exporter.py:484: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0924 17:39:56.936995 140085409609600 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "252 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/12.86m params)\n",
            "  Conv (--/2.65m params)\n",
            "    Conv/biases (512, 512/512 params)\n",
            "    Conv/weights (3x3x576x512, 2.65m/2.65m params)\n",
            "  FirstStageBoxPredictor (--/36.94k params)\n",
            "    FirstStageBoxPredictor/BoxEncodingPredictor (--/24.62k params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/biases (48, 48/48 params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n",
            "    FirstStageBoxPredictor/ClassPredictor (--/12.31k params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/biases (24, 24/24 params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "  FirstStageFeatureExtractor (--/4.25m params)\n",
            "    FirstStageFeatureExtractor/InceptionV2 (--/4.25m params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7 (--/2.71k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/depthwise_weights (7x7x3x8, 1.18k/1.18k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_1a_7x7/pointwise_weights (1x1x24x64, 1.54k/1.54k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1 (--/4.10k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2b_1x1/weights (1x1x64x64, 4.10k/4.10k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3 (--/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Conv2d_2c_3x3/weights (3x3x64x192, 110.59k/110.59k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_3b (--/218.11k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0 (--/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_0/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1 (--/49.15k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3 (--/36.86k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2 (--/150.53k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1 (--/12.29k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0a_1x1/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3 (--/6.14k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1 (--/6.14k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3b/Branch_3/Conv2d_0b_1x1/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_3c (--/259.07k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0 (--/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_0/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1 (--/71.68k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2 (--/154.62k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0a_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_2/Conv2d_0c_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3 (--/16.38k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1 (--/16.38k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_3c/Branch_3/Conv2d_0b_1x1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4a (--/384.00k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0 (--/225.28k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1 (--/40.96k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_0a_1x1/weights (1x1x320x128, 40.96k/40.96k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1 (--/158.72k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1 (--/20.48k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0a_1x1/weights (1x1x320x64, 20.48k/20.48k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3 (--/82.94k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4a/Branch_1/Conv2d_1a_3x3/weights (3x3x96x96, 82.94k/82.94k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4b (--/608.26k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0 (--/129.02k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1 (--/129.02k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_0/Conv2d_0a_1x1/weights (1x1x576x224, 129.02k/129.02k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1 (--/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1 (--/36.86k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0a_1x1/weights (1x1x576x64, 36.86k/36.86k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_1/Conv2d_0b_3x3/weights (3x3x64x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2 (--/313.34k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4b/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4c (--/663.55k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0 (--/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_0/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1 (--/165.89k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_1/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2 (--/313.34k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3 (--/110.59k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0b_3x3/weights (3x3x96x128, 110.59k/110.59k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3 (--/147.46k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_2/Conv2d_0c_3x3/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4c/Branch_3/Conv2d_0b_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4d (--/893.95k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0 (--/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1 (--/92.16k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_0/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1 (--/258.05k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2 (--/488.45k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3 (--/184.32k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0b_3x3/weights (3x3x128x160, 184.32k/184.32k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3 (--/230.40k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_2/Conv2d_0c_3x3/weights (3x3x160x160, 230.40k/230.40k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4d/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FirstStageFeatureExtractor/InceptionV2/Mixed_4e (--/1.11m params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_0/Conv2d_0a_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1 (--/294.91k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3 (--/221.18k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_1/Conv2d_0b_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2 (--/700.42k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1 (--/92.16k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0a_1x1/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3 (--/276.48k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0b_3x3/weights (3x3x160x192, 276.48k/276.48k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3 (--/331.78k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_2/Conv2d_0c_3x3/weights (3x3x192x192, 331.78k/331.78k params)\n",
            "        FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3 (--/55.30k params)\n",
            "          FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1 (--/55.30k params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            FirstStageFeatureExtractor/InceptionV2/Mixed_4e/Branch_3/Conv2d_0b_1x1/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "  SecondStageBoxPredictor (--/21.52k params)\n",
            "    SecondStageBoxPredictor/BoxEncodingPredictor (--/16.40k params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/biases (16, 16/16 params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/weights (1024x16, 16.38k/16.38k params)\n",
            "    SecondStageBoxPredictor/ClassPredictor (--/5.12k params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/biases (5, 5/5 params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/weights (1024x5, 5.12k/5.12k params)\n",
            "  SecondStageFeatureExtractor (--/5.89m params)\n",
            "    SecondStageFeatureExtractor/InceptionV2 (--/5.89m params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5a (--/1.44m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0 (--/294.91k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1 (--/73.73k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_0a_1x1/weights (1x1x576x128, 73.73k/73.73k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3 (--/221.18k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_0/Conv2d_1a_3x3/weights (3x3x128x192, 221.18k/221.18k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1 (--/1.14m params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1 (--/110.59k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0a_1x1/weights (1x1x576x192, 110.59k/110.59k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3 (--/442.37k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_0b_3x3/weights (3x3x192x256, 442.37k/442.37k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3 (--/589.82k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5a/Branch_1/Conv2d_1a_3x3/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5b (--/2.18m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0 (--/360.45k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1 (--/749.57k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2 (--/937.98k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1 (--/163.84k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x160, 163.84k/163.84k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3 (--/322.56k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0b_3x3/weights (3x3x160x224, 322.56k/322.56k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3 (--/131.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5b/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
            "      SecondStageFeatureExtractor/InceptionV2/Mixed_5c (--/2.28m params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0 (--/360.45k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1 (--/360.45k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_0/Conv2d_0a_1x1/weights (1x1x1024x352, 360.45k/360.45k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1 (--/749.57k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3 (--/552.96k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_1/Conv2d_0b_3x3/weights (3x3x192x320, 552.96k/552.96k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2 (--/1.04m params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1 (--/196.61k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0a_1x1/weights (1x1x1024x192, 196.61k/196.61k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3 (--/387.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0b_3x3/weights (3x3x192x224, 387.07k/387.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3 (--/451.58k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_2/Conv2d_0c_3x3/weights (3x3x224x224, 451.58k/451.58k params)\n",
            "        SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3 (--/131.07k params)\n",
            "          SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1 (--/131.07k params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/BatchNorm (--/0 params)\n",
            "            SecondStageFeatureExtractor/InceptionV2/Mixed_5c/Branch_3/Conv2d_0b_1x1/weights (1x1x1024x128, 131.07k/131.07k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "252 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/2.56k flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  map_1/while/mul_3 (300/300 flops)\n",
            "  map_1/while/mul_2 (300/300 flops)\n",
            "  map_1/while/mul_1 (300/300 flops)\n",
            "  map_1/while/mul (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  GridAnchorGenerator/mul_2 (12/12 flops)\n",
            "  GridAnchorGenerator/truediv (12/12 flops)\n",
            "  GridAnchorGenerator/mul_1 (12/12 flops)\n",
            "  GridAnchorGenerator/mul (12/12 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  mul (1/1 flops)\n",
            "  map_1/while/add_1 (1/1 flops)\n",
            "  map_1/while/add (1/1 flops)\n",
            "  map_1/while/Less_1 (1/1 flops)\n",
            "  map_1/while/Less (1/1 flops)\n",
            "  map/while/add_1 (1/1 flops)\n",
            "  map/while/add (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map/while/Less_1 (1/1 flops)\n",
            "  map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/add_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/add (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/add (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/add (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/Maximum (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStageDetectionFeaturesExtract/mul (1/1 flops)\n",
            "  Preprocessor/map/while/add_1 (1/1 flops)\n",
            "  Preprocessor/map/while/add (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/truediv_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/mul_3 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/mul_2 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/mul_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/mul (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/Minimum (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/Greater (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  GridAnchorGenerator/zeros/Less (1/1 flops)\n",
            "  GridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  GridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  GridAnchorGenerator/assert_equal/Equal (1/1 flops)\n",
            "  GridAnchorGenerator/add_4 (1/1 flops)\n",
            "  GridAnchorGenerator/add_3 (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual_1 (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/add_1 (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/object_detection/exporter.py:377: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0924 17:39:57.966720 140085409609600 deprecation_wrapper.py:119] From /content/drive/My Drive/TFOD/models/research/object_detection/exporter.py:377: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "2020-09-24 17:39:58.832061: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2020-09-24 17:39:58.834411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-24 17:39:58.834942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-24 17:39:58.835208: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-09-24 17:39:58.836401: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-09-24 17:39:58.837526: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-09-24 17:39:58.837867: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-09-24 17:39:58.839215: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-09-24 17:39:58.840204: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-09-24 17:39:58.854958: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-24 17:39:58.855087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-24 17:39:58.855687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-24 17:39:58.856213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2020-09-24 17:39:58.856545: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2020-09-24 17:39:58.948873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-24 17:39:58.949569: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x315b640 executing computations on platform CUDA. Devices:\n",
            "2020-09-24 17:39:58.949601: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-09-24 17:39:58.951502: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000185000 Hz\n",
            "2020-09-24 17:39:58.951964: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x315b2c0 executing computations on platform Host. Devices:\n",
            "2020-09-24 17:39:58.951997: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2020-09-24 17:39:58.952195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-24 17:39:58.952739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-24 17:39:58.952807: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-09-24 17:39:58.952833: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-09-24 17:39:58.952855: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-09-24 17:39:58.952874: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-09-24 17:39:58.952893: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-09-24 17:39:58.952911: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-09-24 17:39:58.952931: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-24 17:39:58.953005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-24 17:39:58.953571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-24 17:39:58.954078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2020-09-24 17:39:58.954147: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-09-24 17:39:58.955285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-24 17:39:58.955312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2020-09-24 17:39:58.955326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2020-09-24 17:39:58.955437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-24 17:39:58.955973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-24 17:39:58.956475: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:40] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-09-24 17:39:58.956516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0924 17:39:58.957244 140085409609600 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-22099\n",
            "I0924 17:39:58.959846 140085409609600 saver.py:1280] Restoring parameters from training/model.ckpt-22099\n",
            "2020-09-24 17:40:14.799951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-24 17:40:14.800528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-24 17:40:14.800632: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-09-24 17:40:14.800666: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-09-24 17:40:14.800689: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-09-24 17:40:14.800709: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-09-24 17:40:14.800729: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-09-24 17:40:14.800748: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-09-24 17:40:14.800768: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-24 17:40:14.800854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-24 17:40:14.801395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-24 17:40:14.801872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2020-09-24 17:40:14.801914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-24 17:40:14.801928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2020-09-24 17:40:14.801938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2020-09-24 17:40:14.802029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-24 17:40:14.802565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-24 17:40:14.803059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-22099\n",
            "I0924 17:40:14.804690 140085409609600 saver.py:1280] Restoring parameters from training/model.ckpt-22099\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0924 17:40:15.495898 140085409609600 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0924 17:40:15.496133 140085409609600 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 356 variables.\n",
            "I0924 17:40:15.804240 140085409609600 graph_util_impl.py:311] Froze 356 variables.\n",
            "INFO:tensorflow:Converted 356 variables to const ops.\n",
            "I0924 17:40:15.905468 140085409609600 graph_util_impl.py:364] Converted 356 variables to const ops.\n",
            "2020-09-24 17:40:16.158155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-24 17:40:16.158767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-24 17:40:16.158863: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-09-24 17:40:16.158889: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-09-24 17:40:16.158910: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-09-24 17:40:16.158931: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-09-24 17:40:16.158951: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-09-24 17:40:16.158970: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-09-24 17:40:16.158990: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-24 17:40:16.159074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-24 17:40:16.159624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-24 17:40:16.160104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2020-09-24 17:40:16.160143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-24 17:40:16.160157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2020-09-24 17:40:16.160166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2020-09-24 17:40:16.160275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-24 17:40:16.160891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-24 17:40:16.161465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14974 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/object_detection/exporter.py:259: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "W0924 17:40:16.533429 140085409609600 deprecation_wrapper.py:119] From /content/drive/My Drive/TFOD/models/research/object_detection/exporter.py:259: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/object_detection/exporter.py:262: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0924 17:40:16.535674 140085409609600 deprecation.py:323] From /content/drive/My Drive/TFOD/models/research/object_detection/exporter.py:262: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/object_detection/exporter.py:268: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "W0924 17:40:16.536090 140085409609600 deprecation_wrapper.py:119] From /content/drive/My Drive/TFOD/models/research/object_detection/exporter.py:268: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/object_detection/exporter.py:274: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "W0924 17:40:16.536326 140085409609600 deprecation_wrapper.py:119] From /content/drive/My Drive/TFOD/models/research/object_detection/exporter.py:274: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0924 17:40:16.536607 140085409609600 builder_impl.py:636] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0924 17:40:16.536701 140085409609600 builder_impl.py:456] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: warehouse_model/saved_model/saved_model.pb\n",
            "I0924 17:40:17.057545 140085409609600 builder_impl.py:421] SavedModel written to: warehouse_model/saved_model/saved_model.pb\n",
            "WARNING:tensorflow:From /content/drive/My Drive/TFOD/models/research/object_detection/utils/config_util.py:180: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0924 17:40:17.083775 140085409609600 deprecation_wrapper.py:119] From /content/drive/My Drive/TFOD/models/research/object_detection/utils/config_util.py:180: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "INFO:tensorflow:Writing pipeline config file to warehouse_model/pipeline.config\n",
            "I0924 17:40:17.084002 140085409609600 config_util.py:182] Writing pipeline config file to warehouse_model/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOlZ9Rbe6ipw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "781b0090-09a3-4c54-8fb1-877b5ace233b"
      },
      "source": [
        "tensorboard --logdir=training"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-0ed7687e67b9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensorboard --logdir=training\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to operator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P0TjWr9fFWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h69Sor6-N90",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c548f3f9-9b4e-4ab0-82d6-12f45fd90f6e"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sTJTfK5EQIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# press CRTL + SHIFT + I     # prevent for disconneting google collab\n",
        "# peaste the JS CODE \n",
        "\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"colab-toolbar-button\").click() \n",
        "}setInterval(ClickConnect,60000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1lJvMB0Fmry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSWeP5dmF1VR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9JFnEeSGD-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMoWzKOMGSoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Wn7-22DGhR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RyxScF9Gv7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMJDM_fuG-ky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI_OK4qKHNOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpbbJoJAHb30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjn71MedHqhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPH8alOlH5K0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt82GhqgIH0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4XqCtAZIWdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg873-tvIlHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy5ttnRRIzwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqtjm8ZdJCaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHyz2QXPJRDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krgBRPHGJftR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdpaMuB7JuWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0eVvjtQJ9AR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXwesg4pKLpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z39YksUoKaTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbiiqtdSKo80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd7svTGoK3mR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TnEX5MlLGPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SczaBcXyLU5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yua_2aKALjix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-EGliPyLyMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPciX0rOMA1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGq56Gb9MPfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsPhI5bbMeIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izr6dAw0MsyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XodADO3HM7b2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXU47JCZNKFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwuXzZLCNYuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-4_7KMENnYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kktFOoUqN2CM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZKONX7VOErR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FORhx47IOTUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyBfjL9-Oh-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9BmfLmDOwny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW-0tJBBO_RS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM0T8YB5PN6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l06z3nRnPckS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrvQgli4PrNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTlEUml1P53K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6xDUF9ZQIgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFtZvUrmQYcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPSj9G0_Qlzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFVjl8L-Q0dR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4gYGJzsRDGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB3yK9ZHRRwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQt3f5QLRgZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHSDZchARvDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKIKC-4jR9sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlbsl4sMSMWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPmcQj8DSa_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUF0-S4bSppj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oVwhwkTS4Ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4hX6Wc2TG8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xESqAnCTVlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4OxDY8TTkPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-jyFOF3Ty4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq6_DCsMUBiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tknGKOOCUQLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LilokY5Ue1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwWJn2blUtvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW3DgtKuVhbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtuLVQ6-VxOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG_DprNCV22j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbtVWqTdWFev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai0lu7BcW7ED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7B-2tzUXB5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De6hV1GKXfFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiPOUARWXuTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY1q3BnmX6j0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pFW4-qGYJNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16ELD6NFYX2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHgDAIc8YmhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhPKoNS_Y1Jy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYKUgKgjZDzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9gxfktOZScx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRiFN1-kZhGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2TJRBiFZvxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVZCkRDvZ-ZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf5f3oc7aauZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weG9BpvWabsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR0xJnRaatn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2Zz8ccRa4_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG9JBxoCbHoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfdNWMCebWSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LgKGvRXbk8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9nmOpgtb0B4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3Q5o-yNcCOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHVCHvTvcQ_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9KQfg1jdeiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXZ9dkPHPK1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "function ClickConnect(){\n",
        "    console.log(\"Clicked on connect button\"); \n",
        "    document.querySelector(\"colab-connect-button\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkfIfS0HPpBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "function ClickConnect(){\n",
        "    console.log(\"Clicked on connect button\"); \n",
        "    document.querySelector(\"Put ID here\").click() // Change id here\n",
        "}\n",
        "setInterval(ClickConnect,60000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}